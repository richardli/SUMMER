[{"path":"https://richardli.github.io/SUMMER/articles/web_only/small-area-estimation.html","id":"preliminary","dir":"Articles > Web_only","previous_headings":"","what":"Preliminary","title":"Generic small area estimation","text":"First, load necessary packages data. required package INLA available via standard repository, include code installation found. survey package used generate direct estimates, dplyr tidyr used data manipulation.","code":"library(sae) library(SUMMER) library(survey) library(dplyr) library(tidyr) library(sf) library(ggplot2) if (!isTRUE(requireNamespace(\"INLA\", quietly = TRUE))) {   install.packages(\"INLA\", repos=c(getOption(\"repos\"),                    INLA=\"https://inla.r-inla-download.org/R/stable\"), dep=TRUE) }"},{"path":[]},{"path":"https://richardli.github.io/SUMMER/articles/web_only/small-area-estimation.html","id":"artificial-poverty-rate-example","dir":"Articles > Web_only","previous_headings":"Area level models","what":"Artificial poverty rate example","title":"Generic small area estimation","text":"vignette sae package, Molina Marhuenda (2015) generate artificial dataset income related variables illustrate use area level models. example, objective estimate prevalence poverty Spanish counties. incomedata data frame contains information 17199 observations individuals 52 Spanish provinces. Income values sampling weights provided individual along covariate information including age group education level. Molina Marhuenda (2015) define poverty line calculate indicator variable (name in_poverty) value 1 corresponding income value poverty line 0 otherwise.","code":"data(\"incomedata\") data(\"sizeprov\") data(\"sizeprovedu\") povertyline <- 0.6 * median(incomedata$income) # 6557.143 incomedata$in_poverty <- as.integer(incomedata$income < povertyline)"},{"path":"https://richardli.github.io/SUMMER/articles/web_only/small-area-estimation.html","id":"direct-estimation-with-sae","dir":"Articles > Web_only","previous_headings":"Area level models > Artificial poverty rate example","what":"Direct estimation with sae","title":"Generic small area estimation","text":"considering model-based methods small area estimation, compute direct weighted estimators desired small area means. sae::direct function computes Horvitz-Thompson estimator domain means given \\[ \\widehat{\\overline{Y}}_{}^{\\text{DIR}}=\\frac{1}{N_i}\\sum_{j\\S_i}w_{j}y_{j} \\] \\(N_i\\) population size domain \\(\\), \\(S_i\\) set sampled observations domain \\(\\), \\(w_{j}\\) sampling weight unit \\(j\\), \\(y_{j}\\) observation unit \\(j\\), \\(j \\S_i\\). sae::direct function also estimates standard deviation coefficient variation domain. Note \\(N_i\\) assumed known provided data frame sizeprov. domains interest identified via provlab variable.","code":"Popn <- sizeprov[, c(\"provlab\", \"Nd\")] sae.DIR <- sae::direct(y = incomedata$in_poverty, dom = incomedata$provlab,                        sweight = incomedata$weight, domsize = Popn) |>   select(Domain, Direct, SD)"},{"path":"https://richardli.github.io/SUMMER/articles/web_only/small-area-estimation.html","id":"direct-estimation-with-survey","dir":"Articles > Web_only","previous_headings":"Area level models > Artificial poverty rate example","what":"Direct estimation with survey","title":"Generic small area estimation","text":"can similarly use survey::svyby function compute Horvitz-Thompson estimates:","code":"incomedata$pop <- sum(sizeprov$Nd[match(incomedata$provlab, sizeprov$provlab)]) design <- survey::svydesign(ids = ~1, weights = ~weight,                             data = incomedata, fpc = ~pop)  # estimate area totals svy.DIR <- survey::svyby(~in_poverty, ~provlab, design, svytotal)  # calculate corresponding area mean estimates svy.DIR$prov_pop <- sizeprov$Nd[match(svy.DIR$provlab, sizeprov$provlab)] svy.DIR$Domain <-svy.DIR$provlab  svy.DIR$Direct = svy.DIR$in_poverty/svy.DIR$prov_pop svy.DIR$SD= svy.DIR$se/svy.DIR$prov_pop"},{"path":"https://richardli.github.io/SUMMER/articles/web_only/small-area-estimation.html","id":"basic-area-level-model","dir":"Articles > Web_only","previous_headings":"Area level models > Artificial poverty rate example","what":"Basic area level model","title":"Generic small area estimation","text":"basic area level model, also called Fay-Herriot model, treats direct estimates small area quantities response data explicitly models differences areas using covariate information random effects Fay Herriot (1979). Fay-Herriot model can viewed two-stage model: first stage, sampling model represents sampling variability direct estimator second stage, linking model describes area differences small area quantities. Sampling model: Let \\(\\widehat\\theta^{\\text{DIR}}_i\\) direct estimator area level mean total \\(\\theta_i\\). sampling model treats \\(\\widehat\\theta^{\\text{DIR}}_i\\) noisy observation true finite population quantity \\(\\theta_i\\): \\[ \\widehat\\theta^{\\text{DIR}}_i=\\theta_i+\\epsilon_i;\\hspace{2em}\\epsilon_i\\sim_{ind}N(0,V_i),\\hspace{2em}=1,\\ldots, M \\] \\(V_i\\) known sampling variance direct estimator \\(\\widehat{\\theta}^{\\text{DIR}}_i\\). Linking model: \\[ \\theta_i = \\textbf{x}_i^T\\boldsymbol\\beta+u_i,\\hspace{2em}u_i\\sim_{ind}N(0,\\sigma_u^2)\\hspace{2em}=1,\\ldots, M, \\] \\(\\sigma_u^2\\) (-area residual variance) estimated. basic Fay-Herriot model, area-specific random effects \\(u_i\\) assumed independent identically distributed (IID) areas. , provide quantile-quantile plot comparing direct estimates Gaussian distribution. observed quantiles align well Gaussian distribution, lends support basic IID model.","code":"par(pty = \"s\") mu.DIR <- mean(sae.DIR$Direct) sd.DIR <- sd(sae.DIR$Direct) qqnorm((sae.DIR$Direct - mu.DIR) / sd.DIR, main = \"\") abline(0, 1, col = \"red\")"},{"path":"https://richardli.github.io/SUMMER/articles/web_only/small-area-estimation.html","id":"area-level-modeling-with-sae","dir":"Articles > Web_only","previous_headings":"Area level models > Artificial poverty rate example","what":"Area level modeling with sae","title":"Generic small area estimation","text":"described Molina Marhuenda (2015), sae::mseFH function fits basic area level model (via REML default) calculates empirical best linear unbiased predictors (EBLUP) domain means well estimated MSEs.","code":"sae.FH <- sae::mseFH(sae.DIR$Direct~1, sae.DIR$SD^2) sae.FH.table <- data.frame(   Domain = sae.DIR$Domain,   EBLUP = sae.FH$est$eblup,   RMSE = sqrt(sae.FH$mse) ) head(sae.FH.table) ##     Domain      EBLUP       RMSE ## 1    Alava 0.23407448 0.03836098 ## 2 Albacete 0.15335213 0.02744856 ## 3 Alicante 0.20511853 0.02051886 ## 4  Almeria 0.24498009 0.03427432 ## 5    Avila 0.07797403 0.02372809 ## 6  Badajoz 0.20928033 0.02186672"},{"path":"https://richardli.github.io/SUMMER/articles/web_only/small-area-estimation.html","id":"area-level-modeling-with-summer","dir":"Articles > Web_only","previous_headings":"Area level models > Artificial poverty rate example","what":"Area level modeling with SUMMER","title":"Generic small area estimation","text":"SUMMER package adopts Bayesian approach inference using models basic area level model, carrying computation via INLA package. smoothArea function computes direct estimates produces smoothed estimates using Bayesian Fay-Herriot model. main arguments interest : formula: Describing response variable area-level covariates domain one-sided formula variable containing domain labels right. domain labels variable contained dataset used generate design. design: survey.design object containing survey data specifying survey design. addition, commonly used optional arguments include: adj.mat: Optional adjacency matrix spatial smoothing model desired. transform: \"logit\" specified, logit transform applied direct estimates appropriate transformation applied estimated sampling variances smoothing. direct.est: direct estimates may specified directly smoothing applied directly user-provided estimates. X.domain: Data frame area level covariates. domain.size: Data frame domain sizes used computing direct estimates domain sizes known. optional arguments can specified change priors described documentation. artificial poverty rate example, fit Fay-Herriot model obtain following smoothed estimates. fitted parameters sae (obtained via likelihood-based methods) estimated parameter posterior distribution SUMMER (obtained Bayesian methods, implemented via INLA) reasonable agreement. estimated intercept \\(\\beta_0\\) sae 0.202 ; posterior median \\(\\beta_0\\) SUMMER 0.202. absence strong priors, fixed effects usually close agreement, posterior symmetric. estimated precision \\(1/\\sigma_u^2\\) sae 281.34787 , posterior median \\(1/\\sigma_u^2\\) SUMMER 273.241562. differences larger , posterior variance skewed, expect posterior median smaller REML estimate. area estimates measures uncertainty close agreement, however. first illustrate shrinkage EBLUP estimates, reduced uncertainty:  Now compare EBLUP HB, using posterior variance SUMMER estimated MSE sae measure uncertainty:  SUMMER package includes functions generate additional diagnostic plots based samples model posterior. compareEstimates() function generates heatmap posterior pairwise probabilities one area’s mean exceeding another’s mean. geographic polygon data domain available shapefile, sf package can used load data R. mapEstimates() function can used provide summary map posterior medians posterior variances.","code":"# specify known domain sizes domain.size <- sizeprov[, c(\"provlab\", \"Nd\")] colnames(domain.size)[2] <- \"size\"  # fit model and obtain svysae object summer.FH <- smoothArea(formula = in_poverty~1,                         domain = ~provlab,                         design = design,                         domain.size = domain.size,                          return.samples = T) ## Warning in smoothArea(formula = in_poverty ~ 1, domain = ~provlab, design = ## design, : Direct estimates appear to be proportions. You may want to consider ## using transform = 'logit'.  summer.FH.table <- data.frame(   Domain = sae.DIR$Domain,   Median = summer.FH$iid.model.est$median,   SE = sqrt(summer.FH$iid.model.est$var) ) head(summer.FH.table) ##     Domain     Median         SE ## 1    Alava 0.23449184 0.03704801 ## 2 Albacete 0.15383656 0.02760217 ## 3 Alicante 0.20385758 0.02104621 ## 4  Almeria 0.24485689 0.03331238 ## 5    Avila 0.07516739 0.02379961 ## 6  Badajoz 0.20959769 0.02128758 par(mfrow = c(1, 2)) plot(sae.DIR$Direct, sae.FH$est$eblup,      xlab = \"Direct estimates\",ylab = \"sae package\",      xlim=c(min(sae.DIR$Direct, sae.FH$est$eblup),max(sae.DIR$Direct, sae.FH$est$eblup)),      ylim=c(min(sae.DIR$Direct, sae.FH$est$eblup),max(sae.DIR$Direct, sae.FH$est$eblup)),      main = \"Small area estimates\") abline(0,1,col=\"red\") plot(sae.DIR$SD^2, sae.FH$mse,      xlab = \"Direct estimates\",ylab = \"sae package\",      xlim=c(min(sae.DIR$SD^2, sae.FH$mse),max(sae.DIR$SD^2, sae.FH$mse)),      ylim=c(min(sae.DIR$SD^2, sae.FH$mse),max(sae.DIR$SD^2, sae.FH$mse)),      main = \"Estimates of uncertainty\") abline(0,1,col=\"red\") par(mfrow = c(1, 2)) plot(sae.FH$est$eblup, summer.FH$iid.model.est$median,      xlab = \"sae package\",ylab = \"SUMMER package\",      main = \"Small area estimates\") abline(0,1,col=\"red\") plot(sae.FH$mse,      summer.FH$iid.model.est$var,       xlab = \"sae package mse\",      ylab = \"SUMMER package model variance\",      main = \"Estimates of mse/variance\") abline(0,1,col=\"red\")"},{"path":"https://richardli.github.io/SUMMER/articles/web_only/small-area-estimation.html","id":"spatial-fay-herriot","dir":"Articles > Web_only","previous_headings":"Area level models","what":"Spatial Fay-Herriot","title":"Generic small area estimation","text":"sae package also provides tools implementing spatial version Fay-Herriot model assumes vector area specific effects follows first order simultaneous autoregressive, SAR(1), process: \\[\\textbf{u}=\\rho_1\\textbf{Wu}+\\boldsymbol\\epsilon,\\hspace{1em}\\boldsymbol\\epsilon\\sim N(\\textbf{0}_i,\\sigma_I^2\\textbf{}_i),\\] \\(\\textbf{}_i\\) identity matrix \\(D\\) areas \\(\\textbf{0}_i\\) vector zeroes size \\(D\\). Additionally, \\(\\rho_1\\(-1,1)\\) autoregression parameter \\(\\textbf{W}\\) adjacency matrix (rows standardized sum 1). sae::mseSFH function estimates unknown variance parameters, resulting EBLUP small area estimators, uses bootstrap methods estimate MSE estimators. illustrate use function, Molina Marhuenda (2015) consider synthetic dataset concerning grape production surface area 274 Italian municipalities. load relevant objects sae package. grapes dataset containes direct estimators mean surface area hectares grape production municipality (grapehect), sampling variance direct estimators (var), relevant covariates including number working dats overall agrarian surface area. grapesprox object contains relevant adjacency matrix representing municipalities’ neighborhood structure.","code":"data(\"grapes\") data(\"grapesprox\")"},{"path":"https://richardli.github.io/SUMMER/articles/web_only/small-area-estimation.html","id":"results-using-sae","dir":"Articles > Web_only","previous_headings":"Area level models > Spatial Fay-Herriot","what":"Results using sae","title":"Generic small area estimation","text":"","code":"sae.FH.grapes <- sae::mseSFH(grapehect ~ area + workdays - 1, var, grapesprox, data = grapes)  results <- data.frame(DIR = grapes$grapehect,                       eblup.SFH = sae.FH.grapes$est$eblup,                       mse = sae.FH.grapes$mse) # reorder results for comparison later results$area_name <- paste0('area_', rownames(results))"},{"path":"https://richardli.github.io/SUMMER/articles/web_only/small-area-estimation.html","id":"results-using-summer","dir":"Articles > Web_only","previous_headings":"Area level models > Spatial Fay-Herriot","what":"Results using SUMMER","title":"Generic small area estimation","text":"smoothArea function also allows use model spatially correlated area effects, default implementation assumes BYM2 model \\(\\textbf{u}\\) rather simultaneous autoregressive model SFH model implemented sae. Despite differing models, observe good agreement estimates, though less estimates uncertainty.","code":"# create area_name as SUMMER requires rownames of adj.mat to match area variable grapes$area_name <- paste0('area_', rownames(grapes)) ## Error in eval(expr, envir, enclos): object 'grapes' not found adj.mat.grapes <- as.matrix(grapesprox) ## Error in h(simpleError(msg, call)): error in evaluating the argument 'x' in selecting a method for function 'as.matrix': object 'grapesprox' not found rownames(adj.mat.grapes) <- colnames(adj.mat.grapes) <- grapes$area_name ## Error in eval(expr, envir, enclos): object 'grapes' not found X_grapes <- grapes[,c('area_name', 'area', 'workdays')] ## Error in eval(expr, envir, enclos): object 'grapes' not found # format direct estimates for SUMMER grapes.dir <- grapes[, c(5, 1, 4)] ## Error in eval(expr, envir, enclos): object 'grapes' not found # scale direct estimates for use with INLA grapes.dir$grapehect <- grapes.dir$grapehect / 10 ## Error in eval(expr, envir, enclos): object 'grapes.dir' not found grapes.dir$var <- grapes.dir$var/ 100 ## Error in eval(expr, envir, enclos): object 'grapes.dir' not found summer.FH.grapes <- smoothArea(formula = grapehect~area + workdays,                                 direct.est = grapes.dir, X.domain = X_grapes,                                domain = ~area_name, adj.mat = adj.mat.grapes) ## Error in eval(expr, envir, enclos): object 'grapes.dir' not found plot_list <- plot(summer.FH.grapes, return_list = T) ## Error in h(simpleError(msg, call)): error in evaluating the argument 'x' in selecting a method for function 'plot': object 'summer.FH.grapes' not found summer.bym2.est <-    summer.FH.grapes$bym2.model.est[match(rownames(adj.mat.grapes), summer.FH.grapes$bym2.model.est$domain),] ## Error in eval(expr, envir, enclos): object 'summer.FH.grapes' not found par(mfrow = c(1, 2)) plot(results$eblup.SFH,      summer.bym2.est$median * 10,        xlab = \"sae package\",      ylab = \"SUMMER package\",      main = \"Small area estimates\") ## Error in h(simpleError(msg, call)): error in evaluating the argument 'y' in selecting a method for function 'plot': object 'summer.bym2.est' not found abline(0, 1, col = 'red') ## Error in int_abline(a = a, b = b, h = h, v = v, untf = untf, ...): plot.new has not been called yet plot(results$mse,      summer.bym2.est$var * 100,        xlab = \"sae package mse\",      ylab = \"SUMMER package model variance\",      main = \"Estimates of mse/variance\") ## Error in h(simpleError(msg, call)): error in evaluating the argument 'y' in selecting a method for function 'plot': object 'summer.bym2.est' not found abline(0, 1, col = 'red') ## Error in int_abline(a = a, b = b, h = h, v = v, untf = untf, ...): plot.new has not been called yet"},{"path":"https://richardli.github.io/SUMMER/articles/web_only/small-area-estimation.html","id":"brfss-data","dir":"Articles > Web_only","previous_headings":"Area level models > Spatial Fay-Herriot","what":"BRFSS Data","title":"Generic small area estimation","text":", provide example comparing spatial models sae SUMMER using data Behavioral Risk Factor Surveillance System (BRFSS).","code":"library(ggplot2) library(patchwork) data(BRFSS) data(KingCounty) BRFSS <- subset(BRFSS, !is.na(BRFSS$diab2)) BRFSS <- subset(BRFSS, !is.na(BRFSS$hracode)) head(BRFSS) ##   age pracex       educau zipcode    sex street1 street2      seqno year ## 1  30  White college grad   98001   male      NA      NA 2009000041 2009 ## 2  26  White college grad   98107 female      NA      NA 2009000309 2009 ## 3  33  Black college grad   98133   male      NA      NA 2009000404 2009 ## 4  25  White some college   98058   male      NA      NA 2009000531 2009 ## 5  23  White some college   98102   male      NA      NA 2009000675 2009 ## 6  19  Asian some college   98106   male      NA      NA 2009000694 2009 ##   hispanic mracex strata             hracode tract rwt_llcp genhlth2 fmd obese ## 1 non-Hisp  White  53019        Auburn-North    NA 2107.463        0   0     0 ## 2 non-Hisp  White  53019             Ballard    NA 2197.322        0   1     0 ## 3 non-Hisp  Black  53019          NW Seattle    NA 3086.511        0   0     0 ## 4 non-Hisp  White  53019        Renton-South    NA 3184.740        1   1     1 ## 5 non-Hisp  White  53019 Capitol Hill/E.lake    NA 3184.740        0   0     0 ## 6 non-Hisp  Asian  53019      North Highline    NA 4391.304        0   0     0 ##   smoker1 diab2 aceindx2 zipout streetx ethn age4 ctmiss ## 1       0     0       NA  98001       0    1    3      1 ## 2       0     0       NA  98107       0    1    3      1 ## 3       0     0       NA  98133       0    2    3      1 ## 4       0     0       NA  98058       0    1    3      1 ## 5       0     0       NA  98102       0    1    4      1 ## 6       0     0       NA  98106       0    3    4      1 mat <- getAmat(KingCounty, KingCounty$HRA2010v2_) design <- svydesign(ids = ~1, weights = ~rwt_llcp,                     strata = ~strata, data = BRFSS) direct <- svyby(~diab2, ~hracode, design, svymean)"},{"path":"https://richardli.github.io/SUMMER/articles/web_only/small-area-estimation.html","id":"results-using-sae-1","dir":"Articles > Web_only","previous_headings":"Area level models > Spatial Fay-Herriot > BRFSS Data","what":"Results using sae","title":"Generic small area estimation","text":", use sae smooth logit-transformed direct estimates.","code":"direct$var <- direct$se ^ 2 direct$logit.diab2 <- SUMMER::logit(direct$diab2) direct$logit.var <- direct$var / (direct$diab2 ^ 2 * (1 - direct$diab2) ^ 2) SFH.brfss <- sae::mseSFH(logit.diab2 ~ 1, logit.var, mat, data = direct)  results <- data.frame(domain = direct$hracode,                       eblup.SFH = SUMMER::expit(SFH.brfss$est$eblup),                        mse = SFH.brfss$mse)"},{"path":"https://richardli.github.io/SUMMER/articles/web_only/small-area-estimation.html","id":"results-using-summer-1","dir":"Articles > Web_only","previous_headings":"Area level models > Spatial Fay-Herriot > BRFSS Data","what":"Results using SUMMER","title":"Generic small area estimation","text":", fit two versions spatial area levelmodel SUMMER. change pc.u pc.alpha default value \\(u=1,\\alpha=0.01\\) \\(u=0.1,\\alpha=0.01\\), assign prior mass smaller variance random effects, inducing smoothing. Finally, use SUMMER::mapPlot compare median estimates uncertainty estimates obtained via sae SUMMER.","code":"summer.brfss <- smoothArea(diab2~1, domain= ~hracode,                            design = design,                            transform = \"logit\",                            adj.mat = mat, level = 0.95) summer.brfss.alt <- smoothArea(diab2~1, domain= ~hracode,                                design = design,                                transform = \"logit\",                                adj.mat = mat, level = 0.95,                                pc.u = 0.1, pc.alpha = 0.01) toplot <-  summer.brfss$bym2.model.est toplot$logit.var <- toplot$var /    (summer.brfss$bym2.model.est$median ^ 2 *       (1 - summer.brfss$bym2.model.est$median) ^ 2) toplot$median.alt <-  summer.brfss.alt$bym2.model.est$median toplot$logit.var.alt <-  summer.brfss.alt$bym2.model.est$var /    (summer.brfss.alt$bym2.model.est$median ^ 2 *      (1 - summer.brfss.alt$bym2.model.est$median) ^ 2) toplot$median.sae <- results$eblup.SFH toplot$mse.sae <- results$mse variables <- c(\"median\", \"median.alt\",  \"median.sae\",                \"logit.var\", \"logit.var.alt\", \"mse.sae\") names <- c(\"Median (default prior)\", \"Median (new prior)\",  \"EBLUP (sae)\",            \"Variance (default prior)\", \"Variance (new prior)\", \"MSE (sae)\") mapPlot(data = toplot, geo = KingCounty,         variables=variables[1:3],          labels = names[1:3], by.data = \"domain\",         by.geo = \"HRA2010v2_\", size = 0.1) mapPlot(data = toplot, geo = KingCounty,         variables=variables[4:6], labels = names[4:6],         by.data = \"domain\", by.geo = \"HRA2010v2_\", size = 0.1) par(mfrow = c(1, 2)) range1 <- range(c(direct$diab2,toplot$median.alt)) plot(direct$diab2,toplot$median,        xlab = \"direct estimates\",      ylab = \"model-based estimates\",      main = \"Small area estimates\", col = 'red', pch = 16,      xlim=range1,ylim=range1) points(direct$diab2,toplot$median.sae,  col = 'blue', pch = 16) points(direct$diab2,toplot$median.alt,  col = 'cyan', pch = 16) legend('topleft', pch = 16, col = c('red', 'cyan', 'blue'),         legend = c(\"SUMMER\",'SUMMER (new prior)', \"sae\"),bty=\"n\") abline(0,1) range2 <- range(c(direct$logit.var,toplot$mse.sae,toplot$logit.var.alt)) plot(direct$logit.var,toplot$logit.var,        xlab = \"direct estimate var.\",      ylab = \"model-based uncertainty\",      main = \"Small area estimates\", col = 'red', pch = 16,       xlim=range2,ylim=range2) points(direct$logit.var,toplot$mse.sae,  col = 'blue', pch = 16) points(direct$logit.var,toplot$logit.var.alt,  col = 'cyan', pch = 16) legend('topleft', pch = 16, col = c('red', 'cyan','blue'),        legend = c(\"SUMMER var.\", 'SUMMER var. (new prior)', \"sae mse\"),bty=\"n\") abline(0,1)"},{"path":"https://richardli.github.io/SUMMER/articles/web_only/small-area-estimation.html","id":"unit-level-models","dir":"Articles > Web_only","previous_headings":"","what":"Unit Level Models","title":"Generic small area estimation","text":"nested error model, introduced Battese, Harter, Fuller (1988), uses auxiliary data unit level. Nested error model: \\[y_{dk}=\\mathbf{x}_{dk}^T\\boldsymbol\\beta+u_d+\\epsilon_{dk},\\hspace{1em}u_d\\sim_{ind}N(0,\\sigma_u^2),\\hspace{1em}\\epsilon_{dk}\\sim_{ind}N(0,\\sigma_\\epsilon^2)\\] \\(u_d\\) area random effects \\(\\epsilon_{dk}\\) unit level errors. model assumes sampling design ignorable. sae package conducts estimation domain means first estimating variance parameters \\(\\sigma^2_u\\) \\(\\sigma^2_\\epsilon\\). Next, given known variance parameters, domain means \\(\\theta_d\\) predicted calculating EBLUPs. area fitted values : \\[\\widehat{y}_d^{\\text{EBLUP}} = f_d \\overline{y}_{dS} + (\\overline{X}_d-f_d \\overline{x}_{dS})\\widehat{\\beta} + (1-f_d)\\widehat{u}_d,\\] \\(f_d=n_d/N_d\\) domain sampling fraction. \\(\\overline{y}_{dS}\\) mean response sampled units. \\(\\overline{x}_{dS}\\) mean covariates sampled units. \\(\\overline{X}_d\\) mean covariates population. \\(\\widehat{u}_d\\) estimated random effect.","code":""},{"path":"https://richardli.github.io/SUMMER/articles/web_only/small-area-estimation.html","id":"corn-and-soy-production","dir":"Articles > Web_only","previous_headings":"Unit Level Models","what":"Corn and Soy Production","title":"Generic small area estimation","text":"cornsoybean cornsoybeanmeans datasets contain info corn soy beans production 12 Iowa counties Battese, Harter, Fuller (1988). objective use satellite imagery number pixels assigned corn soy estimate hectares grown corn. SampSegments: sample size. PopnSegments: population size. MeanCornPixPerSeg: county mean number corn pixels (satellite imagery). MeanSoyBeansPixPerSeg county mean number soy beans (satellite imagery) pixels. variables MeanCornPixPerSeg MeanSoyBeansPixPerSeg provide known county means auxiliary variables. load sample data: Next, load population auxiliary information: sae::pbmseBHF function obtains EBLUPs nested error model uses parametric bootstrap approach estimate MSEs. SUMMER::smoothUnit provides ability fit unit level models unit level covariates Gaussian response variables. use .unit argument specify unit level model provide column names unit level covariates X.unit. Finally, X argument provides area level means covariate use generating predictions. Note order align SUMMER estimates sae package, specify relatively flat prior variance area-specific random effect (pc.u = 100, pc.alpha = 0.01 specifies penalized complexity prior \\(P(\\sigma_u > 100)=0.01\\) \\(\\sigma_u\\) standard deviation area-specific random effects). , plot comparisons sae SUMMER results.","code":"data(\"cornsoybean\") head(cornsoybean) ##   County CornHec SoyBeansHec CornPix SoyBeansPix ## 1      1  165.76        8.09     374          55 ## 2      2   96.32      106.03     209         218 ## 3      3   76.08      103.60     253         250 ## 4      4  185.35        6.47     432          96 ## 5      4  116.43       63.82     367         178 ## 6      5  162.08       43.50     361         137 data(\"cornsoybeanmeans\") Xmean <-   data.frame(cornsoybeanmeans[, c(\"CountyIndex\",                                   \"MeanCornPixPerSeg\",                                   \"MeanSoyBeansPixPerSeg\")]) head(Xmean) ##   CountyIndex MeanCornPixPerSeg MeanSoyBeansPixPerSeg ## 1           1            295.29                189.70 ## 2           2            300.40                196.65 ## 3           3            289.60                205.28 ## 4           4            290.74                220.22 ## 5           5            318.21                188.06 ## 6           6            257.17                247.13 Popn <-   data.frame(cornsoybeanmeans[, c(\"CountyIndex\",                                   \"PopnSegments\")]) head(Popn) ##   CountyIndex PopnSegments ## 1           1          545 ## 2           2          566 ## 3           3          394 ## 4           4          424 ## 5           5          564 ## 6           6          570 cornsoybean <- cornsoybean[-33, ] # remove outlier sae.bhf <-    pbmseBHF(CornHec ~ CornPix + SoyBeansPix,            dom = County, meanxpop = Xmean,            popnsize = Popn, B = 200,             data = cornsoybean) cornsoybean$id <- 1:dim(cornsoybean)[1] Xsummer <- Xmean colnames(Xsummer) = c(\"County\", \"CornPix\", \"SoyBeansPix\") des0 <- svydesign(ids = ~1, data = cornsoybean) ## Warning in svydesign.default(ids = ~1, data = cornsoybean): No weights or ## probabilities supplied, assuming equal probability summer.bhf.unit <- smoothUnit(formula = CornHec ~ CornPix + SoyBeansPix,                               family = \"gaussian\",                               domain = ~County,                               design = des0, X.pop = Xsummer,                               pc.u = 1000, pc.alpha = 0.01, level = 0.95) ## Warning in smoothUnit(formula = CornHec ~ CornPix + SoyBeansPix, family = ## \"gaussian\", : No spatial information provided, using iid domain effects par(mfrow = c(1, 2)) range1 <- range(c(sae.bhf$est$eblup$eblup,summer.bhf.unit$median)) plot(sae.bhf$est$eblup$eblup,summer.bhf.unit$iid.model.est$median,        xlab = \"sae package\",      ylab = \"SUMMER unit-level model package\",      main = \"Small area estimates\",      xlim=range1,ylim=range1) abline(0,1) range2 <- range(c(sae.bhf$mse$mse, summer.bhf.unit$var)) plot(sae.bhf$mse$mse, summer.bhf.unit$iid.model.est$var,        xlab = \"sae package mse\",      ylab = \"SUMMER unit-level model package model variance\",      main = \"Estimates of mse/variance\",      xlim=range2,ylim=range2) abline(0,1)"},{"path":"https://richardli.github.io/SUMMER/articles/web_only/u5mr-dhs-vignette.html","id":"pre-processing-the-data","dir":"Articles > Web_only","previous_headings":"","what":"Pre-processing the data","title":"Case Study: Estimating Subnational U5MR using DHS data","text":"First, load package necessary data. INLA standard repository, check available install installed. vignette, used INLA version 20.03.17. DHS data can obtained DHS program website https://dhsprogram.com/data/dataset/Kenya_Standard-DHS_2014. analysis U5MR, use Births Recode .dta format. Notice registration DHS program required order access dataset. show two ways read files. One option download DHS birth record data corresponding shapefiles website save local directory. can load packages readstata13. Another option use rdhs package. allows users download DHS datasets directly within R session. first look DHS surveys Kenya. download 2014 Kenya DHS data. Notice first time users, DHS key required registering DHS website rdhs package. use haven package read birth record file downloaded zip folder make region variable v024 factors. map files DHS can freely downloaded https://spatialdata.dhsprogram.com/boundaries/. load downloaded shapefile using sf package. also generates spatial adjacency matrix Amat using function getAmat(). Amat matrix encodes spatial adjacency matrix 8 Admin-1 region groups, column row names matching regions used map. adjacency matrix used spatial smoothing model. can also created hand necessary.","code":"library(SUMMER) library(ggplot2) library(patchwork) library(rdhs) library(haven) library(sf) library(readstata13) filename <- \"data/KEBR71DT/KEBR71FL.DTA\" births <- read.dta13(filename, generate.factors = TRUE) sv <- dhs_surveys(countryIds = \"KE\", surveyType = \"DHS\") sv[, c(\"SurveyId\", \"FieldworkStart\", \"FieldworkEnd\")] ##    SurveyId FieldworkStart FieldworkEnd ## 1 KE1989DHS     1988-12-01   1989-05-01 ## 2 KE1993DHS     1993-02-01   1993-08-01 ## 3 KE1998DHS     1998-02-01   1998-07-01 ## 4 KE2003DHS     2003-04-01   2003-09-01 ## 5 KE2008DHS     2008-11-01   2009-02-01 ## 6 KE2014DHS     2014-05-01   2014-10-01 ## 7 KE2022DHS     2022-02-01   2022-07-01 BR <- dhs_datasets(surveyIds = sv$SurveyId[6], fileFormat = \"STATA\", fileType = \"BR\") BRfiles <- get_datasets(BR$FileName, reformat = TRUE, download_option = \"zip\") BRfiles ## $KEBR72DT ## [1] \"~/Library/Caches/rdhs/datasets_reformatted/KEBR72DT.ZIP\" ##  ## attr(,\"reformat\") ## [1] TRUE births <- read_dta(unz(BRfiles[[1]], \"KEBR72FL.DTA\")) births$v024 <- as_factor(births$v024) births$b5 <- as_factor(births$b5) mapfilename <- \"data/shps/sdr_subnational_boundaries.shp\" sf_use_s2(FALSE) geo <- read_sf(mapfilename) Amat <- getAmat(geo, geo$REGNAME)"},{"path":[]},{"path":"https://richardli.github.io/SUMMER/articles/web_only/u5mr-dhs-vignette.html","id":"prepare-person-month-data","dir":"Articles > Web_only","previous_headings":"Bayesian space-time smoothing of direct estimates","what":"Prepare person-month data","title":"Case Study: Estimating Subnational U5MR using DHS data","text":"first demonstrate method smooths direct estimates subnational-level U5MR. analysis, consider \\(8\\) Admin-1 region groups. order calculate direct estimates U5MR, need full birth history data format every row corresponds birth columns contain: Indicators corresponding survey design, e.g., strata (v023), cluster (v001), household (v002) Survey weight (v025) Date interview century month codes (CMC) format, .e., number month since beginning 1900 (v008) Date child’s birth CMC format (b3) Indicator death child (b5) Age death child months (b7) birth history data DHS already form getBirths function default use current recode manual column names (indicated ). name fields can defined explicitly function arguments . reorganize data ‘person-month’ format getBirths function reorder columns better readability. Notice DHS reports age years children 2 years old. Thus b7 variable contains ages mostly multiples 12 24 months. truncation adjusted age.truncate = 24 argument, adds 5 months age children records least 24 months old age multiples 12. also specify surveyyear argument remove observations fall time periods 2014, exist adjusted dataset. Notice also need specify time intervals interest. example, calculate predict U5MR 5-year intervals 1985-1990 2015-2019. U5MR, use discrete survival model calculate direct estimates region time. step involves breaking age death discrete intervals. default option assumes discrete survival model six discrete hazards (probabilities dying particular interval, given survival start interval) age bands: \\([0,1), [1,12), [12,24), [24,36), [36,48)\\), \\([48,60]\\). may also calculate types mortality rates interest using getBirths. example, U1MR, smoothing steps can similarly carried .","code":"dat <- getBirths(data = births, strata = c(\"v023\"), surveyyear = 2014, year.cut = seq(1985,     2020, by = 5)) dat <- dat[, c(\"v001\", \"v002\", \"v024\", \"time\", \"age\", \"v005\", \"strata\", \"died\")] colnames(dat) <- c(\"clustid\", \"id\", \"region\", \"time\", \"age\", \"weights\", \"strata\",     \"died\") head(dat) ##   clustid id  region  time  age weights strata died ## 1       1  6 nairobi 05-09    0 5476381      1    0 ## 2       1  6 nairobi 05-09 1-11 5476381      1    0 ## 3       1  6 nairobi 05-09 1-11 5476381      1    0 ## 4       1  6 nairobi 05-09 1-11 5476381      1    0 ## 5       1  6 nairobi 05-09 1-11 5476381      1    0 ## 6       1  6 nairobi 05-09 1-11 5476381      1    0 dat_infant = getBirths(data = births, surveyyear = 2014, month.cut = c(1, 12), strata = c(\"v023\"))"},{"path":"https://richardli.github.io/SUMMER/articles/web_only/u5mr-dhs-vignette.html","id":"horvitz-thompson-estimators-of-u5mr","dir":"Articles > Web_only","previous_headings":"Bayesian space-time smoothing of direct estimates","what":"Horvitz-Thompson estimators of U5MR","title":"Case Study: Estimating Subnational U5MR using DHS data","text":"Using person-month format data, can calculate Horvitz-Thompson estimators using getDirect single survey getDirectList multiple surveys. discrete hazards time interval estimated using logistic regression model, weighting account survey design. direct estimates calculated using discrete hazards. order correctly account survey design, need specify stratification cluster variables. Kenya DHS example, two-stage stratified cluster sampling design used, strata specified strata column, clusters specified cluster ID (clusterid) household ID (id).","code":"years <- levels(dat$time) direct0 <- getDirect(births = dat, years = years, regionVar = \"region\", timeVar = \"time\",     clusterVar = \"~clustid + id\", ageVar = \"age\", weightsVar = \"weights\") head(direct0) ##   region years  mean lower upper logit.est var.est survey logit.prec ## 1    All 85-89 0.093 0.079 0.109      -2.3  0.0082     NA        122 ## 2    All 90-94 0.098 0.089 0.109      -2.2  0.0033     NA        306 ## 3    All 95-99 0.088 0.081 0.097      -2.3  0.0024     NA        409 ## 4    All 00-04 0.078 0.072 0.084      -2.5  0.0016     NA        630 ## 5    All 05-09 0.059 0.054 0.064      -2.8  0.0020     NA        506 ## 6    All 10-14 0.051 0.047 0.056      -2.9  0.0021     NA        472"},{"path":"https://richardli.github.io/SUMMER/articles/web_only/u5mr-dhs-vignette.html","id":"adjustments-using-external-information","dir":"Articles > Web_only","previous_headings":"Bayesian space-time smoothing of direct estimates","what":"Adjustments using external information","title":"Case Study: Estimating Subnational U5MR using DHS data","text":"Sometimes additional information available adjust direct estimates surveys. example, countries high prevalence HIV, estimates U5MR can biased, particularly ART treatment became widely available. Pre-treatment HIV positive women high risk dying, women given birth therefore less likely appear surveys. children HIV positive women also likely higher probability dying compared born HIV negative women. Thus expect U5MR underestimated adjust missing women. Suppose can obtain ratio reported U5MR true U5MR, \\(r_{}\\), region \\(\\) time period \\(t\\), can apply adjustment factor direct estimates associated variances. HIV adjustment factors calculated 2014 Kenya DHS survey included package.","code":"data(KenData) direct <- getAdjusted(data = direct0, ratio = KenData$HIV2014, logit.lower = NA,     logit.upper = NA, prob.lower = \"lower\", prob.upper = \"upper\")"},{"path":"https://richardli.github.io/SUMMER/articles/web_only/u5mr-dhs-vignette.html","id":"national-estimates-of-u5mr","dir":"Articles > Web_only","previous_headings":"Bayesian space-time smoothing of direct estimates","what":"National estimates of U5MR","title":"Case Study: Estimating Subnational U5MR using DHS data","text":"direct estimates calculated using getDirect contains national estimates subnational estimates \\(8\\) regions, \\(6\\) time periods projection period 2015-2019. first fit model temporal random effects smooth national estimates time. part, use subset data region variable “”. can fit Random Walk 2 model defined 5-year period. can also estimate Random Walk 2 random effects yearly scale. marginal posteriors already stored fitted object. use following function extract re-arrange . can compare results visually. Notice correctly display period estimates, reference year period needs specified. simply take median year period.  national model also allows us benchmark estimates using published national results. example, take 2019 UN-IGME estimates find median -5 mortality rates periods. can calculate ratio estimates national models published UN estimates. use adjustment ratio correct bias direct estimates. organize adjustment ratios matrix two columns, since adjustment factor varies time. can perform benchmarking UN estimates similar HIV adjustment . benchmarking, can fit smoothing model adjusted direct estimates, see align UN estimates.","code":"fit1 <- smoothDirect(data = direct, Amat = NULL, year_label = years, year_range = c(1985,     2019), time.model = \"rw2\", m = 1) fit2 <- smoothDirect(data = direct, Amat = NULL, year_label = years, year_range = c(1985,     2019), time.model = \"rw2\", m = 5) out1 <- getSmoothed(fit1) out2 <- getSmoothed(fit2) years.ref <- c(1987, 1992, 1997, 2002, 2007, 2012, 2017) g1 <- plot(out1, year_med = years.ref) + ggtitle(\"National period model\") + ylim(c(0,     0.17)) g2 <- plot(out2, year_med = years.ref) + ggtitle(\"National yearly model\") + ylim(c(0,     0.17)) g1 + g2 data(KenData) UN <- KenData$IGME2019 UN.period <- data.frame(period = c(\"85-89\", \"90-94\", \"95-99\", \"00-04\", \"05-09\", \"10-14\"),     median = NA) for (i in 1:6) {     UN.period$median[i] <- median(UN$mean[which(UN$years %in% (c(1985:1989) + (i -         1) * 5))]) } ratio <- subset(out1, region == \"All\")$median[1:6]/UN.period$median print(ratio) ## [1] 0.98 0.95 0.91 0.95 0.92 1.00 benchmark <- data.frame(years = c(\"85-89\", \"90-94\", \"95-99\", \"00-04\", \"05-09\", \"10-14\"),     ratio = ratio) direct <- getAdjusted(data = direct, ratio = benchmark, time = \"years\", region = \"region\",     est = \"mean\", logit.lower = \"logit.lower\", logit.upper = \"logit.upper\") fit2.benchmark <- smoothDirect(data = direct, Amat = NULL, year_label = years, year_range = c(1985,     2019), time.model = \"rw2\", m = 5) out2.benchmark <- getSmoothed(fit2.benchmark)  g1 <- plot(out2, year_label = years, year_med = years.ref, data.add = UN, option.add = list(point = \"mean\"),     label.add = \"UN\", color.add = \"orange\") + ggtitle(\"National yearly model: original\") +     ylim(c(0, 0.17)) g2 <- plot(out2.benchmark, year_label = years, year_med = years.ref, data.add = UN,     option.add = list(point = \"mean\"), label.add = \"UN\", color.add = \"orange\") +     ggtitle(\"National yearly model: benchmarked\") + ylim(c(0, 0.17)) g1 + g2"},{"path":"https://richardli.github.io/SUMMER/articles/web_only/u5mr-dhs-vignette.html","id":"subnational-estimates-of-u5mr","dir":"Articles > Web_only","previous_headings":"Bayesian space-time smoothing of direct estimates","what":"Subnational estimates of U5MR","title":"Case Study: Estimating Subnational U5MR using DHS data","text":"syntax fit subnational smoothing model similar. Similar national model, can choose estimate temporal random effects either yearly period level. can also choose four types space-time interaction terms using st.type argument. default hyper priors precision random effects now PC priors. Similarly can also estimate Random Walk 2 random effects yearly scale.  can also add back direct estimates comparison.  can show estimates time maps. revert color scale higher mortality represented darker colors.  order also illustrate uncertainties estimates presented maps, can use hatching indicate width 94% posterior credible intervals.","code":"fit3 <- smoothDirect(data = direct, Amat = Amat, year_label = years, year_range = c(1985,     2019), time.model = \"rw2\", type.st = 4, m = 1) out3 <- getSmoothed(fit3) fit4 <- smoothDirect(data = direct, Amat = Amat, year_label = years, year_range = c(1985,     2019), time.model = \"rw2\", type.st = 4, m = 5) out4 <- getSmoothed(fit4)  g1 <- plot(out3) + ggtitle(\"Subnational period model\") + ylim(c(0, 0.3)) g2 <- plot(out4) + ggtitle(\"Subnational yearly model\") + ylim(c(0, 0.3)) g1 + g2 plot(out4, data.add = direct, option.add = list(point = \"mean\", by = \"survey\")) +     facet_wrap(~region, scales = \"free\") mapPlot(data = subset(out4, is.yearly == FALSE), geo = geo, variables = \"years\",     values = \"median\", by.data = \"region\", by.geo = \"REGNAME\", is.long = TRUE, ncol = 4,     direction = -1, legend.label = \"U5MR\", per1000 = TRUE) hatchPlot(data = subset(out4, is.yearly == FALSE), geo = geo, variables = \"years\",     values = \"median\", by.data = \"region\", by.geo = \"REGNAME\", lower = \"lower\", upper = \"upper\",     is.long = TRUE, direction = -1, legend.label = \"U5MR\", per1000 = TRUE, ncol = 4)"},{"path":"https://richardli.github.io/SUMMER/articles/web_only/u5mr-dhs-vignette.html","id":"comparing-different-models","dir":"Articles > Web_only","previous_headings":"","what":"Comparing different models","title":"Case Study: Estimating Subnational U5MR using DHS data","text":"section, compare models different prior setup. focus subnational models yearly temporal resolution. use random walk order 2 model main temporal trend, compare different priors space-time interaction term. consider random walk order 1 2, PC priors \\(U = 1, 5\\). can seen RW2 interaction, region specific U5MR allowed follow trends regulation slopes. hand, RW1 interaction stays constant observation periods ends instead following region-specific trends. can seen clearly interaction effect plots end. posterior sensitive choice \\(U\\).","code":"index <- 1 f.list <- NULL est.list <- NULL for (model in c(\"rw1\", \"rw2\")) {     for (u in c(1, 5)) {         f <- smoothDirect(data = direct, Amat = Amat, year_range = c(1985, 2019),             year_label = years, time.model = \"rw2\", st.time.model = model, m = 5,             type.st = 4, pc.st.u = u, pc.st.alpha = 0.01)         f.list[[index]] <- f         out <- getSmoothed(f)         out$st.model <- model         out$st.u <- paste(\"U =\", u)         est.list <- rbind(est.list, out)         index <- index + 1     } } plot(est.list, plot.CI = TRUE) + facet_grid(st.model ~ st.u)"},{"path":"https://richardli.github.io/SUMMER/articles/web_only/u5mr-vignette.html","id":"load-data","dir":"Articles > Web_only","previous_headings":"","what":"Load Data","title":"Estimating Subnational U5MR using Simulated Data","text":"first load package data. use dplyr package data processing steps, ggplot2 patchwork visualization. DemoData contains model survey data provided DHS. Note data simulated represent real country’s data. DemoData obtained processing raw DHS birth data (.dta format) R. raw file birth recodes can downloaded DHS website https://dhsprogram.com/data/Download-Model-Datasets.cfm. demo dataset, registration needed. real DHS survey datasets, permission access needs registered DHS directly. DemoData contains small sample observations dataset randomly assigned \\(5\\) example DHS surveys. details, following code snippet demonstrates split raw demo data person-month format similar DemoData object. Notice read file early version stata, package readstata13 required. following script based example dataset ZZBR62FL.DTA available DHS website. use interaction v024 v025 strata indicator purpose demonstration. can see range(data$v008) CMC code date interview corresponds year 1900 + floor(1386/12)= 2015. practice, however, survey year usually known. survey year variable allows mis-recorded data. Dates surveyyear removed. Thus survey taking place multiple years, later year suggested used surveyyear. set NA checking performed. Back pre-processed dataset, DemoData list \\(5\\) data frames row represent one person-month record contains \\(8\\) variables shown . Notice time variable turned 5-year bins 80-84 10-14. demonstration purpose, associate regions simulated dataset example map stored DemoMap object SUMMER package. DemoMap contains geographic data 1995 Uganda Admin 1 regions defined DHS. contains SpatialPolygonsDataFrame object geo corresponding spatial adjacency matrix mat. spatial adjacency matrix can also created directly SpatialPolygonsDataFrame Finally, details pipeline downloading processing raw DHS data shapefiles can found vignette Case Study Estimating Subnational U5MR using DHS data.","code":"library(SUMMER) data(DemoData) library(dplyr) library(ggplot2) library(patchwork) library(readstata13) my_fp <- \"data/ZZBR62DT/ZZBR62FL.DTA\" dat <- getBirths(filepath = my_fp, surveyyear = 2015, strata = c(\"v024\", \"v025\")) dat <- dat[, c(\"v001\", \"v002\", \"v024\", \"per5\", \"ageGrpD\", \"v005\", \"strata\", \"died\")] colnames(dat) <- c(\"clustid\", \"id\", \"region\", \"time\", \"age\", \"weights\", \"strata\",     \"died\") summary(DemoData) ##      Length Class      Mode ## 1999 8      data.frame list ## 2003 8      data.frame list ## 2007 8      data.frame list ## 2011 8      data.frame list ## 2015 8      data.frame list head(DemoData[[1]]) ##   clustid id  region  time  age weights        strata died ## 1       1  1 eastern 00-04    0     1.1 eastern.rural    0 ## 2       1  1 eastern 00-04 1-11     1.1 eastern.rural    0 ## 3       1  1 eastern 00-04 1-11     1.1 eastern.rural    0 ## 4       1  1 eastern 00-04 1-11     1.1 eastern.rural    0 ## 5       1  1 eastern 00-04 1-11     1.1 eastern.rural    0 ## 6       1  1 eastern 00-04 1-11     1.1 eastern.rural    0 data(DemoMap) geo <- DemoMap$geo mat <- DemoMap$Amat mat <- getAmat(geo, geo$REGNAME)"},{"path":"https://richardli.github.io/SUMMER/articles/web_only/u5mr-vignette.html","id":"direct-estimates","dir":"Articles > Web_only","previous_headings":"","what":"Direct estimates","title":"Estimating Subnational U5MR using Simulated Data","text":"First, obtain Horvitz-Thompson estimators using getDirectList. specify survey design two-stage stratified cluster sampling strata specified strata column, clusters specified cluster ID (clusterid) household ID (id). fitting model, also aggregate estimates based different surveys single set estimates, using inverse design-based variances weights.","code":"years <- levels(DemoData[[1]]$time) data_multi <- getDirectList(births = DemoData, years = years, regionVar = \"region\",     timeVar = \"time\", clusterVar = \"~clustid+id\", ageVar = \"age\", weightsVar = \"weights\",     geo.recode = NULL) dim(data_multi) ## [1] 150  10 data <- aggregateSurvey(data_multi) dim(data) ## [1] 30 10"},{"path":[]},{"path":"https://richardli.github.io/SUMMER/articles/web_only/u5mr-vignette.html","id":"national-estimates-of-u5mr","dir":"Articles > Web_only","previous_headings":"Area-level model for U5MR","what":"National estimates of U5MR","title":"Estimating Subnational U5MR using Simulated Data","text":"combined direct estimates, ready fit smoothing models described Li et al. (2019). First, ignore subnational estimates, fit model temporal random effects . part, use subset data region variable “”. fitting model, first define list time periods wish project estimates . First can fit Random Walk 2 model defined 5-year period. argument m = 1 specifies random walk temporal resolution input data. See next example case random walk model specified higher resolution. data sparse, direct estimates yearly level may unstable. used 5-year periods model’s temporal resolution example. performing temporal smoothing, however, can define temporal smoother yearly scale instead. Notice direct estimates still calculated 5-year intervals, smoothed estimator now produce estimates yearly period resolutions. marginal posteriors already stored fitted object. use following function extract re-arrange . can compare results visually using function .","code":"years.all <- c(years, \"15-19\") fit1 <- smoothDirect(data = data, Amat = NULL, year_label = years.all, year_range = c(1985,     2019), time.model = \"rw2\", m = 1) ## ---------------------------------- ## Smoothed Direct Model ##   Main temporal model:        rw2 ##   Number of time periods:     35 ##   Temporal resolution:        period model (m = 1) ## ---------------------------------- summary(fit1) ## ---------------------------------- ## Smoothed Direct Model ##   Main temporal model:        rw2 ##   Number of time periods:     35 ##   Temporal resolution:        period model (m = 1) ## ---------------------------------- ## Fixed Effects ##             mean    sd 0.025quant 0.5quant 0.97quant mode kld ## (Intercept) -1.4 0.081       -1.6     -1.4      -1.3 -1.4   0 ## ---------------------------------- ## Random Effects ##            Name     Model ## 1   time.struct RW2 model ## 2 time.unstruct IID model ## ---------------------------------- ## Model hyperparameters ##                             mean   sd 0.025quant 0.5quant 0.97quant mode ## Precision for time.struct   1212 9510        5.4      140      6882  9.8 ## Precision for time.unstruct 1191 6732       11.2      207      6959 23.3 ## NULL ##                                       [,1] ## log marginal-likelihood (integration) -2.1 ## log marginal-likelihood (Gaussian)    -1.9 fit2 <- smoothDirect(data = data, Amat = NULL, year_label = years.all, year_range = c(1985,     2019), time.model = \"rw2\", m = 5, type.st = 4) ## ---------------------------------- ## Smoothed Direct Model ##   Main temporal model:        rw2 ##   Number of time periods:     35 ##   Temporal resolution:        yearly model (m = 5) ## ---------------------------------- summary(fit2) ## ---------------------------------- ## Smoothed Direct Model ##   Main temporal model:        rw2 ##   Number of time periods:     35 ##   Temporal resolution:        yearly model (m = 5) ## ---------------------------------- ## Fixed Effects ##             mean    sd 0.025quant 0.5quant 0.97quant mode kld ## (Intercept) -1.4 0.074       -1.6     -1.4      -1.3 -1.4   0 ## ---------------------------------- ## Random Effects ##            Name     Model ## 1   time.struct RGeneric2 ## 2 time.unstruct RGeneric2 ## ---------------------------------- ## Model hyperparameters ##                          mean  sd 0.025quant 0.5quant 0.97quant mode ## Theta1 for time.struct    5.0 1.9        1.6      5.0       8.8  4.6 ## Theta1 for time.unstruct  4.3 1.8        1.1      4.2       7.8  3.9 ## NULL ##                                       [,1] ## log marginal-likelihood (integration)  -75 ## log marginal-likelihood (Gaussian)     -75 out1 <- getSmoothed(fit1) out2 <- getSmoothed(fit2) g1 <- plot(out1) + ggtitle(\"National period model\") g2 <- plot(out2) + ggtitle(\"National yearly model\") g1 + g2"},{"path":"https://richardli.github.io/SUMMER/articles/web_only/u5mr-vignette.html","id":"subnational-estimates-of-u5mr","dir":"Articles > Web_only","previous_headings":"Area-level model for U5MR","what":"Subnational estimates of U5MR","title":"Estimating Subnational U5MR using Simulated Data","text":"Now fit full model subnational regions. First, use Random Walk 2 model defined 5-year period. Similarly can also estimate Random Walk 2 random effects yearly scale. figures shows comparison subnational model different temporal scales.  can also add back direct estimates comparison plotting smoothed estimates.  Finally, show estimates time maps.","code":"fit3 <- smoothDirect(data = data, Amat = mat, year_label = years.all, year_range = c(1985,     2019), time.model = \"rw2\", m = 1, type.st = 4) ## ---------------------------------- ## Smoothed Direct Model ##   Main temporal model:        rw2 ##   Number of time periods:     35 ##   Temporal resolution:        period model (m = 1) ##   Spatial effect:             bym2 ##   Number of regions:          4 ##   Interaction temporal model: rw2 ##   Interaction type:           4 ## ---------------------------------- out3 <- getSmoothed(fit3) fit4 <- smoothDirect(data = data, Amat = mat, year_label = years.all, year_range = c(1985,     2019), time.model = \"rw2\", m = 5, type.st = 4) ## ---------------------------------- ## Smoothed Direct Model ##   Main temporal model:        rw2 ##   Number of time periods:     35 ##   Temporal resolution:        yearly model (m = 5) ##   Spatial effect:             bym2 ##   Number of regions:          4 ##   Interaction temporal model: rw2 ##   Interaction type:           4 ## ---------------------------------- out4 <- getSmoothed(fit4) g1 <- plot(out3, is.yearly = FALSE) + ggtitle(\"Subnational period model\") g2 <- plot(out4, is.yearly = TRUE) + ggtitle(\"Subnational yearly model\") g1 + g2 plot(out4, is.yearly = TRUE, data.add = data_multi, option.add = list(point = \"mean\",     by = \"surveyYears\")) + facet_wrap(~region, scales = \"free\") mapPlot(data = subset(out4, is.yearly == F), geo = DemoMap$geo, variables = c(\"years\"),     values = c(\"median\"), by.data = \"region\", by.geo = \"NAME_final\", is.long = TRUE,     ncol = 4)"},{"path":"https://richardli.github.io/SUMMER/articles/web_only/u5mr-vignette.html","id":"cluster-level-model-for-u5mr","dir":"Articles > Web_only","previous_headings":"","what":"Cluster-level model for U5MR","title":"Estimating Subnational U5MR using Simulated Data","text":"now describe fitting cluster-level model U5MR described Martin et al. (2020) Fuglstad, Li, Wakefield (2021). simulated dataset, strata variable coded region crossed urban/rural status. analysis urban/rural stratified model, first construct new strata variable contains urban/rural status, .e., additional stratification within region. fit cluster-level model, calculate number person-months number deaths cluster, time period, age group. first create data frame using getCounts function survey combine single data frame. model fitting function smoothCluster expects columns specific names. rename cluster ID time period columns ‘cluster’ ‘years’. response variable ‘Y’ binomial total ‘total’. created data frame, fit cluster-level model using smoothCluster function. Notice need specify age groups (age.groups), length age group (age.n) months, age groups mapped temporal random effects (age.rw.group). default case, age.rw.group = c(1, 2, 3, 3, 3, 3) means first two age groups temporal trend, following four age groups share temporal trend. start default temporal model random walk order 2 5-year periods dataset (real data, can use finer temporal resolution). space-time interaction, use AR(1) prior (specified st.time.model) interacting spatial ICAR prior, random linear trends area (specified pc.st.slope.u pc.st.slope.alpha). add survey iid effects model well using survey.effect = TRUE argument. temporal main effects defined stratum separately (specified strata.time.effect = TRUE, total six random walks used model main temporal effect. example, bias adjustment simple model. ratio adjustments U5MR known, entered bias.adj bias.adj.arguments fitting model. Posterior samples model taken summarized using getSmoothed function. models large number areas time points, step may take time compute. save.draws argument makes possible save raw posterior draws, can use functions recompute different posterior credible intervals. example, recompute posterior CI directly using existing draws:","code":"for (i in 1:length(DemoData)) {     strata <- DemoData[[i]]$strata     DemoData[[i]]$strata[grep(\"urban\", strata)] <- \"urban\"     DemoData[[i]]$strata[grep(\"rural\", strata)] <- \"rural\" } counts.all <- NULL for (i in 1:length(DemoData)) {     vars <- c(\"clustid\", \"region\", \"strata\", \"time\", \"age\")     counts <- getCounts(DemoData[[i]][, c(vars, \"died\")], variables = \"died\", by = vars,         drop = TRUE)     counts <- counts %>%         mutate(cluster = clustid, years = time, Y = died)     counts$survey <- names(DemoData)[i]     counts.all <- rbind(counts.all, counts) } periods <- c(\"85-89\", \"90-94\", \"95-99\", \"00-04\", \"05-09\", \"10-14\") fit.bb  <- smoothCluster(data = counts.all, Amat = DemoMap$Amat,                      family = \"betabinomial\",                     year_label = c(periods, \"15-19\"),                      age.groups = c(\"0\", \"1-11\", \"12-23\", \"24-35\", \"36-47\", \"48-59\"),                     age.n = c(1, 11, 12, 12, 12, 12),                     age.rw.group = c(1, 2, 3, 3, 3, 3),                     time.model = \"rw2\",                     st.time.model = \"ar1\",                     pc.st.slope.u = 1, pc.st.slope.alpha = 0.01,                     survey.effect = TRUE,                      strata.time.effect = TRUE) ## Argument 'age.rw.group' have been deprecated and replaced by 'age.time.group' in version 1.4.0. The value for 'age.time.group' has been set to be the input argument 'age.rw.group' ## ---------------------------------- ## Cluster-level model ##   Main temporal model:        rw2 ##   Number of time periods:     7 ##   Spatial effect:             bym2 ##   Number of regions:          4 ##   Interaction temporal model: ar1 ##   Interaction type:           4 ##   Interaction random slopes:  yes ##   Number of age groups: 6 ##   Stratification: yes ##   Number of age-specific fixed effect intercept per stratum: 6 ##   Number of age-specific trends per stratum: 3 ##   Strata-specific temporal trends: yes ##   Survey effect: yes ## ---------------------------------- summary(fit.bb) ## ---------------------------------- ## Cluster-level model ##   Main temporal model:        rw2 ##   Number of time periods:     7 ##   Spatial effect:             bym2 ##   Number of regions:          4 ##   Interaction temporal model: ar1 ##   Interaction type:           4 ##   Interaction random slopes:  yes ##   Number of age groups: 6 ##   Stratification: yes ##   Number of age group fixed effect intercept per stratum: 6 ##   Number of age-specific trends per stratum: 3 ##   Strata-specific temporal trends: yes ##   Survey effect: yes ## ---------------------------------- ## Fixed Effects ##                          mean   sd 0.025quant 0.5quant 0.97quant mode kld ## age.intercept0:rural     -3.0 0.14       -3.3     -3.0      -2.7 -3.0   0 ## age.intercept1-11:rural  -4.7 0.11       -4.9     -4.7      -4.5 -4.7   0 ## age.intercept12-23:rural -5.8 0.14       -6.1     -5.8      -5.5 -5.8   0 ## age.intercept24-35:rural -6.6 0.20       -6.9     -6.6      -6.2 -6.6   0 ## age.intercept36-47:rural -6.9 0.23       -7.3     -6.9      -6.4 -6.9   0 ## age.intercept48-59:rural -7.3 0.29       -7.9     -7.3      -6.8 -7.3   0 ## age.intercept0:urban     -2.7 0.13       -3.0     -2.7      -2.5 -2.7   0 ## age.intercept1-11:urban  -5.0 0.13       -5.2     -5.0      -4.7 -5.0   0 ## age.intercept12-23:urban -5.7 0.17       -6.1     -5.7      -5.4 -5.7   0 ## age.intercept24-35:urban -7.1 0.28       -7.6     -7.1      -6.5 -7.1   0 ## age.intercept36-47:urban -7.6 0.37       -8.3     -7.6      -6.9 -7.6   0 ## age.intercept48-59:urban -8.0 0.46       -8.9     -8.0      -7.1 -8.0   0 ##  ## Slope fixed effect index: ## time.slope.group1: 0:rural ## time.slope.group2: 1-11:rural ## time.slope.group3: 12-23:rural, 24-35:rural, 36-47:rural, 48-59:rural ## time.slope.group4: 0:urban ## time.slope.group5: 1-11:urban ## time.slope.group6: 12-23:urban, 24-35:urban, 36-47:urban, 48-59:urban ## ---------------------------------- ## Random Effects ##            Name             Model ## 1   time.struct         RW2 model ## 2 time.unstruct         IID model ## 3 region.struct        BYM2 model ## 4    region.int Besags ICAR model ## 5   st.slope.id         IID model ## 6     survey.id         IID model ## ---------------------------------- ## Model hyperparameters ##                                                     mean       sd 0.025quant ## overdispersion for the betabinomial observations   0.002    0.001      0.001 ## Precision for time.struct                         89.127  107.545     11.587 ## Precision for time.unstruct                      835.404 3162.330     13.344 ## Precision for region.struct                      362.694 1178.564      7.304 ## Phi for region.struct                              0.347    0.237      0.029 ## Precision for region.int                         662.287 2901.332      6.107 ## Group PACF1 for region.int                         0.898    0.190      0.304 ## Precision for st.slope.id                        106.781  393.439      1.313 ##                                                  0.5quant 0.97quant   mode ## overdispersion for the betabinomial observations    0.002     0.005  0.002 ## Precision for time.struct                          57.308   338.863 27.622 ## Precision for time.unstruct                       219.625  4806.292 28.959 ## Precision for region.struct                       109.650  2037.244 16.380 ## Phi for region.struct                               0.300     0.844  0.088 ## Precision for region.int                          146.979  3888.536 11.031 ## Group PACF1 for region.int                          0.971     1.000  1.000 ## Precision for st.slope.id                          27.986   615.455  2.528 ## NULL ##                                        [,1] ## log marginal-likelihood (integration) -3454 ## log marginal-likelihood (Gaussian)    -3449 est.bb <- getSmoothed(fit.bb, nsim = 1000, CI = 0.95, save.draws = TRUE) summary(est.bb) ## --------------------------------------------- ## Stratified estimates stored in ...$stratified ## Aggregated estimates stored in ...$overall ## --------------------------------------------- ## Estimates computed for 7 time period(s) and 4 area(s) ## No strata weights has been supplied. Overall estimates are not calculated. ## Posterior draws are saved in the output. You can use 'getSmoothed(..., draws = ...$draws)' next time to speed up the call. ## 1000 posterior draws taken. est.bb.90CI <- getSmoothed(fit.bb, nsim = 1000, CI = 0.95, draws = est.bb$draws)"},{"path":"https://richardli.github.io/SUMMER/articles/web_only/u5mr-vignette.html","id":"aggregation-across-strata","dir":"Articles > Web_only","previous_headings":"Cluster-level model for U5MR","what":"Aggregation across strata","title":"Estimating Subnational U5MR using Simulated Data","text":"est.bb object computes U5MR estimates urban/rural strata. order obtain overall region-specific U5MR, need additional information population fractions stratum within regions. demonstration, simulate population totals years order compute aggregated estimates, need proportion urban/rural populations within region time period. Now can recompute smoothed estimates population fractions. can compare stratum-specific aggregated U5MR estimates now.","code":"pop.base <- expand.grid(region = c(\"central\", \"eastern\", \"northern\", \"western\"),     strata = c(\"urban\", \"rural\")) pop.base$population <- round(runif(dim(pop.base)[1], 1000, 20000)) periods.all <- c(periods, \"15-19\") pop <- NULL for (i in 1:length(periods.all)) {     tmp <- pop.base     tmp$population <- pop.base$population + round(rnorm(dim(pop.base)[1], mean = 0,         sd = 200))     tmp$years <- periods.all[i]     pop <- rbind(pop, tmp) } head(pop) ##     region strata population years ## 1  central  urban      16641 85-89 ## 2  eastern  urban       2662 85-89 ## 3 northern  urban       4307 85-89 ## 4  western  urban      13222 85-89 ## 5  central  rural      16821 85-89 ## 6  eastern  rural      17979 85-89 weight.strata <- expand.grid(region = c(\"central\", \"eastern\", \"northern\", \"western\"),     years = periods.all) weight.strata$urban <- weight.strata$rural <- NA for (i in 1:dim(weight.strata)[1]) {     which.u <- which(pop$region == weight.strata$region[i] & pop$years == weight.strata$years[i] &         pop$strata == \"urban\")     which.r <- which(pop$region == weight.strata$region[i] & pop$years == weight.strata$years[i] &         pop$strata == \"rural\")     weight.strata[i, \"urban\"] <- pop$population[which.u]/(pop$population[which.u] +         pop$population[which.r])     weight.strata[i, \"rural\"] <- 1 - weight.strata[i, \"urban\"] } head(weight.strata) ##     region years rural urban ## 1  central 85-89  0.50  0.50 ## 2  eastern 85-89  0.87  0.13 ## 3 northern 85-89  0.37  0.63 ## 4  western 85-89  0.36  0.64 ## 5  central 90-94  0.51  0.49 ## 6  eastern 90-94  0.87  0.13 est.bb <- getSmoothed(fit.bb, nsim = 1000, CI = 0.95, save.draws = TRUE, weight.strata = weight.strata) head(est.bb$overall) ##    region years time area variance median mean upper lower rural urban ## 5 central 85-89    1    1  0.00116   0.23 0.23  0.30  0.17  0.50  0.50 ## 6 central 90-94    2    1  0.00047   0.21 0.21  0.26  0.17  0.51  0.49 ## 7 central 95-99    3    1  0.00027   0.19 0.19  0.23  0.16  0.50  0.50 ## 1 central 00-04    4    1  0.00023   0.18 0.18  0.21  0.15  0.51  0.49 ## 2 central 05-09    5    1  0.00021   0.17 0.17  0.20  0.14  0.50  0.50 ## 3 central 10-14    6    1  0.00030   0.15 0.15  0.18  0.12  0.50  0.50 ##   is.yearly years.num ## 5     FALSE        NA ## 6     FALSE        NA ## 7     FALSE        NA ## 1     FALSE        NA ## 2     FALSE        NA ## 3     FALSE        NA g1 <- plot(est.bb$stratified, plot.CI = TRUE) + facet_wrap(~strata) + ylim(0, 0.5) g2 <- plot(est.bb$overall, plot.CI = TRUE) + ylim(0, 0.5) + ggtitle(\"Aggregated estimates\") g1 + g2"},{"path":"https://richardli.github.io/SUMMER/articles/web_only/u5mr-vignette.html","id":"visualizations","dir":"Articles > Web_only","previous_headings":"","what":"Visualizations","title":"Estimating Subnational U5MR using Simulated Data","text":"extensive visualization tools package. can add hatching map visualizations indicate uncertainty estimates using hatchPlot similar syntax.  Next show posterior densities estimates, panel correspond one time period, regions ordered posterior median estimates last year (specified order = -1 argument).  can also plotted region time well.","code":"hatchPlot(est.bb$overall,            geo = DemoMap$geo, by.data = \"region\", by.geo = \"REGNAME\",          is.long = TRUE, variables = \"years\", values = \"median\",          lower = \"lower\", upper = \"upper\", hatch = \"red\",         ncol = 4, direction = -1, per1000 = TRUE, legend.label = \"U5MR\") ridgePlot(draws = est.bb, year_plot = periods.all,                   ncol = 4, per1000 = TRUE, order = -1, direction = -1) ridgePlot(draws = est.bb, year_plot = periods.all,                   ncol = 4, per1000 = TRUE, by.year = FALSE, direction = -1)"},{"path":"https://richardli.github.io/SUMMER/articles/web_only/u5mr-vignette.html","id":"benchmarking-to-external-information","dir":"Articles > Web_only","previous_headings":"Visualizations","what":"Benchmarking to external information","title":"Estimating Subnational U5MR using Simulated Data","text":"external estimates available national level, may want subnational estimates aggregate national estimates internal validation purposes. Methods benchmark national mean estimates proposed literature. vignette Case Study Estimating Subnational U5MR using DHS data demonstrates approach described Li et al. (2019) area-level model. bias.adj argument smoothCluster() function allows one adjust estimates benchmarking ratio known, using approximation methods described Wakefield et al. (2019). refer readers package document details. demonstrate post-processing method described Okonek Wakefield (2022). additional advantage mean uncertainty national estimates accounted benchmarking process. demonstrate function, first simulate national estimates. realistic simulation, reuse national direct estimates add constant bias term. assume estimates external source. Thus expect estimates benchmarking larger general. order perform benchmarking process, need proportion population region time periods. can compute simulated population . perform benchmarking procedure using Benchmark function Since benchmarking procedure based rejection sampler, number posterior draws accepted benchmarking can small, example. recommend increasing number draws first, .e., can compare posterior median variance benchmarking.  sanity check, can compute simple weighted average posterior median regions form set rough national estimates. can seen benchmarked estimates indeed higher closer simulated national estimates benchmarked .","code":"national <- data.frame(years = periods.all, est = out1$median + 0.01, sd = runif(7,     0.01, 0.03)) head(national) ##   years  est    sd ## 1 85-89 0.24 0.020 ## 2 90-94 0.23 0.012 ## 3 95-99 0.21 0.025 ## 4 00-04 0.22 0.023 ## 5 05-09 0.20 0.018 ## 6 10-14 0.17 0.025 weight.region <- expand.grid(region = c(\"central\", \"eastern\", \"northern\", \"western\"),     years = periods.all) weight.region$proportion <- NA for (i in 1:dim(weight.region)[1]) {     which <- which(pop$region == weight.strata$region[i] & pop$years == weight.strata$years[i])     which.year <- which(pop$years == weight.strata$years[i])     weight.region[i, \"proportion\"] <- sum(pop$population[which])/sum(pop$population[which.year]) } head(weight.region) ##     region years proportion ## 1  central 85-89      0.410 ## 2  eastern 85-89      0.253 ## 3 northern 85-89      0.084 ## 4  western 85-89      0.253 ## 5  central 90-94      0.413 ## 6  eastern 90-94      0.256 est.bb.bench <- Benchmark(est.bb, national, weight.region = weight.region, estVar = \"est\",     sdVar = \"sd\", timeVar = \"years\") est.bb <- getSmoothed(fit.bb, nsim = 20000, CI = 0.95, save.draws = TRUE, weight.strata = weight.strata) est.bb.bench <- Benchmark(est.bb, national, weight.region = weight.region, estVar = \"est\",     sdVar = \"sd\", timeVar = \"years\") par(mfrow = c(1, 2)) plot(est.bb$overall$median, est.bb.bench$overall$median, xlab = \"Before benchmarking\",     ylab = \"After benchmarking\", main = \"Posterior median\") abline(c(0, 1)) plot(est.bb$overall$variance, est.bb.bench$overall$variance, xlab = \"Before benchmarking\",     ylab = \"After benchmarking\", main = \"Posterior variance\") abline(c(0, 1)) compare <- national compare$before <- NA compare$after <- NA for (i in 1:dim(compare)[1]) {     weights <- subset(weight.region, years == national$years[i])     sub <- subset(est.bb$overall, years == national$years[i])     sub <- merge(sub, weights)     sub.bench <- subset(est.bb.bench$overall, years == national$years[i])     sub.bench <- merge(sub.bench, weights)     compare$before[i] <- sum(sub$proportion * sub$median)     compare$after[i] <- sum(sub.bench$proportion * sub.bench$median) } plot(compare$est, compare$after, col = 2, pch = 10, xlim = range(c(compare$est, compare$before,     compare$after)), ylim = range(c(compare$est, compare$before, compare$after)),     xlab = \"External national estimates\", ylab = \"Weighted posterior median after benchmarking\",     main = \"Sanity check: compare weighted average of area medians to benchmark\") points(compare$est, compare$before) abline(c(0, 1)) legend(\"topleft\", c(\"Before benchmarking\", \"After benchmarking\"), pch = c(1, 10),     col = c(1, 2))"},{"path":[]},{"path":"https://richardli.github.io/SUMMER/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Zehang R Li. Maintainer, author. Bryan D Martin. Author. Yuan Hsiao. Author. Jessica Godwin. Author. John Paige. Author. Peter Gao. Author. Jon Wakefield. Author. Samuel J Clark. Author. Geir-Arne Fuglstad. Author. Andrea Riebler. Author.","code":""},{"path":"https://richardli.github.io/SUMMER/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Li Z, Martin B, Hsiao Y, Godwin J, Paige J, Gao P, Wakefield J, Clark S, Fuglstad G, Riebler (2024). SUMMER: Small-Area-Estimation Unit/Area Models Methods Estimation R. R package version 1.4.1,  https://richardli.github.io/SUMMER/, https://github.com/richardli/SUMMER.","code":"@Manual{,   title = {SUMMER: Small-Area-Estimation Unit/Area Models and Methods for Estimation in R},   author = {Zehang R Li and Bryan D Martin and Yuan Hsiao and Jessica Godwin and John Paige and Peter Gao and Jon Wakefield and Samuel J Clark and Geir-Arne Fuglstad and Andrea Riebler},   year = {2024},   note = {R package version 1.4.1,  https://richardli.github.io/SUMMER/},   url = {https://github.com/richardli/SUMMER}, }"},{"path":"https://richardli.github.io/SUMMER/index.html","id":"summer-","dir":"","previous_headings":"","what":"Small-Area-Estimation Unit/Area Models and Methods for Estimation in R","title":"Small-Area-Estimation Unit/Area Models and Methods for Estimation in R","text":"SAE Unit/area Models Methods Estimation R","code":""},{"path":"https://richardli.github.io/SUMMER/index.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"Small-Area-Estimation Unit/Area Models and Methods for Estimation in R","text":"SUMMER R package providing extensive collection space-time smoothing small area estimation methods prevalence estimation using complex survey data, special focus Demographic Health Surveys (DHS) data, estimation child mortality using full birth history data. package also provides collection plotting functions visualize estimates space time.","code":""},{"path":"https://richardli.github.io/SUMMER/index.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Small-Area-Estimation Unit/Area Models and Methods for Estimation in R","text":"cite SUMMER package publications use cite specific version SUMMER package use + v1.0.0 earlier versions (e.g., v0.3.0)","code":"@Manual{li2020space,     title = {Space-Time Smoothing of Demographic and Health Indicators using the R Package SUMMER},     author = {Zehang R Li and Bryan D Martin and Tracy Q Dong and Geir-Arne Fuglstad and Jessica Godwin and John Paige and Andrea Riebler and Samuel Clark and Jon Wakefield},     year = {2020},     journal = {arXiv preprint}   } @Manual{summer2020,     title = {SUMMER: Spatio-Temporal Under-Five Mortality Methods for Estimation},     author = {Zehang R Li and Bryan D Martin and Yuan Hsiao and Jessica Godwin and Jon Wakefield and Samuel J Clark and Geir-Arne Fuglstad and Andrea Riebler},     year = {2020},     note = {R package version 1.0.0},   } @Manual{summer2019,     title = {SUMMER: Spatio-Temporal Under-Five Mortality Methods for Estimation},     author = {Bryan D Martin and Zehang R Li and Yuan Hsiao and Jessica Godwin and Jon Wakefield and Samuel J Clark and Geir-Arne Fuglstad and Andrea Riebler},     year = {2019},     note = {R package version 0.3.0},   }"},{"path":"https://richardli.github.io/SUMMER/index.html","id":"installation---cran","dir":"","previous_headings":"","what":"Installation - CRAN","title":"Small-Area-Estimation Unit/Area Models and Methods for Estimation in R","text":"package now available CRAN. easiest way download install directly using code .","code":"install.packages(\"SUMMER\")"},{"path":"https://richardli.github.io/SUMMER/index.html","id":"installation---development-version","dir":"","previous_headings":"","what":"Installation - Development Version","title":"Small-Area-Estimation Unit/Area Models and Methods for Estimation in R","text":"download development version SUMMER package, use code . Examples main functions described several vignettes listed https://cran.r-project.org/package=SUMMER.","code":"# install.packages(\"devtools\") devtools::install_github(\"richardli/SUMMER\")"},{"path":"https://richardli.github.io/SUMMER/index.html","id":"bug-reports--change-requests","dir":"","previous_headings":"Installation - Development Version","what":"Bug Reports / Change Requests","title":"Small-Area-Estimation Unit/Area Models and Methods for Estimation in R","text":"encounter bug like make change request, please file issue .","code":""},{"path":"https://richardli.github.io/SUMMER/reference/BRFSS.html","id":null,"dir":"Reference","previous_headings":"","what":"The BRFSS dataset — BRFSS","title":"The BRFSS dataset — BRFSS","text":"Behavioral Risk Factor Surveillance System (BRFSS) annual telephone health survey conducted Centers Disease Control Prevention (CDC) tracks health conditions risk behaviors United States territories since 1984. BRFSS dataset contains 16124 observations. `diab2` variable binary indicator Type II diabetes, `strata` strata indicator `rwt_llcp` final design weight. Records missing HRA code diabetes status removed dataset. See https://www.cdc.gov/brfss/annual_data/2013/pdf/Weighting_Data.pdf details weighting procedure.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/BRFSS.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The BRFSS dataset — BRFSS","text":"","code":"data(BRFSS)"},{"path":"https://richardli.github.io/SUMMER/reference/BRFSS.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"The BRFSS dataset — BRFSS","text":"data.frame 26 variables.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/BRFSS.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"The BRFSS dataset — BRFSS","text":"Washington State Department Health, Center Health Statistics. Behavioral Risk Factor Surveillance System, supported part Centers Disease Control Prevention. Corporative Agreement U58/DP006066-01 (2015).","code":""},{"path":"https://richardli.github.io/SUMMER/reference/Benchmark.html","id":null,"dir":"Reference","previous_headings":"","what":"Benchmark posterior draws to national estimates — Benchmark","title":"Benchmark posterior draws to national estimates — Benchmark","text":"Benchmark posterior draws national estimates","code":""},{"path":"https://richardli.github.io/SUMMER/reference/Benchmark.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Benchmark posterior draws to national estimates — Benchmark","text":"","code":"Benchmark(   fitted,   national,   estVar,   sdVar,   timeVar = NULL,   weight.region = NULL,   method = c(\"MH\", \"Rejection\")[2] )"},{"path":"https://richardli.github.io/SUMMER/reference/Benchmark.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Benchmark posterior draws to national estimates — Benchmark","text":"fitted output getSmoothed benchmarked. national data frame national level estimates benchmarked , least two columns indicating national estimates (probability scale) associated standard error. benchmarking multiple time period, third column indicating time period needed. estVar column name national indicates national estimates. sdVar column name national indicates standard errors national estimates. timeVar column name national indicates time periods. weight.region data frame column `region` specifying subnational regions, column `proportion` specifies proportion population region. multiple time periods exist, third column `years` required population proportions population proportions region corresponding time period. method string denoting algorithm use benchmarking. Options include `MH` Metropolis-Hastings, `Rejection` rejection sampler. Defaults `Rejection`.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/Benchmark.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Benchmark posterior draws to national estimates — Benchmark","text":"Benchmarked object S3 class SUMMERproj SUMMERprojlist format input object fitted.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/Benchmark.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Benchmark posterior draws to national estimates — Benchmark","text":"Taylor Okonek, Zehang Richard Li","code":""},{"path":"https://richardli.github.io/SUMMER/reference/Benchmark.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Benchmark posterior draws to national estimates — Benchmark","text":"","code":"if (FALSE) { ##  ------------------------------------------ ## ##     Benchmarking with smoothCluster output ##  ------------------------------------------ ##  data(DemoData) # fit unstratified cluster-level model counts.all <- NULL for(i in 1:length(DemoData)){ vars <- c(\"clustid\", \"region\", \"time\", \"age\") counts <- getCounts(DemoData[[i]][, c(vars, \"died\")],              variables = 'died',              by = vars, drop=TRUE) counts$cluster <- counts$clustid counts$years <- counts$time counts$Y <- counts$died counts$survey <- names(DemoData)[i]   counts.all <- rbind(counts.all, counts) } periods <- c(\"85-89\", \"90-94\", \"95-99\", \"00-04\", \"05-09\", \"10-14\", \"15-19\") fit.bb  <- smoothCluster(data = counts.all, Amat = DemoMap$Amat,          family = \"betabinomial\",         year_label = periods,          survey.effect = TRUE) est.bb <- getSmoothed(fit.bb, nsim = 1e4, CI = 0.95, save.draws=TRUE)  # construct a simple population weight data frame with equal weights weight.region <- expand.grid(region = unique(counts.all$region),               years = periods) weight.region$proportion <- 0.25  # construct a simple national estimates national <- data.frame(years = periods,             est = seq(0.27, 0.1, length = 7),             sd = runif(7, 0.01, 0.03))   # benchmarking est.bb.bench <- Benchmark(est.bb, national, weight.region = weight.region,              estVar = \"est\", sdVar = \"sd\", timeVar = \"years\")  # Sanity check: Benchmarking comparison compare <- national compare$before <- NA compare$after <- NA for(i in 1:dim(compare)[1]){   weights <- subset(weight.region, years == national$years[i])   sub <- subset(est.bb$overall, years == national$years[i])   sub <- merge(sub, weights)   sub.bench <- subset(est.bb.bench$overall, years == national$years[i])   sub.bench <- merge(sub.bench, weights)   compare$before[i] <- sum(sub$proportion * sub$median)   compare$after[i] <- sum(sub.bench$proportion * sub.bench$median) } plot(compare$est, compare$after, col = 2, pch = 10,      xlim = range(c(compare$est, compare$before, compare$after)),      ylim = range(c(compare$est, compare$before, compare$after)),      xlab = \"External national estimates\",       ylab = \"Weighted posterior median after benchmarking\",     main = \"Sanity check: weighted average of area medians\") points(compare$est, compare$before) abline(c(0, 1)) legend(\"topleft\", c(\"Before benchmarking\", \"After benchmarking\"), pch = c(1, 10), col = c(1, 2))  #  construct a simple national estimates national <- data.frame(years = periods,               est = seq(0.22, 0.1, length = 7),               sd = runif(7, 0.01, 0.03)) # national does not need to have all years national_sub <- national[1:3,]  # benchmarking est.bb.bench <- Benchmark(est.bb, national_sub,              weight.region = weight.region,              estVar = \"est\", sdVar = \"sd\", timeVar = \"years\")  # Sanity check: only benchmarked for three periods compare <- national compare$before <- NA compare$after <- NA for(i in 1:dim(compare)[1]){   weights <- subset(weight.region, years == national$years[i])   sub <- subset(est.bb$overall, years == national$years[i])   sub <- merge(sub, weights)   sub.bench <- subset(est.bb.bench$overall, years == national$years[i])   sub.bench <- merge(sub.bench, weights)   compare$before[i] <- sum(sub$proportion * sub$median)   compare$after[i] <- sum(sub.bench$proportion * sub.bench$median) } plot(compare$est, compare$after, col = 2, pch = 10,      xlim = range(c(compare$est, compare$before, compare$after)),      ylim = range(c(compare$est, compare$before, compare$after)),      xlab = \"External national estimates\",       ylab = \"Weighted posterior median after benchmarking\",     main = \"Sanity check: weighted average of area medians\") points(compare$est, compare$before) abline(c(0, 1)) legend(\"topleft\", c(\"Before benchmarking\", \"After benchmarking\"), pch = c(1, 10), col = c(1, 2))  #  Another extreme benchmarking example, where almost all weights in central region weight.region$proportion <- 0.01 weight.region$proportion[weight.region$region == \"central\"] <- 0.97 # benchmarking est.bb.bench <- Benchmark(est.bb, national, weight.region = weight.region,            estVar = \"est\", sdVar = \"sd\", timeVar = \"years\") # It can be seen the central region are pulled to the national benchmark plot(national$est,     subset(est.bb.bench$overall, region == \"central\")$mean,    col = 2, pch = 10, xlab = \"External national estimates\",     ylab = \"Central region estimates\")  points(national$est,     subset(est.bb$overall, region == \"central\")$mean)  legend(\"topleft\", c(\"Before benchmarking\", \"After benchmarking\"), pch = c(1, 10),  col = c(1, 2)) abline(c(0, 1))  # Example with the MH method # Benchmarking with MH should be applied when customized priors are  #  specified for fixed effects when fitting the model fit.bb.new  <- smoothCluster(data = counts.all, Amat = DemoMap$Amat,          family = \"betabinomial\",         year_label = periods,          survey.effect = TRUE,          control.fixed = list(           mean=list(`age.intercept0:1`=-4,                     `age.intercept1-11:1`=-5,                    `age.intercept12-23:1`=-8,                    `age.intercept24-35:1`=-9,                    `age.intercept36-47:1`=-10,                    `age.intercept48-59:1`=-11),            prec=list(`age.intercept0:1`=10,                     `age.intercept1-11:1`=10,                    `age.intercept12-23:1`=10,                    `age.intercept24-35:1`=10,                    `age.intercept36-47:1`=10,                    `age.intercept48-59:1`=10))) est.bb.new <- getSmoothed(fit.bb.new, nsim = 10000, CI = 0.95, save.draws=TRUE)  #  construct a simple national estimates national <- data.frame(years = periods,               est = seq(0.22, 0.1, length = 7),               sd = runif(7, 0.01, 0.03)) weight.region <- expand.grid(region = unique(counts.all$region),               years = periods) weight.region$proportion <- 0.25              est.bb.bench.MH <- Benchmark(est.bb.new, national,    weight.region = weight.region,    estVar = \"est\", sdVar = \"sd\", timeVar = \"years\",   method = \"MH\")  compare <- national compare$before <- NA compare$after <- NA for(i in 1:dim(compare)[1]){   weights <- subset(weight.region, years == national$years[i])   sub <- subset(est.bb.new$overall, years == national$years[i])   sub <- merge(sub, weights)   sub.bench <- subset(est.bb.bench.MH$overall, years == national$years[i])   sub.bench <- merge(sub.bench, weights)   compare$before[i] <- sum(sub$proportion * sub$median)   compare$after[i] <- sum(sub.bench$proportion * sub.bench$median) } plot(compare$est, compare$after, col = 2, pch = 10,      xlim = range(c(compare$est, compare$before, compare$after)),      ylim = range(c(compare$est, compare$before, compare$after)),      xlab = \"External national estimates\",       ylab = \"Weighted posterior median after benchmarking\",     main = \"Sanity check: weighted average of area medians\") points(compare$est, compare$before) abline(c(0, 1)) legend(\"topleft\", c(\"Before benchmarking\", \"After benchmarking\"), pch = c(1, 10), col = c(1, 2))  ##  ------------------------------------------ ## ##     Benchmarking with smoothDirect output ##  ------------------------------------------ ## years <- levels(DemoData[[1]]$time) # obtain direct estimates data_multi <- getDirectList(births = DemoData, years = years,                         regionVar = \"region\",  timeVar = \"time\", clusterVar = \"~clustid+id\",                         ageVar = \"age\", weightsVar = \"weights\", geo.recode = NULL) data <- aggregateSurvey(data_multi) #  subnational model years.all <- c(years, \"15-19\") fit2 <- smoothDirect(data = data, Amat = DemoMap$Amat,                  year_label = years.all, year_range = c(1985, 2019),                  time.model = \"rw2\", m = 5, type.st = 4) out2a <- getSmoothed(fit2, joint = TRUE, nsim = 1e5, save.draws = TRUE)  ## ## Benchmarking for yearly estimates ## weight.region <- expand.grid(region = unique(data$region[data$region != \"All\"]),                              years = 1985:2019) weight.region$proportion <- 0.25 # construct a simple national estimates national <- data.frame(years = 1985:2019,                        est = seq(0.25, 0.15, length = 35),                        sd = runif(35, 0.03, 0.05)) # Benchmarking to national estimates on the yearly scale out2b <- Benchmark(out2a, national, weight.region = weight.region,                           estVar = \"est\", sdVar = \"sd\", timeVar = \"years\") plot(out2a$overall)   plot(out2b$overall)   # combine the point estimate and compare with the benchmark values national.est <- aggregate(mean ~ years,     data = out2a$overall[out2a$overall$is.yearly, ], FUN = mean) national.est.bench <- aggregate(mean ~ years,     data = out2b$overall[out2b$overall$is.yearly, ], FUN = mean)  plot(national$est, national.est$mean,        xlim = range(c(national$est, national.est$mean, national.est.bench$mean)),      ylim = range(c(national$est, national.est$mean, national.est.bench$mean)),      xlab = \"External national estimates\",       ylab = \"Weighted posterior median after benchmarking\",     main = \"Sanity check: weighted average of area means\") points(national$est, national.est.bench$mean, col = 2, pch = 10) abline(c(0, 1)) legend(\"topleft\", c(\"Before benchmarking\", \"After benchmarking\"), pch = c(1, 10), col = c(1, 2))    ## ## Benchmarking for period estimates ## weight.region <- expand.grid(region = unique(data$region[data$region != \"All\"]),                              years = years.all) weight.region$proportion <- 0.25 # construct a simple national estimates national <- data.frame(years = years.all,                        est = seq(0.25, 0.15, len = 7),                        sd = runif(7, 0.01, 0.03)) # Benchmarking to national estimates on the period scale out2c <- Benchmark(out2a, national, weight.region = weight.region,                           estVar = \"est\", sdVar = \"sd\", timeVar = \"years\") plot(out2a$overall) plot(out2c$overall)  # combine the point estimate and compare with the benchmark values national.est <- aggregate(mean ~ years,        data = out2a$overall[!out2a$overall$is.yearly, ], FUN = mean) national.est.bench <- aggregate(mean ~ years,        data = out2c$overall[!out2b$overall$is.yearly, ], FUN = mean)  plot(national$est, national.est$mean,        xlim = range(c(national$est, national.est$mean, national.est.bench$mean)),      ylim = range(c(national$est, national.est$mean, national.est.bench$mean)),      xlab = \"External national estimates\",       ylab = \"Weighted posterior median after benchmarking\",     main = \"Sanity check: weighted average of area means\") points(national$est, national.est.bench$mean, col = 2, pch = 10) abline(c(0, 1)) legend(\"topleft\", c(\"Before benchmarking\", \"After benchmarking\"), pch = c(1, 10), col = c(1, 2))    }"},{"path":"https://richardli.github.io/SUMMER/reference/ChangeRegion.html","id":null,"dir":"Reference","previous_headings":"","what":"Map region names to a common set. — ChangeRegion","title":"Map region names to a common set. — ChangeRegion","text":"Map region names common set.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/ChangeRegion.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Map region names to a common set. — ChangeRegion","text":"","code":"ChangeRegion(data, Bmat, regionVar = \"region\")"},{"path":"https://richardli.github.io/SUMMER/reference/ChangeRegion.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Map region names to a common set. — ChangeRegion","text":"data Preprocessed data Bmat Matrix changes. row corresponds region name possibly data files, column corresponds region mapping. values matrix binary. row names column names need specified region names. regionVar String indicating region variable. Defaults 'region'.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/ChangeRegion.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Map region names to a common set. — ChangeRegion","text":"Data changing region names","code":""},{"path":"https://richardli.github.io/SUMMER/reference/ChangeRegion.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Map region names to a common set. — ChangeRegion","text":"Zehang Richard Li","code":""},{"path":"https://richardli.github.io/SUMMER/reference/ChangeRegion.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Map region names to a common set. — ChangeRegion","text":"","code":"# Construct a small test data testdata <- data.frame(region = c(\"north\", \"south\", \"east\",  \"south\", \"east\"), index = c(1:5))  # Construct a changing rule: combining south and east Bmat <- matrix(c(1, 0, 0, 0, 1, 1), 3, 2) colnames(Bmat) <- c(\"north\", \"south and east\") rownames(Bmat) <- c(\"north\", \"south\", \"east\") print(Bmat) #>       north south and east #> north     1              0 #> south     0              1 #> east      0              1  # New data after transformation test <- ChangeRegion(testdata, Bmat, \"region\") #> 2 names changed, in total 4 rows in data changed print(test) #>           region index #> 1          north     1 #> 2 south and east     2 #> 3 south and east     3 #> 4 south and east     4 #> 5 south and east     5"},{"path":"https://richardli.github.io/SUMMER/reference/DemoData.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulated child mortality person-month dataset. — DemoData","title":"Simulated child mortality person-month dataset. — DemoData","text":"small simulated dataset 4 regions 5 survey years.  represent  real country's data based subset model dataset provided DHS.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/DemoData.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulated child mortality person-month dataset. — DemoData","text":"","code":"data(DemoData)"},{"path":"https://richardli.github.io/SUMMER/reference/DemoData.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Simulated child mortality person-month dataset. — DemoData","text":"list five components, named survey year.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/DemoData.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Simulated child mortality person-month dataset. — DemoData","text":"https://dhsprogram.com/data/model-datasets.cfm","code":""},{"path":"https://richardli.github.io/SUMMER/reference/DemoData2.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulated dataset for prevalence mapping. — DemoData2","title":"Simulated dataset for prevalence mapping. — DemoData2","text":"small fake dataset 8 regions two response variables: age tobacco.use.  represent  real country's data based subset model dataset provided DHS.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/DemoData2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulated dataset for prevalence mapping. — DemoData2","text":"","code":"data(DemoData2)"},{"path":"https://richardli.github.io/SUMMER/reference/DemoData2.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Simulated dataset for prevalence mapping. — DemoData2","text":"data.frame 7 variables.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/DemoData2.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Simulated dataset for prevalence mapping. — DemoData2","text":"https://dhsprogram.com/data/model-datasets.cfm","code":""},{"path":"https://richardli.github.io/SUMMER/reference/DemoMap.html","id":null,"dir":"Reference","previous_headings":"","what":"Uganda Admin-1 region map for illustration purpose — DemoMap","title":"Uganda Admin-1 region map for illustration purpose — DemoMap","text":"Shapefiles 1995 Uganda Admin 1 regions provided DHS, data represent real information country.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/DemoMap.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Uganda Admin-1 region map for illustration purpose — DemoMap","text":"","code":"data(DemoMap)"},{"path":"https://richardli.github.io/SUMMER/reference/DemoMap.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Uganda Admin-1 region map for illustration purpose — DemoMap","text":"object class list length 2.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/DemoMap.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Uganda Admin-1 region map for illustration purpose — DemoMap","text":"https://spatialdata.dhsprogram.com/boundaries/#view=table&countryId=UG","code":""},{"path":"https://richardli.github.io/SUMMER/reference/DemoMap.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Uganda Admin-1 region map for illustration purpose — DemoMap","text":"geo. Geographic map files Amat. Adjacency matrix regions","code":""},{"path":"https://richardli.github.io/SUMMER/reference/DemoMap2.html","id":null,"dir":"Reference","previous_headings":"","what":"Kenya Admin-1 region map for illustration purpose — DemoMap2","title":"Kenya Admin-1 region map for illustration purpose — DemoMap2","text":"Shapefiles 2014 Kenya Admin 1 regions provided DHS.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/DemoMap2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Kenya Admin-1 region map for illustration purpose — DemoMap2","text":"","code":"data(DemoMap2)"},{"path":"https://richardli.github.io/SUMMER/reference/DemoMap2.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Kenya Admin-1 region map for illustration purpose — DemoMap2","text":"object class list length 2.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/DemoMap2.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Kenya Admin-1 region map for illustration purpose — DemoMap2","text":"https://spatialdata.dhsprogram.com/boundaries/#view=table&countryId=KE","code":""},{"path":"https://richardli.github.io/SUMMER/reference/DemoMap2.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Kenya Admin-1 region map for illustration purpose — DemoMap2","text":"geo Geographic map files Amat Adjacency matrix regions","code":""},{"path":"https://richardli.github.io/SUMMER/reference/KenData.html","id":null,"dir":"Reference","previous_headings":"","what":"Auxiliary data for Kenya 2014 DHS. — KenData","title":"Auxiliary data for Kenya 2014 DHS. — KenData","text":"list contains several data frames.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/KenData.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Auxiliary data for Kenya 2014 DHS. — KenData","text":"","code":"data(KenData)"},{"path":"https://richardli.github.io/SUMMER/reference/KenData.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Auxiliary data for Kenya 2014 DHS. — KenData","text":"object class list length 4.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/KenData.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Auxiliary data for Kenya 2014 DHS. — KenData","text":"HIV2014, data frame three columns: years (five year periods),  region (8 Admin-1 region groups), estimated bias reported U5MR due HIV 5 year period 1990-1994 2010-2014. bias represented ratio reported U5MR true U5MR. HIV2014.yearly, data frame three columns: years (one year interval),  region (8 Admin-1 region groups), estimated bias reported U5MR due HIV year 1980 2014. bias represented ratio reported U5MR true U5MR. IGME2019. Yearly Estimates national -5 child mortality Kenya 2019 UN-IGME estimates. UrbanProp. Proportion urban population county total population county. Source: 2009 Kenya Population Housing Census, Table A2 Kenya 2014 DHS report.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/KenData.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Auxiliary data for Kenya 2014 DHS. — KenData","text":"Neff Walker, Kenneth Hill, Fengmin Zhao (2012) Child mortality estimation: methods used adjust bias due aids estimating trends -five mortality., PLoS Medicine, 9(8):e1001298.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/KingCounty.html","id":null,"dir":"Reference","previous_headings":"","what":"Map of King County — KingCounty","title":"Map of King County — KingCounty","text":"Shapefiles King County Washington States.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/KingCounty.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Map of King County — KingCounty","text":"","code":"KingCounty"},{"path":"https://richardli.github.io/SUMMER/reference/KingCounty.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Map of King County — KingCounty","text":"object class SpatialPolygonsDataFrame 48 rows 9 columns.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/MalawiData.html","id":null,"dir":"Reference","previous_headings":"","what":"Auxiliary data for Malawi 2000, 2004, 2010, and 2015 DHS. — MalawiData","title":"Auxiliary data for Malawi 2000, 2004, 2010, and 2015 DHS. — MalawiData","text":"list contains several data frames.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/MalawiData.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Auxiliary data for Malawi 2000, 2004, 2010, and 2015 DHS. — MalawiData","text":"","code":"data(MalawiData)"},{"path":"https://richardli.github.io/SUMMER/reference/MalawiData.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Auxiliary data for Malawi 2000, 2004, 2010, and 2015 DHS. — MalawiData","text":"object class list length 4.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/MalawiData.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Auxiliary data for Malawi 2000, 2004, 2010, and 2015 DHS. — MalawiData","text":"HIV, data frame three columns: years (five year periods),  survey, estimated bias reported U5MR due HIV 5 year period. bias represented ratio reported U5MR true U5MR. HIV.yearly, data frame three columns: years (one year interval),  survey, estimated bias reported U5MR due HIV year. bias represented ratio reported U5MR true U5MR. IGME2019. Yearly Estimates national -5 child mortality Malawi 2019 UN-IGME estimates. IGME2019.nmr. Yearly Estimates national neonatal mortality Malawi 2019 UN-IGME estimates.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/MalawiData.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Auxiliary data for Malawi 2000, 2004, 2010, and 2015 DHS. — MalawiData","text":"Neff Walker, Kenneth Hill, Fengmin Zhao (2012) Child mortality estimation: methods used adjust bias due aids estimating trends -five mortality., PLoS Medicine, 9(8):e1001298.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/MalawiMap.html","id":null,"dir":"Reference","previous_headings":"","what":"Malawi Admin-2 map — MalawiMap","title":"Malawi Admin-2 map — MalawiMap","text":"SpatialPolygonsDataFrame objects reflect Admin 2 regions Malawi, including Likoma island. Admin 2 region names ADM2_EN field.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/MalawiMap.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Malawi Admin-2 map — MalawiMap","text":"","code":"data(MalawiMap)"},{"path":"https://richardli.github.io/SUMMER/reference/MalawiMap.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Malawi Admin-2 map — MalawiMap","text":"object class SpatialPolygonsDataFrame 28 rows 14 columns.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/SUMMER-package.html","id":null,"dir":"Reference","previous_headings":"","what":"SUMMER package documentation. — SUMMER-package","title":"SUMMER package documentation. — SUMMER-package","text":"SUMMER provides methods spatial spatio-temporal smoothing demographic health indicators using survey data, particular focus estimating projecting -five mortality rates.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/SUMMER-package.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"SUMMER package documentation. — SUMMER-package","text":"details model implemented package, see Mercer et al. (2015) <doi:10.1214/15-AOAS872> Li et al. (2019) <doi:10.1371/journal.pone.0210645>. development version package maintained https://github.com/richardli/SUMMER.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/aggPixelPreds.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper function of pixelPopToArea — aggPixelPreds","title":"Helper function of pixelPopToArea — aggPixelPreds","text":"Aggregates population  pixel level level area interest.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/aggPixelPreds.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper function of pixelPopToArea — aggPixelPreds","text":"","code":"aggPixelPreds(   Zg,   Ng,   areas,   urban = targetPopMat$urban,   targetPopMat = NULL,   useDensity = FALSE,   stratifyByUrban = TRUE,   normalize = useDensity )"},{"path":"https://richardli.github.io/SUMMER/reference/aggPixelPreds.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helper function of pixelPopToArea — aggPixelPreds","text":"Zg nIntegrationPoint x nsim matrix simulated response (population numerators) pixel sample Ng nIntegrationPoint x nsim matrix simulated counts (population denominators) pixel sample areas nIntegrationPoint length character vector areas (subareas) urban nIntegrationPoint length vector indicators specifying whether pixels urban rural targetPopMat simPopCustom useDensity whether use population density aggregation weights. stratifyByUrban whether stratify simulations urban/rural classification normalize TRUE, pixel level aggregation weights within specified area normalized sum 1. produces  average values Zg rather sum. general, set TRUE smooth integrals risk.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/aggPop.html","id":null,"dir":"Reference","previous_headings":"","what":"Aggregate populations to the specified areal level — aggPop","title":"Aggregate populations to the specified areal level — aggPop","text":"Takes simulated populations aggregates  specified areal level. Also calculates aggregated risk prevalence.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/aggPop.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Aggregate populations to the specified areal level — aggPop","text":"","code":"pixelPopToArea(   pixelLevelPop,   eaSamples,   areas,   stratifyByUrban = TRUE,   targetPopMat = NULL,   doFineScaleRisk = !is.null(pixelLevelPop$fineScaleRisk$p),   doSmoothRisk = !is.null(pixelLevelPop$smoothRisk$p) )  areaPopToArea(   areaLevelPop,   areasFrom,   areasTo,   stratifyByUrban = TRUE,   doFineScaleRisk = !is.null(areaLevelPop$aggregationResults$pFineScaleRisk),   doSmoothRisk = !is.null(areaLevelPop$aggregationResults$pSmoothRisk) )"},{"path":"https://richardli.github.io/SUMMER/reference/aggPop.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Aggregate populations to the specified areal level — aggPop","text":"pixelLevelPop pixel level population information want aggregate. format output simPopCustom eaSamples nIntegrationPoint x nsim matrix number enumeration areas per pixel sampled input pixel level population areas character vector length nIntegrationPoints area names  want aggregate. Can also subareas stratifyByUrban whether stratify simulations urban/rural classification targetPopMat pixellated grid data frame variables `lon`, `lat`, `pop` (target population), `area`, `subareas` (subareaLevel TRUE), `urban` (stratifyByUrban TRUE), `east`, `north` doFineScaleRisk whether calculate fine scale risk addition prevalence. See details doSmoothRisk Whether calculate smooth risk addition prevalence. See details areaLevelPop output simPopCustom containing pixel level information  population interest areasFrom character vector length equal number areas  like aggregate containing unique names areas.  Can also subareas, smaller \"areas\",  \"area\" must entirely contained single \"area\" areasTo character vector length equal number areas  like aggregate containing names areas containing  respective `' area. Can also set subareas,  larger \"areas\".","code":""},{"path":"https://richardli.github.io/SUMMER/reference/aggPop.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Aggregate populations to the specified areal level — aggPop","text":"list containing elements `fineScalePrevalence` `fineScaleRisk`.  turn lists aggregated prevalence risk area  interest, containg following elements, paranethesis indicate elements  fineScaleRisk model rather fineScalePrevalence: p Aggregated prevalence (risk), calculated aggregate Z divided  aggregate N Z Aggregated (expected) population numerator N Aggregated (expected) population denominator pUrban Aggregated prevalence (risk) urban part area, calculated  aggregate Z divided aggregate N ZUrban Aggregated (expected) population numerator urban part area NUrban Aggregated (expected) population denominator urban part area pRural Aggregated prevalence (risk) rural part area, calculated  aggregate Z divided aggregate N ZRural Aggregated (expected) population numerator rural part area NRural Aggregated (expected) population denominator rural part area Aggregation matrix used aggregate pixel level areal level AUrban Aggregation matrix used aggregate pixel level urban part areal level ARural Aggregation matrix used aggregate pixel level rural part areal level","code":""},{"path":"https://richardli.github.io/SUMMER/reference/aggPop.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Aggregate populations to the specified areal level — aggPop","text":"pixelPopToArea(): Aggregate pixel areal level areaPopToArea(): Aggregate areal populations another areal level","code":""},{"path":"https://richardli.github.io/SUMMER/reference/aggPop.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Aggregate populations to the specified areal level — aggPop","text":"Preparation","code":""},{"path":[]},{"path":"https://richardli.github.io/SUMMER/reference/aggPop.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Aggregate populations to the specified areal level — aggPop","text":"John Paige","code":""},{"path":"https://richardli.github.io/SUMMER/reference/aggPop.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Aggregate populations to the specified areal level — aggPop","text":"","code":"if (FALSE) { ##### Now we make a model for the risk. We will use an SPDE model with these  ##### parameters for the linear predictor on the logist scale, which are chosen  ##### to be of practical interest: beta0=-2.9 # intercept gamma=-1 # urban effect rho=(1/3)^2 # spatial variance effRange = 400 # effective spatial range in km sigmaEpsilon=sqrt(1/2.5) # cluster (nugget) effect standard deviation  # simulate the population! Note that this produces multiple dense  # nEA x nsim and nIntegrationPoint x nsim matrices. In the future  # sparse matrices will and chunk by chunk computations may be incorporated. simPop = simPopSPDE(nsim=1, easpa=easpaKenyaNeonatal,                      popMat=popMatKenya, targetPopMat=popMatKenyaNeonatal,                      poppsub=poppsubKenya, spdeMesh=kenyaMesh,                      margVar=rho, sigmaEpsilonSq=sigmaEpsilon^2,                      gamma=gamma, effRange=effRange, beta0=beta0,                      seed=123, inla.seed=12, nHHSampled=25,                      stratifyByUrban=TRUE, subareaLevel=TRUE,                      doFineScaleRisk=TRUE,                      min1PerSubarea=TRUE)  pixelPop = simPop$pixelPop subareaPop = pixelPopToArea(pixelLevelPop=pixelPop, eaSamples=pixelPop$eaSamples,    areas=popMatKenya$subarea, stratifyByUrban=TRUE,    targetPopMat=popMatKenyaNeonatal, doFineScaleRisk=TRUE)  # get areas associated with each subarea for aggregation tempAreasFrom = popMatKenya$subarea tempAreasTo = popMatKenya$area areasFrom = sort(unique(tempAreasFrom)) areasToI = match(areasFrom, tempAreasFrom) areasTo = tempAreasTo[areasToI]  # do the aggregation from subareas to areas outAreaLevel = areaPopToArea(areaLevelPop=subareaPop,    areasFrom=areasFrom, areasTo=areasTo,    stratifyByUrban=TRUE, doFineScaleRisk=TRUE) }"},{"path":"https://richardli.github.io/SUMMER/reference/aggregateSurvey.html","id":null,"dir":"Reference","previous_headings":"","what":"Aggregate estimators from different surveys. — aggregateSurvey","title":"Aggregate estimators from different surveys. — aggregateSurvey","text":"Aggregate estimators different surveys.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/aggregateSurvey.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Aggregate estimators from different surveys. — aggregateSurvey","text":"","code":"aggregateSurvey(data)"},{"path":"https://richardli.github.io/SUMMER/reference/aggregateSurvey.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Aggregate estimators from different surveys. — aggregateSurvey","text":"data Output getDirectList","code":""},{"path":"https://richardli.github.io/SUMMER/reference/aggregateSurvey.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Aggregate estimators from different surveys. — aggregateSurvey","text":"Estimators aggregated across surveys.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/aggregateSurvey.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Aggregate estimators from different surveys. — aggregateSurvey","text":"Zehang Richard Li","code":""},{"path":"https://richardli.github.io/SUMMER/reference/aggregateSurvey.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Aggregate estimators from different surveys. — aggregateSurvey","text":"","code":"if (FALSE) { data(DemoData) data(DemoMap) years <- levels(DemoData[[1]]$time)  # obtain direct estimates data <- getDirectList(births = DemoData,  years = years,  regionVar = \"region\", timeVar = \"time\",  clusterVar = \"~clustid+id\",  ageVar = \"age\", weightsVar = \"weights\",  geo.recode = NULL)  # obtain maps geo <- DemoMap$geo mat <- DemoMap$Amat  # Simulate hyper priors priors <- simhyper(R = 2, nsamp = 1e+05, nsamp.check = 5000, Amat = mat, only.iid = TRUE)  # combine data from multiple surveys data <- aggregateSurvey(data) utils::head(data)  }"},{"path":"https://richardli.github.io/SUMMER/reference/calibrateByRegion.html","id":null,"dir":"Reference","previous_headings":"","what":"Calibrate the point level totals so their sum matches the regional totals — calibrateByRegion","title":"Calibrate the point level totals so their sum matches the regional totals — calibrateByRegion","text":"Calibrate/normalize point level totals sum matches  regional totals. Technically, totals can level smaller   region level specified.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/calibrateByRegion.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calibrate the point level totals so their sum matches the regional totals — calibrateByRegion","text":"","code":"calibrateByRegion(pointTotals, pointRegions, regions, regionTotals)"},{"path":"https://richardli.github.io/SUMMER/reference/calibrateByRegion.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calibrate the point level totals so their sum matches the regional totals — calibrateByRegion","text":"pointTotals Vector point level totals calibrated/normalized pointRegions Vector regions associated point regions Vector region names regionTotals Vector desired region level totals associated `regions`","code":""},{"path":"https://richardli.github.io/SUMMER/reference/calibrateByRegion.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calibrate the point level totals so their sum matches the regional totals — calibrateByRegion","text":"vector length pointTotals pointRegions containing  calibrated/normalized point totals sum correct regional totals Vector updated point level totals, calibrated match region totals","code":""},{"path":"https://richardli.github.io/SUMMER/reference/calibrateByRegion.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Calibrate the point level totals so their sum matches the regional totals — calibrateByRegion","text":"John Paige","code":""},{"path":"https://richardli.github.io/SUMMER/reference/calibrateByRegion.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calibrate the point level totals so their sum matches the regional totals — calibrateByRegion","text":"","code":"pointTotals = c(1, 1, 1, 2) pointRegions = c(\"a\", \"a\", \"b\", \"b\") regionTotals = c(10, 20) regions = c(\"a\", \"b\") calibrateByRegion(pointTotals, pointRegions, regions, regionTotals) #> [1]  5.000000  5.000000  6.666667 13.333333"},{"path":"https://richardli.github.io/SUMMER/reference/compareEstimates.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot heatmap comparing pairwise posterior exceedence probabilities for svysae object — compareEstimates","title":"Plot heatmap comparing pairwise posterior exceedence probabilities for svysae object — compareEstimates","text":"Plot heatmap comparing pairwise posterior exceedence probabilities svysae object","code":""},{"path":"https://richardli.github.io/SUMMER/reference/compareEstimates.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot heatmap comparing pairwise posterior exceedence probabilities for svysae object — compareEstimates","text":"","code":"compareEstimates(x, posterior.sample = NULL)"},{"path":"https://richardli.github.io/SUMMER/reference/compareEstimates.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot heatmap comparing pairwise posterior exceedence probabilities for svysae object — compareEstimates","text":"x svysae object. Plots created models object. posterior.sample Matrix posteriors samples area level quantities one row area one column sample. argument may specified provide heatmap desired samples.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/compareEstimates.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot heatmap comparing pairwise posterior exceedence probabilities for svysae object — compareEstimates","text":"ggplot containing heat map pairwise comparisons","code":""},{"path":"https://richardli.github.io/SUMMER/reference/compareEstimates.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot heatmap comparing pairwise posterior exceedence probabilities for svysae object — compareEstimates","text":"","code":"if (FALSE) { data(DemoData2) data(DemoMap2) library(survey) des0 <- svydesign(ids = ~clustid+id, strata = ~strata,                   weights = ~weights, data = DemoData2, nest = TRUE) Xmat <- aggregate(age~region, data = DemoData2, FUN = mean)  cts.res <- smoothArea(tobacco.use ~ 1,                       domain = ~region,                       design = des0,                       adj.mat = DemoMap2$Amat,                        pc.u = 1,                       pc.alpha = 0.01,                       pc.u.phi = 0.5,                       pc.alpha.phi = 2/3,                       return.samples = TRUE) compareEstimates(cts.res) }"},{"path":"https://richardli.github.io/SUMMER/reference/expit.html","id":null,"dir":"Reference","previous_headings":"","what":"Expit transformation — expit","title":"Expit transformation — expit","text":"Expit transformation","code":""},{"path":"https://richardli.github.io/SUMMER/reference/expit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Expit transformation — expit","text":"","code":"expit(x)"},{"path":"https://richardli.github.io/SUMMER/reference/expit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Expit transformation — expit","text":"x data","code":""},{"path":"https://richardli.github.io/SUMMER/reference/expit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Expit transformation — expit","text":"expit x","code":""},{"path":"https://richardli.github.io/SUMMER/reference/expit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Expit transformation — expit","text":"","code":"x <- .5 expit(x) #> [1] 0.6224593"},{"path":"https://richardli.github.io/SUMMER/reference/getAdjusted.html","id":null,"dir":"Reference","previous_headings":"","what":"Adjust direct estimates and their associated variances — getAdjusted","title":"Adjust direct estimates and their associated variances — getAdjusted","text":"Adjust direct estimates associated variances","code":""},{"path":"https://richardli.github.io/SUMMER/reference/getAdjusted.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Adjust direct estimates and their associated variances — getAdjusted","text":"","code":"getAdjusted(   data,   ratio,   time = \"years\",   region = \"region\",   est = \"mean\",   logit = \"logit.est\",   logit.var = \"var.est\",   logit.prec = \"logit.prec\",   logit.lower = \"lower\",   logit.upper = \"upper\",   prob.lower = NULL,   prob.upper = NULL,   adj = \"ratio\",   verbose = FALSE,   lower = NULL,   upper = NULL )"},{"path":"https://richardli.github.io/SUMMER/reference/getAdjusted.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Adjust direct estimates and their associated variances — getAdjusted","text":"data data frame adjusted estimates associated uncertainties, see arguments specific columns. ratio ratio unadjusted mortality rates true mortality rates. can either data frame following three columns (region, time, adj) adjustment factor differ region; data frame following two columns (time adj) adjustment factor varies time. column names specifying region, time, adjustment specified arguments function call. time column name time data adjustment ratio. region column name region data  adjustment ratio. est column name unadjusted mortality rates data logit column name logit unadjusted mortality rates data logit.var column name variance logit unadjusted mortality rates data logit.prec column name precision logit unadjusted mortality rates data logit.lower column name 95% lower bound logit unadjusted mortality rates data logit.upper column name 95% lower bound logit unadjusted mortality rates data prob.lower column name 95% lower bound unadjusted mortality rates data. provided instead logit.lower, logit scale lower bound created. prob.upper column name 95% lower bound unadjusted mortality rates data. provided instead logit.upper, logit scale upper bound created. adj column name adjustment ratio verbose logical indicator whether print unadjusted row index lower previous argument name prob.lower. removed next update upper previous argument name prob.upper. removed next update","code":""},{"path":"https://richardli.github.io/SUMMER/reference/getAdjusted.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Adjust direct estimates and their associated variances — getAdjusted","text":"adjusted dataset columns.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/getAdjusted.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Adjust direct estimates and their associated variances — getAdjusted","text":"Zehang Richard Li","code":""},{"path":"https://richardli.github.io/SUMMER/reference/getAdjusted.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Adjust direct estimates and their associated variances — getAdjusted","text":"","code":"if (FALSE) { years <- levels(DemoData[[1]]$time)  # obtain direct estimates data <- getDirectList(births = DemoData,  years = years,   regionVar = \"region\", timeVar = \"time\",  clusterVar = \"~clustid+id\",  ageVar = \"age\", weightsVar = \"weights\",  geo.recode = NULL) # obtain direct estimates data_multi <- getDirectList(births = DemoData, years = years,   regionVar = \"region\",  timeVar = \"time\", clusterVar = \"~clustid+id\",   ageVar = \"age\", weightsVar = \"weights\", geo.recode = NULL) data <- aggregateSurvey(data_multi)  # randomly simulate adjustment factor adj <- expand.grid(region = unique(data$region), years = years) adj$ratio <- runif(dim(adj)[1], min = 0.5, max = 0.8) data.adj <- getAdjusted(data = data, ratio = adj)  }"},{"path":"https://richardli.github.io/SUMMER/reference/getAmat.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract adjacency matrix from the map — getAmat","title":"Extract adjacency matrix from the map — getAmat","text":"Extract adjacency matrix map","code":""},{"path":"https://richardli.github.io/SUMMER/reference/getAmat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract adjacency matrix from the map — getAmat","text":"","code":"getAmat(geo, names)"},{"path":"https://richardli.github.io/SUMMER/reference/getAmat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract adjacency matrix from the map — getAmat","text":"geo SpatialPolygonsDataFrame map names character vector region ids added neighbours list","code":""},{"path":"https://richardli.github.io/SUMMER/reference/getAmat.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract adjacency matrix from the map — getAmat","text":"Spatial djacency matrix.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/getAmat.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Extract adjacency matrix from the map — getAmat","text":"Zehang Richard Li","code":""},{"path":"https://richardli.github.io/SUMMER/reference/getAmat.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract adjacency matrix from the map — getAmat","text":"","code":"if (FALSE) { data(DemoMap)  mat <- getAmat(geo = DemoMap$geo, names = DemoMap$geo$REGNAME) mat DemoMap$Amat }"},{"path":"https://richardli.github.io/SUMMER/reference/getAreaName.html","id":null,"dir":"Reference","previous_headings":"","what":"Determines which administrative areas contain the given points — getAreaName","title":"Determines which administrative areas contain the given points — getAreaName","text":"points area, assigned nearest area using  fields::fields.rdist.near fields::rdist depending number points  maximum memory bytes warning.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/getAreaName.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Determines which administrative areas contain the given points — getAreaName","text":"","code":"getAreaName(   pts,   shapefile,   areaNameVar = \"NAME_1\",   delta = 0.05,   mean.neighbor = 50,   maxBytes = 3 * 2^30 )"},{"path":"https://richardli.github.io/SUMMER/reference/getAreaName.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Determines which administrative areas contain the given points — getAreaName","text":"pts 2 column matrix lon/lat coordinates shapefile SpatialPolygonsDataFrame object areaNameVar column name slot(shapefile, \"data\")  corresponding area level interest delta Argument passed fields::fields.rdist.near fields package mean.neighbor Argument passed fields::fields.rdist.near fields  package maxBytes Maximum allowed memory bytes (default 3Gb). Determines  whether call fields::fields.rdist.near saves memory requires  delta mean.neighbor inputs specified fields::fields.rdist.near","code":""},{"path":"https://richardli.github.io/SUMMER/reference/getAreaName.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Determines which administrative areas contain the given points — getAreaName","text":"list area IDs, area names, whether  points multiple areas, whether points  areas assigned nearest one.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/getAreaName.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Determines which administrative areas contain the given points — getAreaName","text":"delta mean.neighbor arguments used points  areas, perhaps due inconsistencies shapefiles.","code":""},{"path":[]},{"path":"https://richardli.github.io/SUMMER/reference/getAreaName.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Determines which administrative areas contain the given points — getAreaName","text":"John Paige","code":""},{"path":"https://richardli.github.io/SUMMER/reference/getAreaName.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Determines which administrative areas contain the given points — getAreaName","text":"","code":"if (FALSE) { # download Kenya GADM shapefiles from SUMMERdata github repository githubURL <- \"https://github.com/paigejo/SUMMERdata/blob/main/data/kenyaMaps.rda?raw=true\" download.file(githubURL,\"kenyaMaps.rda\")  # load it in load(\"kenyaMaps.rda\")  # use the shapefile data to see what Admin1 and 2 areas the  # points (0, 37) and (0.5, 38) are in # (these are longitude/latitude coordinates) pts = cbind(c(37, 38), c(0, .5)) head(slot(adm1, \"data\")) admin1Areas = getAreaName(pts, adm1, \"NAME_1\") admin2Areas = getAreaName(pts, adm2, \"NAME_2\") }"},{"path":"https://richardli.github.io/SUMMER/reference/getBirths.html","id":null,"dir":"Reference","previous_headings":"","what":"Reformat full birth records into person-month format — getBirths","title":"Reformat full birth records into person-month format — getBirths","text":"Reformat full birth records person-month format","code":""},{"path":"https://richardli.github.io/SUMMER/reference/getBirths.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reformat full birth records into person-month format — getBirths","text":"","code":"getBirths(   filepath = NULL,   data = NULL,   surveyyear = NA,   variables = c(\"caseid\", \"v001\", \"v002\", \"v004\", \"v005\", \"v021\", \"v022\", \"v023\", \"v024\",     \"v025\", \"v139\", \"bidx\"),   strata = c(\"v024\", \"v025\"),   dob = \"b3\",   alive = \"b5\",   age = \"b7\",   age.truncate = 24,   date.interview = \"v008\",   month.cut = c(1, 12, 24, 36, 48, 60),   year.cut = seq(1980, 2020, by = 5),   min.last.period = 0,   cmc.adjust = 0,   compact = FALSE,   compact.by = c(\"v001\", \"v024\", \"v025\", \"v005\") )"},{"path":"https://richardli.github.io/SUMMER/reference/getBirths.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reformat full birth records into person-month format — getBirths","text":"filepath file path raw .dta file DHS. used data frame provided function call. data data frame DHS survey surveyyear year survey. Observations year excluded analysis. variables vector variables used obtaining person-month files. variables correspond DHS recode manual VI. early DHS data, variable names may need changed. strata vector variable names used strata. single variable specified, variable used strata indicator multiple variables specified, interaction variables used strata indicator. dob variable name date birth. alive variable name indicator whether child alive dead time interview. factor character variable levels \"\" \"yes\". coding scheme recognized can lead errors. age variable name age death child completed months. age.truncate smallest age months full years reported. default value 24, corresponds DHS practice recording age full years children 2 years old. , children age starting 24 months old, assume age variable reported multiples 12 truncated true value. example, children age 24 35 months recorded 24. account truncation age, 5 months added ages recorded multiples 12 starting 24. avoid adjustment, set argument NA. date.interview variable name date interview. month.cut cutoff bins age group unit months. Default values 1, 12, 24, 36, 48, 60, representing age groups (0, 1), [1, 12), [12, 24), ..., [48, 60). year.cut cutoff bins time periods, including boundaries. Default values 1980, 1985, ..., 2020, representing time periods 80-84, 85-89, ..., 15-19. Notice bin contains one year, last year output max(year.cut)-1. example, year.cut = 1980:2020, last year output 2019. min.last.period cutoff many years last period must contain order counted output. example, last period 2015-2019 min.last.period = 3, person-months last period returned survey contains observations least 2017. argument avoids situation estimates last period based small number initial years, applicable. Default 0. cmc.adjust number months add recorded month dataset. DHS surveys use Gregorian calendar (calendar used world). example, Ethiopian calendar 92 months behind Gregorian calendar general. can set cmc.adjust 92, adds 92 months dates dataset, effectively transforming Ethiopian calendar Gregorian calendar. compact logical indicator whether compact format returned. compact output, person months aggregated cluster, age, time. Total number person months deaths group returned instead raw person-months. compact.vector variables summarize compact form .","code":""},{"path":"https://richardli.github.io/SUMMER/reference/getBirths.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reformat full birth records into person-month format — getBirths","text":"function returns new data frame row indicate person-month, additional variables specified function argument.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/getBirths.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Reformat full birth records into person-month format — getBirths","text":"Li, Z., Hsiao, Y., Godwin, J., Martin, B. D., Wakefield, J., Clark, S. J., & support United Nations Inter-agency Group Child Mortality Estimation technical advisory group. (2019). Changes spatial distribution -five mortality rate: Small-area analysis 122 DHS surveys 262 subregions 35 countries Africa. PloS one, 14(1), e0210645. Mercer, L. D., Wakefield, J., Pantazis, ., Lutambi, . M., Masanja, H., & Clark, S. (2015). Space-time smoothing complex survey data: small area estimation child mortality. annals applied statistics, 9(4), 1889.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/getBirths.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Reformat full birth records into person-month format — getBirths","text":"Zehang Richard Li, Bryan Martin, Laina Mercer","code":""},{"path":"https://richardli.github.io/SUMMER/reference/getBirths.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reformat full birth records into person-month format — getBirths","text":"","code":"if (FALSE) { my_fp <- \"/myExampleFilepath/surveyData.DTA\" DemoData <- getBirths(filepath = my_fp, surveyyear = 2015)  }"},{"path":"https://richardli.github.io/SUMMER/reference/getCounts.html","id":null,"dir":"Reference","previous_headings":"","what":"Aggregate person-month data into counts and totals by groups. — getCounts","title":"Aggregate person-month data into counts and totals by groups. — getCounts","text":"Aggregate person-month data counts totals groups.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/getCounts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Aggregate person-month data into counts and totals by groups. — getCounts","text":"","code":"getCounts(data, variables, by, ignore = NULL, addtotal = TRUE, drop = TRUE)"},{"path":"https://richardli.github.io/SUMMER/reference/getCounts.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Aggregate person-month data into counts and totals by groups. — getCounts","text":"data dataset person-month format variables character vector variables aggregate character vector columns specifies groups aggregate . ignore list conditions impute 0. left unspecified, group levels data imputed 0 counts. addtotal logical indicator whether add column group total counts. drop logical indicator whether drop rows total = 0.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/getCounts.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Aggregate person-month data into counts and totals by groups. — getCounts","text":"data.frame ggregated counts.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/getCounts.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Aggregate person-month data into counts and totals by groups. — getCounts","text":"Zehang Richard Li","code":""},{"path":"https://richardli.github.io/SUMMER/reference/getCounts.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Aggregate person-month data into counts and totals by groups. — getCounts","text":"","code":"# a toy dataset with 4 time periods but one missing in data timelist <- factor(1:4) data = data.frame(died = c(0,0,0,1,1,0,0),            area = c(rep(c(\"A\", \"B\"), 3), \"A\"),            time = timelist[c(1,1,2,3,3,3,3)]) data #>   died area time #> 1    0    A    1 #> 2    0    B    1 #> 3    0    A    2 #> 4    1    B    3 #> 5    1    A    3 #> 6    0    B    3 #> 7    0    A    3 # without ignore argument, all levels will be imputed getCounts(data, variables = \"died\", by = c(\"area\", \"time\")) #>   area time died total #> 1    A    1    0     1 #> 2    B    1    0     1 #> 3    A    2    0     1 #> 4    A    3    1     2 #> 5    B    3    1     2  # ignoring time = 4, the ignored level will not be imputed (but still in the output) getCounts(data, variables = \"died\", by = c(\"area\", \"time\"),        ignore = list(\"time\"=c(4)) ) #>   area time died total #> 1    A    1    0     1 #> 2    B    1    0     1 #> 3    A    2    0     1 #> 4    A    3    1     2 #> 5    B    3    1     2"},{"path":"https://richardli.github.io/SUMMER/reference/getDiag.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract posterior summaries of random effects — getDiag","title":"Extract posterior summaries of random effects — getDiag","text":"Extract posterior summaries random effects","code":""},{"path":"https://richardli.github.io/SUMMER/reference/getDiag.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract posterior summaries of random effects — getDiag","text":"","code":"getDiag(   inla_mod,   field = c(\"space\", \"time\", \"spacetime\")[1],   CI = 0.95,   draws = NULL,   nsim = 1000,   ... )"},{"path":"https://richardli.github.io/SUMMER/reference/getDiag.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract posterior summaries of random effects — getDiag","text":"inla_mod output smoothDirect smoothCluster field random effects plot. can one following: space, time, spacetime. CI Desired level credible intervals draws Posterior samples drawn fitted model. argument allows previously sampled draws (setting save.draws TRUE) used new aggregation tasks. nsim number simulations, applicable cluster-level model space-time interaction terms random slopes included. ... Unused arguments, users fitted object package v1.0.0, arguments including Amat, year_label, year_range can still specified manually.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/getDiag.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract posterior summaries of random effects — getDiag","text":"List diagnostic plots","code":""},{"path":"https://richardli.github.io/SUMMER/reference/getDiag.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Extract posterior summaries of random effects — getDiag","text":"Zehang Richard Li","code":""},{"path":"https://richardli.github.io/SUMMER/reference/getDiag.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract posterior summaries of random effects — getDiag","text":"","code":"if (FALSE) {   data(DemoMap)   years <- levels(DemoData[[1]]$time)      # obtain direct estimates   data <- getDirectList(births = DemoData,    years = years,     regionVar = \"region\", timeVar = \"time\",    clusterVar = \"~clustid+id\",    ageVar = \"age\", weightsVar = \"weights\",    geo.recode = NULL)   # obtain direct estimates   data_multi <- getDirectList(births = DemoData, years = years,     regionVar = \"region\",  timeVar = \"time\", clusterVar = \"~clustid+id\",     ageVar = \"age\", weightsVar = \"weights\", geo.recode = NULL)   data <- aggregateSurvey(data_multi)      #  national model   years.all <- c(years, \"15-19\")   fit1 <- smoothDirect(data = data, geo = DemoMap$geo, Amat = DemoMap$Amat,      year_label = years.all, year_range = c(1985, 2019),      rw = 2, is.yearly=FALSE, m = 5) random.time <- getDiag(fit1, field = \"time\")   random.space <- getDiag(fit1, field = \"space\")   random.spacetime <- getDiag(fit1, field = \"spacetime\") }"},{"path":"https://richardli.github.io/SUMMER/reference/getDirect.html","id":null,"dir":"Reference","previous_headings":"","what":"Obtain the Horvitz-Thompson direct estimates and standard errors using delta method for a single survey. — getDirect","title":"Obtain the Horvitz-Thompson direct estimates and standard errors using delta method for a single survey. — getDirect","text":"Obtain Horvitz-Thompson direct estimates standard errors using delta method single survey.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/getDirect.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Obtain the Horvitz-Thompson direct estimates and standard errors using delta method for a single survey. — getDirect","text":"","code":"getDirect(   births,   years,   regionVar = \"region\",   timeVar = \"time\",   clusterVar = \"~v001+v002\",   ageVar = \"age\",   weightsVar = \"v005\",   Ntrials = NULL,   geo.recode = NULL,   national.only = FALSE,   CI = 0.95 )"},{"path":"https://richardli.github.io/SUMMER/reference/getDirect.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Obtain the Horvitz-Thompson direct estimates and standard errors using delta method for a single survey. — getDirect","text":"births matrix child-month data getBirths years String vector year intervals used regionVar Variable name region input births data. timeVar Variable name time period indicator input births data. clusterVar Variable name cluster, typically '~v001 + v002' ageVar Variable name age group. variable need form \"-b\" b ages months. example, \"1-11\" means age 1 11 months, including end points. exception age less one month can represented \"0\" \"0-0\". weightsVar Variable name sampling weights, typically 'v005' Ntrials Variable total number person-months input data (births) compact form. geo.recode recode matrix used region name consistent across different surveys. See ChangeRegion. national.Logical indicator obtain national estimates CI desired confidence interval calculate","code":""},{"path":"https://richardli.github.io/SUMMER/reference/getDirect.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Obtain the Horvitz-Thompson direct estimates and standard errors using delta method for a single survey. — getDirect","text":"matrix period-region summary Horvitz-Thompson direct estimates region time period specified argument, standard errors using delta method single survey, 95% confidence interval, logit estimates.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/getDirect.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Obtain the Horvitz-Thompson direct estimates and standard errors using delta method for a single survey. — getDirect","text":"Li, Z., Hsiao, Y., Godwin, J., Martin, B. D., Wakefield, J., Clark, S. J., & support United Nations Inter-agency Group Child Mortality Estimation technical advisory group. (2019). Changes spatial distribution -five mortality rate: Small-area analysis 122 DHS surveys 262 subregions 35 countries Africa. PloS one, 14(1), e0210645. Mercer, L. D., Wakefield, J., Pantazis, ., Lutambi, . M., Masanja, H., & Clark, S. (2015). Space-time smoothing complex survey data: small area estimation child mortality. annals applied statistics, 9(4), 1889.","code":""},{"path":[]},{"path":"https://richardli.github.io/SUMMER/reference/getDirect.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Obtain the Horvitz-Thompson direct estimates and standard errors using delta method for a single survey. — getDirect","text":"Zehang Richard Li, Bryan Martin, Laina Mercer","code":""},{"path":"https://richardli.github.io/SUMMER/reference/getDirect.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Obtain the Horvitz-Thompson direct estimates and standard errors using delta method for a single survey. — getDirect","text":"","code":"if (FALSE) { data(DemoData) years <- c(\"85-89\", \"90-94\", \"95-99\", \"00-04\", \"05-09\", \"10-14\") mean <- getDirect(births = DemoData[[1]],  years = years,  regionVar = \"region\", timeVar = \"time\", clusterVar = \"~clustid+id\",  ageVar = \"age\", weightsVar = \"weights\", geo.recode = NULL) }"},{"path":"https://richardli.github.io/SUMMER/reference/getDirectList.html","id":null,"dir":"Reference","previous_headings":"","what":"Obtain the Horvitz-Thompson direct estimates and standard errors using delta method for multiple surveys. — getDirectList","title":"Obtain the Horvitz-Thompson direct estimates and standard errors using delta method for multiple surveys. — getDirectList","text":"Obtain Horvitz-Thompson direct estimates standard errors using delta method multiple surveys.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/getDirectList.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Obtain the Horvitz-Thompson direct estimates and standard errors using delta method for multiple surveys. — getDirectList","text":"","code":"getDirectList(   births,   years,   regionVar = \"region\",   timeVar = \"time\",   clusterVar = \"~v001+v002\",   ageVar = \"age\",   weightsVar = \"v005\",   Ntrials = NULL,   geo.recode = NULL,   national.only = FALSE )"},{"path":"https://richardli.github.io/SUMMER/reference/getDirectList.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Obtain the Horvitz-Thompson direct estimates and standard errors using delta method for multiple surveys. — getDirectList","text":"births list child-month data multiple surveys getBirths. name list used identifier output. years String vector year intervals used regionVar Variable name region, typically 'v024', older surveys might 'v101' timeVar Variable name time period indicator input births data. clusterVar Variable name IDs second-stage cluster sampling, typically '~v001 + v002', .e., cluster number household number. cluster sampling design exists, variable usually household ID. ageVar Variable name age group. variable need form \"-b\" b ages months. example, \"1-11\" means age 1 11 months, including end points. exception age less one month can represented \"0\" \"0-0\". weightsVar Variable name sampling weights, typically 'v005' Ntrials Variable total number person-months input data (births) compact form. geo.recode recode matrix used region name consistent across different surveys. See ChangeRegion. national.Logical indicator obtain national estimates","code":""},{"path":"https://richardli.github.io/SUMMER/reference/getDirectList.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Obtain the Horvitz-Thompson direct estimates and standard errors using delta method for multiple surveys. — getDirectList","text":"extension getDirect function returns estimates multiple surveys. Additional columns output (survey surveyYears) specify estimates different surveys.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/getDirectList.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Obtain the Horvitz-Thompson direct estimates and standard errors using delta method for multiple surveys. — getDirectList","text":"Li, Z., Hsiao, Y., Godwin, J., Martin, B. D., Wakefield, J., Clark, S. J., & support United Nations Inter-agency Group Child Mortality Estimation technical advisory group. (2019). Changes spatial distribution -five mortality rate: Small-area analysis 122 DHS surveys 262 subregions 35 countries Africa. PloS one, 14(1), e0210645. Mercer, L. D., Wakefield, J., Pantazis, ., Lutambi, . M., Masanja, H., & Clark, S. (2015). Space-time smoothing complex survey data: small area estimation child mortality. annals applied statistics, 9(4), 1889.","code":""},{"path":[]},{"path":"https://richardli.github.io/SUMMER/reference/getDirectList.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Obtain the Horvitz-Thompson direct estimates and standard errors using delta method for multiple surveys. — getDirectList","text":"Zehang Richard Li, Bryan Martin, Laina Mercer","code":""},{"path":"https://richardli.github.io/SUMMER/reference/getDirectList.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Obtain the Horvitz-Thompson direct estimates and standard errors using delta method for multiple surveys. — getDirectList","text":"","code":"if (FALSE) { data(DemoData) years <- c(\"85-89\", \"90-94\", \"95-99\", \"00-04\", \"05-09\", \"10-14\") mean <- getDirectList(births = DemoData, years = years,  regionVar = \"region\", timeVar = \"time\", clusterVar = \"~clustid+id\",  ageVar = \"age\", weightsVar = \"weights\", geo.recode = NULL) }"},{"path":"https://richardli.github.io/SUMMER/reference/getSmoothed.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract smoothed estimates. — getSmoothed","title":"Extract smoothed estimates. — getSmoothed","text":"Extract smoothed estimates.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/getSmoothed.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract smoothed estimates. — getSmoothed","text":"","code":"getSmoothed(   inla_mod,   nsim = 1000,   weight.strata = NULL,   weight.frame = NULL,   verbose = FALSE,   mc = 0,   include_time_unstruct = FALSE,   CI = 0.95,   draws = NULL,   save.draws = FALSE,   include_subnational = TRUE,   only.age = NULL,   joint = FALSE,   ... )"},{"path":"https://richardli.github.io/SUMMER/reference/getSmoothed.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract smoothed estimates. — getSmoothed","text":"inla_mod output smoothDirect smoothCluster nsim number simulations, applicable cluster-level model direct model joint = TRUE specified. smooth direct model draw 1e5 samples marginal distribution joint = FALSE since computation faster. weight.strata data frame two columns specifying time region, followed columns specifying proportion strata region. argument specifies weights strata-specific estimates probability scale. weight.frame data frame three columns, years, region, weight frame corresponding time period region. argument specifies weights frame-specific estimates logit scale. Notice different weight.strata argument. verbose logical indicator whether print progress messages inla.posterior.sample. mc number monte carlo draws approximate marginal prevalence/hazards binomial model. mc = 0, analytical approximation used. analytical approximation invalid hazard modeling one age groups. include_time_unstruct Indicator whether include temporal unstructured effects (.e., shocks) smoothed estimates cluster-level model. argument applies cluster-level models (smoothCluster). Default FALSE excludes unstructured temporal components. set TRUE  unstructured temporal random effects included. Alternatively, specified vector   subset year labels (year_label argument), unstructured terms corresponding time periods added prediction. CI Desired level credible intervals draws Posterior samples drawn fitted model. argument allows previously sampled draws (setting save.draws TRUE) used new aggregation tasks. save.draws Logical indicator whether raw posterior draws saved. Saved draws can used accelerate aggregations different weights. include_subnational logical indicator whether include spatial space-time interaction components smoothed estimates. set FALSE, main temporal trends returned. .age vector age groups used compute final estimates. Default NULL, includes age groups model. argument can used extract mortality rates finer age groups fitting multiple age groups jointly. joint Logical indicator whether posterior draws drawn joint posterior marginal distributions. releveant smooth direct model. Default marginal distribution (joint = FALSE). ... Unused arguments, users fitted object package v1.0.0, arguments including Amat, year_label, year_range can still specified manually.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/getSmoothed.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract smoothed estimates. — getSmoothed","text":"data frame list data frames S3 class SUMMERproj, contains smoothed estimates.","code":""},{"path":[]},{"path":"https://richardli.github.io/SUMMER/reference/getSmoothed.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Extract smoothed estimates. — getSmoothed","text":"Zehang Richard Li","code":""},{"path":[]},{"path":"https://richardli.github.io/SUMMER/reference/hatchPlot.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot maps with uncertainty hatching. — hatchPlot","title":"Plot maps with uncertainty hatching. — hatchPlot","text":"function visualizes map different variables. input data frame can either long wide format.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/hatchPlot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot maps with uncertainty hatching. — hatchPlot","text":"","code":"hatchPlot(   data,   variables,   values = NULL,   labels = NULL,   geo,   by.data,   by.geo,   is.long = FALSE,   lower,   upper,   lim = NULL,   lim.CI = NULL,   breaks.CI = NULL,   ncol = 4,   hatch = NULL,   border = NULL,   size = 1,   legend.label = NULL,   per1000 = FALSE,   direction = 1,   ... )"},{"path":"https://richardli.github.io/SUMMER/reference/hatchPlot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot maps with uncertainty hatching. — hatchPlot","text":"data data frame variables plotted variables vector variables plotted. long format data used, one variable can selected values column corresponding values plotted, used long format data used labels vector labels use variable, used wide format data used geo SpatialPolygonsDataFrame object map .data column name specifying region names data .geo variable name specifying region names data .long logical indicator whether data long format, default FALSE lower column name lower bound CI upper column name upper bound CI lim fixed range values variables plot lim.CI fixed range CI widths plot breaks.CI vector numerical values decides breaks CI widths shown ncol number columns output tabs hatch color hatching lines. border color polygon borders. size line width polygon borders. legend.label Label color legend. per1000 logical indicator plot mortality rates rates per 1,000 live births. Note added comparison data always probability scale. direction Direction color scheme. can either 1 (smaller values darker) -1 (higher values darker). Default set 1. ... unused.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/hatchPlot.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Plot maps with uncertainty hatching. — hatchPlot","text":"Zehang Richard Li, Katie Wilson","code":""},{"path":"https://richardli.github.io/SUMMER/reference/hatchPlot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot maps with uncertainty hatching. — hatchPlot","text":"","code":"if (FALSE) { years <- levels(DemoData[[1]]$time)  # obtain direct estimates data <- getDirectList(births = DemoData,  years = years,   regionVar = \"region\", timeVar = \"time\",  clusterVar = \"~clustid+id\",  ageVar = \"age\", weightsVar = \"weights\",  geo.recode = NULL) # obtain direct estimates data_multi <- getDirectList(births = DemoData, years = years,   regionVar = \"region\",  timeVar = \"time\", clusterVar = \"~clustid+id\",   ageVar = \"age\", weightsVar = \"weights\", geo.recode = NULL) data <- aggregateSurvey(data_multi)  fit2 <- smoothDirect(data = data, geo = geo, Amat = mat,    year_label = years.all, year_range = c(1985, 2019),    rw = 2, is.yearly=TRUE, m = 5, type.st = 4) out2 <- getSmoothed(fit2)  plot(out2, is.yearly=TRUE, is.subnational=TRUE)  hatchPlot(data = subset(out2, is.yearly==FALSE), geo = geo, variables=c(\"years\"), values = c(\"median\"),  by.data = \"region\", by.geo = \"REGNAME\",  lower = \"lower\", upper = \"upper\", is.long=TRUE)  }"},{"path":"https://richardli.github.io/SUMMER/reference/iid.new.html","id":null,"dir":"Reference","previous_headings":"","what":"New random IID models for m-year to period random effects — iid.new","title":"New random IID models for m-year to period random effects — iid.new","text":"New random IID models m-year period random effects","code":""},{"path":"https://richardli.github.io/SUMMER/reference/iid.new.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"New random IID models for m-year to period random effects — iid.new","text":"","code":"iid.new(   cmd = c(\"graph\", \"Q\", \"mu\", \"initial\", \"log.norm.const\", \"log.prior\", \"quit\"),   theta = NULL )"},{"path":"https://richardli.github.io/SUMMER/reference/iid.new.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"New random IID models for m-year to period random effects — iid.new","text":"cmd list model components theta log precision","code":""},{"path":"https://richardli.github.io/SUMMER/reference/iid.new.pc.html","id":null,"dir":"Reference","previous_headings":"","what":"New random IID models for m-year to period random effects — iid.new.pc","title":"New random IID models for m-year to period random effects — iid.new.pc","text":"New random IID models m-year period random effects","code":""},{"path":"https://richardli.github.io/SUMMER/reference/iid.new.pc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"New random IID models for m-year to period random effects — iid.new.pc","text":"","code":"iid.new.pc(   cmd = c(\"graph\", \"Q\", \"mu\", \"initial\", \"log.norm.const\", \"log.prior\", \"quit\"),   theta = NULL )"},{"path":"https://richardli.github.io/SUMMER/reference/iid.new.pc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"New random IID models for m-year to period random effects — iid.new.pc","text":"cmd list model components theta log precision","code":""},{"path":"https://richardli.github.io/SUMMER/reference/kenyaPopulationData.html","id":null,"dir":"Reference","previous_headings":"","what":"Kenya 2009 Census Frame and Related Datasets — kenyaPopulationData","title":"Kenya 2009 Census Frame and Related Datasets — kenyaPopulationData","text":"Datasets related 2009 census frame Kenya based 2009 Kenya Population Housing  Census. General population totals estimated 2014. Based 2014 population density  estimates interpolated exponential growth rate 2010 2015 WorldPop data.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/kenyaPopulationData.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Kenya 2009 Census Frame and Related Datasets — kenyaPopulationData","text":"","code":"data(kenyaPopulationData)  easpaKenyaNeonatal  poppaKenya  poppsubKenya"},{"path":"https://richardli.github.io/SUMMER/reference/kenyaPopulationData.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Kenya 2009 Census Frame and Related Datasets — kenyaPopulationData","text":"number data.frames information 2009 Kenya Population Housing Census population Kenya time 2014 Demographic Health Survey.  data.frames adjusted contain information neonatals born 2010-2014 rather general population 2014.  dataset names : easpaKenya, easpaKenyaNeonatal,  poppaKenya, poppsubKenya. object class data.frame 47 rows 12 columns. object class data.frame 47 rows 6 columns. object class data.frame 300 rows 7 columns.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/kenyaPopulationData.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Kenya 2009 Census Frame and Related Datasets — kenyaPopulationData","text":"<http://dhsprogram.com/pubs/pdf/FR308/FR308.pdf>","code":""},{"path":"https://richardli.github.io/SUMMER/reference/kenyaPopulationData.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Kenya 2009 Census Frame and Related Datasets — kenyaPopulationData","text":"Kenya National Bureau Statistics, Ministry Health/Kenya, National AIDS Control Council/Kenya, Kenya Medical Research Institute, National Council Population Development/Kenya, 2015. Kenya Demographic Health Survey 2014. Rockville, Maryland, USA. URL: http://dhsprogram.com/pubs/pdf/FR308/FR308.pdf. Stevens, F.R., Gaughan, .E., Linard, C., Tatem, .J., 2015. Disaggregat- ing census data population mapping using random forests remotely-sensed ancillary data. PloS One 10, e0107042. Tatem, .J., 2017. WorldPop, open data spatial demography. Scientific Data 4.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/logit.html","id":null,"dir":"Reference","previous_headings":"","what":"Logit transformation — logit","title":"Logit transformation — logit","text":"Logit transformation","code":""},{"path":"https://richardli.github.io/SUMMER/reference/logit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Logit transformation — logit","text":"","code":"logit(x)"},{"path":"https://richardli.github.io/SUMMER/reference/logit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Logit transformation — logit","text":"x data","code":""},{"path":"https://richardli.github.io/SUMMER/reference/logit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Logit transformation — logit","text":"logit x","code":""},{"path":"https://richardli.github.io/SUMMER/reference/logit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Logit transformation — logit","text":"","code":"x <- .5 logit(x) #> [1] 0"},{"path":"https://richardli.github.io/SUMMER/reference/logitNormMean.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate the mean of a distribution whose logit is Gaussian — logitNormMean","title":"Calculate the mean of a distribution whose logit is Gaussian — logitNormMean","text":"Adapted logitnorm package.  Calculates mean distribution whose  logit Gaussian. row muSigmaMat mean standard deviation  logit scale.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/logitNormMean.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate the mean of a distribution whose logit is Gaussian — logitNormMean","text":"","code":"logitNormMean(muSigmaMat, logisticApprox = FALSE, ...)"},{"path":"https://richardli.github.io/SUMMER/reference/logitNormMean.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate the mean of a distribution whose logit is Gaussian — logitNormMean","text":"muSigmaMat n x 2 matrix row \\(\\mu\\) \\(\\sigma\\)  logit scale independent random variable. logisticApprox Whether use logistic approximation speed  computation. See details information. ... arguments, passed integrate function","code":""},{"path":"https://richardli.github.io/SUMMER/reference/logitNormMean.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate the mean of a distribution whose logit is Gaussian — logitNormMean","text":"vector expectations specified random variables","code":""},{"path":"https://richardli.github.io/SUMMER/reference/logitNormMean.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate the mean of a distribution whose logit is Gaussian — logitNormMean","text":"\\(\\mbox{logit}(Y) \\sim N(\\mu, \\sigma^2)\\),  function calculates \\(E[Y]\\) via either numerical integration  assuming Y follows logistic distribution. approximation, setting  \\(k = 16 \\sqrt(3) / (15 \\pi)\\), approximate  expectation : $$E[Y] = expit(\\mu / \\sqrt(1 + k^2 \\sigma^2))$$. logistic approximation speeds computation, also sacrifices  accuracy.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/logitNormMean.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Calculate the mean of a distribution whose logit is Gaussian — logitNormMean","text":"John Paige","code":""},{"path":"https://richardli.github.io/SUMMER/reference/logitNormMean.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate the mean of a distribution whose logit is Gaussian — logitNormMean","text":"","code":"mus = c(-5, 0, 5) sigmas = rep(1, 3) logitNormMean(cbind(mus, sigmas)) #> [1] 0.01079679 0.50000000 0.98920321 logitNormMean(cbind(mus, sigmas), TRUE) #> [1] 0.01325606 0.50000000 0.98674394"},{"path":"https://richardli.github.io/SUMMER/reference/makePopIntegrationTab.html","id":null,"dir":"Reference","previous_headings":"","what":"Generating pixellated populations, and population frames — makePopIntegrationTab","title":"Generating pixellated populations, and population frames — makePopIntegrationTab","text":"Functions generating pixellated population information  population frames `area` `subarea` levels.   `area` `subarea` levels can thought big  regions little regions, areas can partitioned  unique sets subareas. example, Admin-1 Admin-2  areas might areas subareas respectively. population totals either  tabulated area x urban/rural level, subarea x urban/rural  level, pixel level specified resolution. Totals  calculated using population density information, shapefiles,  , possibly, preexisting population frames different  areal levels. Note area names unique, similarly  subarea names.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/makePopIntegrationTab.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generating pixellated populations, and population frames — makePopIntegrationTab","text":"","code":"makePopIntegrationTab(   kmRes = 5,   pop,   domainMapDat,   eastLim,   northLim,   mapProjection,   areaMapDat,   subareaMapDat,   areaNameVar = \"NAME_1\",   subareaNameVar = \"NAME_2\",   poppa = NULL,   poppsub = NULL,   stratifyByUrban = TRUE,   areapa = NULL,   areapsub = NULL,   customSubsetPolygons = NULL,   areaPolygonSubsetI = NULL,   subareaPolygonSubsetI = NULL,   mean.neighbor = 50,   delta = 0.1,   returnPoppTables = FALSE,   setNAsToZero = TRUE,   fixZeroPopDensitySubareas = FALSE,   extractMethod = \"bilinear\" )  getPoppsub(   kmRes = 1,   pop,   domainMapDat,   eastLim,   northLim,   mapProjection,   poppa,   areapa = NULL,   areapsub,   subareaMapDat,   subareaNameVar = \"NAME_2\",   stratifyByUrban = TRUE,   areaMapDat = NULL,   areaNameVar = \"NAME_1\",   areaPolygonSubsetI = NULL,   subareaPolygonSubsetI = NULL,   customSubsetPolygons = NULL,   mean.neighbor = 50,   delta = 0.1,   setNAsToZero = TRUE,   fixZeroPopDensitySubareas = FALSE )  adjustPopMat(   popMat,   poppaTarget = NULL,   adjustBy = c(\"area\", \"subarea\"),   stratifyByUrban = TRUE )"},{"path":"https://richardli.github.io/SUMMER/reference/makePopIntegrationTab.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generating pixellated populations, and population frames — makePopIntegrationTab","text":"kmRes resolution pixelated grid km pop Population density raster domainMapDat shapefile representing full spatial domain (e.g. country) eastLim Range km easting spatial domain input projection northLim Range km northing spatial domain input projection mapProjection projection function taking longitude latitude returning easting  northing km. inverse inverse set TRUE. example,  projKenya. Check https://epsg.io/ example best projection EPSG codes  specific countries areaMapDat SpatialPolygonsDataFrame object area level map information subareaMapDat SpatialPolygonsDataFrame object subarea level map information areaNameVar name area variable associated areaMapDat@data  subareaMapDat@data subareaNameVar name subarea variable associated subareaMapDat@data poppa data.frame population per area separated urban/rural. `poppsub`    included, used normalization populations associated    population integration points. Contains variables: area name area popUrb total urban (general) population area popRur total rural (general) population area popTotal total (general) population area pctUrb percentage population area urban (0 100) poppsub data.frame population per subarea separated  urban/rural using population normalization urbanicity  classification. Often based extra fine scale population density grid.  variables: subarea name subarea area name area popUrb total urban (general) population subarea popRur total rural (general) population subarea popTotal total (general) population subarea pctUrb percentage population subarea urban (0 100) stratifyByUrban Whether stratify pixellated grid urban/rural. TRUE,  renormalizes population densities within areas subareas crossed urban/rural areapa list variables: area name area spatialArea spatial area subarea (e.g. km^2) areapsub list variables: subarea name subarea spatialArea spatial area subarea (e.g. km^2) customSubsetPolygons 'SpatialPolygonsDataFrame' 'SpatialPolygons' object subset  grid . option can help reduce computation time relative  constructing whole grid subsetting afterwards. `areaPolygonSubsetI`  `subareaPolygonSubsetI` can used subsetting areas subareas  `areaMapDat` `subareaMapDat`. Must latitude/longitude projection \"EPSG:4326\" areaPolygonSubsetI Index areaMapDat specific area subset grid .  option can help reduce computation time relative constructing whole grid  subsetting afterwards subareaPolygonSubsetI EXPERIMENTAL PURPOSES . Index subareaMapDat  specific area subset grid .  option can help reduce computation time relative constructing whole grid  subsetting afterwards mean.neighbor determining area subarea points nearest  directly fall area. See fields.rdist.near details. delta determining area subarea points nearest  directly fall area. See fields.rdist.near details. returnPoppTables TRUE, poppa poppsub calculated based generated  population integration matrix input area/subarea map data setNAsToZero TRUE, sets NA populations 0. fixZeroPopDensitySubareas TRUE, population density subarea estimated  zero, total population subarea nonzero, population filled  area uniformly extractMethod Either 'bilinear' 'simple'. see `method`  extract popMat Pixellated grid data frame variables `area` `pop`  generated makePopIntegrationTab poppaTarget Target population per area stratified urban rural. format poppa adjustBy Whether adjust population density `area` `subarea` level","code":""},{"path":"https://richardli.github.io/SUMMER/reference/makePopIntegrationTab.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Generating pixellated populations, and population frames — makePopIntegrationTab","text":"makePopIntegrationTab(): Generate pixellated `grid` coordinates (longitude/latitude east/north)  spatial domain given resolution associated population totals, areas, subareas,  urban/rural levels. small areas might  otherwise grid point , custom integration point added  centroid. Sets urbanicity classifications thresholding input population density raster  using area subarea population tables, generates area subarea population  tables population density information already given. Can used integrating  predictions given coordinates area subarea levels using population weights. getPoppsub(): Generate table estimates population totals per subarea x urban/rural combination based population density raster `kmres` resolution \"grid\", including custom integration points subarea small include grid points centroids. adjustPopMat(): Adjust population densities grid based population frame.","code":""},{"path":[]},{"path":"https://richardli.github.io/SUMMER/reference/makePopIntegrationTab.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Generating pixellated populations, and population frames — makePopIntegrationTab","text":"John Paige","code":""},{"path":"https://richardli.github.io/SUMMER/reference/makePopIntegrationTab.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generating pixellated populations, and population frames — makePopIntegrationTab","text":"","code":"if (FALSE) {  library(sp) library(sf) # download Kenya GADM shapefiles from SUMMERdata github repository githubURL <- paste0(\"https://github.com/paigejo/SUMMERdata/blob/main/data/\",                      \"kenyaMaps.rda?raw=true\") tempDirectory = \"~/\" mapsFilename = paste0(tempDirectory, \"/kenyaMaps.rda\") if(!file.exists(mapsFilename)) {   download.file(githubURL,mapsFilename) }  # load it in out = load(mapsFilename) out adm1@data$NAME_1 = as.character(adm1@data$NAME_1) adm1@data$NAME_1[adm1@data$NAME_1 == \"Trans Nzoia\"] = \"Trans-Nzoia\" adm1@data$NAME_1[adm1@data$NAME_1 == \"Elgeyo-Marakwet\"] = \"Elgeyo Marakwet\" adm2@data$NAME_1 = as.character(adm2@data$NAME_1) adm2@data$NAME_1[adm2@data$NAME_1 == \"Trans Nzoia\"] = \"Trans-Nzoia\" adm2@data$NAME_1[adm2@data$NAME_1 == \"Elgeyo-Marakwet\"] = \"Elgeyo Marakwet\"  # some Admin-2 areas have the same name adm2@data$NAME_2 = as.character(adm2@data$NAME_2) adm2@data$NAME_2[(adm2@data$NAME_1 == \"Bungoma\") &                     (adm2@data$NAME_2 == \"Lugari\")] = \"Lugari, Bungoma\" adm2@data$NAME_2[(adm2@data$NAME_1 == \"Kakamega\") &                     (adm2@data$NAME_2 == \"Lugari\")] = \"Lugari, Kakamega\" adm2@data$NAME_2[(adm2@data$NAME_1 == \"Meru\") &                     (adm2@data$NAME_2 == \"Igembe South\")] = \"Igembe South, Meru\" adm2@data$NAME_2[(adm2@data$NAME_1 == \"Tharaka-Nithi\") &                     (adm2@data$NAME_2 == \"Igembe South\")] = \"Igembe South, Tharaka-Nithi\"  # The spatial area of unknown 8 is so small, it causes problems unless its removed or  # unioned with another subarea. Union it with neighboring Kakeguria: newadm2 = adm2 unknown8I = which(newadm2$NAME_2 == \"unknown 8\") newadm2$NAME_2[newadm2$NAME_2 %in% c(\"unknown 8\", \"Kapenguria\")] <-    \"Kapenguria + unknown 8\" admin2.IDs <- newadm2$NAME_2  newadm2@data = cbind(newadm2@data, NAME_2OLD = newadm2@data$NAME_2) newadm2@data$NAME_2OLD = newadm2@data$NAME_2 newadm2@data$NAME_2 = admin2.IDs newadm2$NAME_2 = admin2.IDs temp <- terra::aggregate(as(newadm2, \"SpatVector\"), by=\"NAME_2\")  temp <- sf::st_as_sf(temp) temp <- sf::as_Spatial(temp)  tempData = newadm2@data[-unknown8I,] tempData = tempData[order(tempData$NAME_2),] newadm2 <- SpatialPolygonsDataFrame(temp, tempData, match.ID = F) adm2 = newadm2  # download 2014 Kenya population density TIF file  githubURL <- paste0(\"https://github.com/paigejo/SUMMERdata/blob/main/data/\",                      \"Kenya2014Pop/worldpop_total_1y_2014_00_00.tif?raw=true\") popTIFFilename = paste0(tempDirectory, \"/worldpop_total_1y_2014_00_00.tif\") if(!file.exists(popTIFFilename)) {   download.file(githubURL,popTIFFilename) }  # load it in pop = terra::rast(popTIFFilename)  eastLim = c(-110.6405, 832.4544) northLim = c(-555.1739, 608.7130)  ## Construct poppsubKenya, a table of urban/rural general population totals  ## in each subarea. Technically, this is not necessary since we can load in  ## poppsubKenya via data(kenyaPopulationData). First, we will need to calculate  ## the areas in km^2 of the areas and subareas   # use Lambert equal area projection of areas (Admin-1) and subareas (Admin-2) midLon = mean(adm1@bbox[1,]) midLat = mean(adm1@bbox[2,]) p4s = paste0(\"+proj=laea +x_0=0 +y_0=0 +lon_0=\", midLon,               \" +lat_0=\", midLat, \" +units=km\")  adm1_sf = st_as_sf(adm1) adm1proj_sf = st_transform(adm1_sf, p4s) adm1proj = as(adm1proj_sf, \"Spatial\")  adm2_sf = st_as_sf(adm2) adm2proj_sf = st_transform(adm2_sf, p4s) adm2proj = as(adm2proj_sf, \"Spatial\")  # now calculate spatial area in km^2 admin1Areas = as.numeric(st_area(adm1proj_sf)) admin2Areas = as.numeric(st_area(adm2proj_sf))  areapaKenya = data.frame(area=adm1proj@data$NAME_1, spatialArea=admin1Areas) areapsubKenya = data.frame(area=adm2proj@data$NAME_1, subarea=adm2proj@data$NAME_2,                             spatialArea=admin2Areas)  # Calculate general population totals at the subarea (Admin-2) x urban/rural  # level and using 1km resolution population grid. Assign urbanicity by  # thresholding population density based on estimated proportion population  # urban/rural, making sure total area (Admin-1) urban/rural populations in  # each area matches poppaKenya. require(fields) # NOTE: the following function will typically take ~15-20 minutes. Can speed up  #       by setting kmRes to be higher, but we recommend fine resolution for  #       this step, since it only needs to be done once. Instead of running this,  #       you can simply run data(kenyaPopulationData) system.time(poppsubKenya <- getPoppsub(   kmRes=1, pop=pop, domainMapDat=adm0,   eastLim=eastLim, northLim=northLim, mapProjection=projKenya,   poppa = poppaKenya, areapa=areapaKenya, areapsub=areapsubKenya,    areaMapDat=adm1, subareaMapDat=adm2,    areaNameVar = \"NAME_1\", subareaNameVar=\"NAME_2\"))  # Now generate a general population integration table at 5km resolution,  # based on subarea (Admin-2) x urban/rural population totals. This takes  # ~1 minute system.time(popMatKenya <- makePopIntegrationTab(   kmRes=5, pop=pop, domainMapDat=adm0,   eastLim=eastLim, northLim=northLim, mapProjection=projKenya,   poppa = poppaKenya, poppsub=poppsubKenya,    areaMapDat = adm1, subareaMapDat = adm2,   areaNameVar = \"NAME_1\", subareaNameVar=\"NAME_2\"))  ## Adjust popMat to be target (neonatal) rather than general population density. First ## creat the target population frame ## (these numbers are based on IPUMS microcensus data) mothersPerHouseholdUrb = 0.3497151 childrenPerMotherUrb = 1.295917 mothersPerHouseholdRur = 0.4787696 childrenPerMotherRur = 1.455222 targetPopPerStratumUrban = easpaKenya$HHUrb * mothersPerHouseholdUrb * childrenPerMotherUrb targetPopPerStratumRural = easpaKenya$HHRur * mothersPerHouseholdRur * childrenPerMotherRur easpaKenyaNeonatal = easpaKenya easpaKenyaNeonatal$popUrb = targetPopPerStratumUrban easpaKenyaNeonatal$popRur = targetPopPerStratumRural easpaKenyaNeonatal$popTotal = easpaKenyaNeonatal$popUrb + easpaKenyaNeonatal$popRur easpaKenyaNeonatal$pctUrb = 100 * easpaKenyaNeonatal$popUrb / easpaKenyaNeonatal$popTotal easpaKenyaNeonatal$pctTotal =    100 * easpaKenyaNeonatal$popTotal / sum(easpaKenyaNeonatal$popTotal)  # Generate the target population density by scaling the current population density grid  # at the Admin1 x urban/rural level popMatKenyaNeonatal = adjustPopMat(popMatKenya, easpaKenyaNeonatal)  # Generate neonatal population table from the neonatal population integration matrix. # This is technically not necessary for population simulation purposes, but is here  # for illustrative purposes poppsubKenyaNeonatal = poppRegionFromPopMat(popMatKenyaNeonatal, popMatKenyaNeonatal$subarea) poppsubKenyaNeonatal = cbind(subarea=poppsubKenyaNeonatal$region,                               area=adm2@data$NAME_1[match(poppsubKenyaNeonatal$region,                                 adm2@data$NAME_2)],                               poppsubKenyaNeonatal[,-1]) print(head(poppsubKenyaNeonatal)) }"},{"path":"https://richardli.github.io/SUMMER/reference/mapEstimates.html","id":null,"dir":"Reference","previous_headings":"","what":"Mapping estimates for svysae object — mapEstimates","title":"Mapping estimates for svysae object — mapEstimates","text":"Mapping estimates svysae object","code":""},{"path":"https://richardli.github.io/SUMMER/reference/mapEstimates.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mapping estimates for svysae object — mapEstimates","text":"","code":"mapEstimates(x, geo.data, variable, viridis.option = \"viridis\")"},{"path":"https://richardli.github.io/SUMMER/reference/mapEstimates.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mapping estimates for svysae object — mapEstimates","text":"x syvsae object geo.data sf object containing polygon data small areas. One columns named domain contain domain labels. variable posterior summary variable plot. May one \"median\", \"mean\", \"var\". viridis.option viridis color scheme","code":""},{"path":"https://richardli.github.io/SUMMER/reference/mapEstimates.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Mapping estimates for svysae object — mapEstimates","text":"ggplot containing map small area posterior summary statistics","code":""},{"path":"https://richardli.github.io/SUMMER/reference/mapEstimates.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mapping estimates for svysae object — mapEstimates","text":"","code":"if (FALSE) { data(DemoData2) data(DemoMap2) library(survey) des0 <- svydesign(ids = ~clustid+id, strata = ~strata,                   weights = ~weights, data = DemoData2, nest = TRUE) Xmat <- aggregate(age~region, data = DemoData2, FUN = mean) geo.data <- sf::st_as_sf(DemoMap2$geo) geo.data$domain <- geo.data$REGNAME cts.res <- smoothArea(tobacco.use ~ 1,                       domain = ~region,                       design = des0,                       adj.mat = DemoMap2$Amat,                        pc.u = 1,                       pc.alpha = 0.01,                       pc.u.phi = 0.5,                       pc.alpha.phi = 2/3,                       return.samples = TRUE) mapEstimates(cts.res, geo.data = geo.data, variable = \"median\") mapEstimates(cts.res, geo.data = geo.data, variable = \"var\") }"},{"path":"https://richardli.github.io/SUMMER/reference/mapPlot.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot region-level variables on a map — mapPlot","title":"Plot region-level variables on a map — mapPlot","text":"function visualizes map different variables. input data frame can either long wide format.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/mapPlot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot region-level variables on a map — mapPlot","text":"","code":"mapPlot(   data = NULL,   variables,   values = NULL,   labels = NULL,   geo,   by.data,   by.geo,   is.long = FALSE,   size = 0.5,   removetab = FALSE,   border = \"gray20\",   ncol = NULL,   ylim = NULL,   legend.label = NULL,   per1000 = FALSE,   clean = TRUE,   size.label = 2,   add.adj = FALSE,   color.adj = \"red\",   alpha.adj = 0.85,   direction = 1,   cut = NULL )"},{"path":"https://richardli.github.io/SUMMER/reference/mapPlot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot region-level variables on a map — mapPlot","text":"data data frame variables plotted. null, map produced. variables vector variables plotted. long format data used, one variable can selected values column corresponding values plotted, used long format data used labels vector labels use variable, used wide format data used geo SpatialPolygonsDataFrame object map .data column name specifying region names data .geo variable name specifying region names data .long logical indicator whether data long format, default FALSE size size border removetab logical indicator show tab label, applicable one tab present. border color border ncol number columns output tabs ylim range values plotted. legend.label Label color legend. per1000 logical indicator plot mortality rates rates per 1,000 live births. Note added comparison data always probability scale. clean remove coordinates cleaner layout, default TRUE. size.label size label regions. add.adj logical indicator add edges connected regions. color.adj color adjacency matrix edges. alpha.adj alpha level (transparency) adjacency matrix edges. direction Direction color scheme. can either 1 (smaller values darker) -1 (higher values darker). Default set 1. cut vector values cut continuous scale color discrete intervals.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/mapPlot.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Plot region-level variables on a map — mapPlot","text":"Zehang Richard Li","code":""},{"path":"https://richardli.github.io/SUMMER/reference/mapPlot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot region-level variables on a map — mapPlot","text":"","code":"if (FALSE) { data(DemoMap) # Plotting data in the long format dat <- data.frame(region = rep(c(\"central\",  \"eastern\", \"northern\", \"western\"), 3), year = rep(c(1980, 1990, 2000), each = 4), values = stats::rnorm(12)) utils::head(dat) mapPlot(dat, variables = \"year\", values = \"values\", by.data = \"region\", geo = DemoMap$geo, by.geo = \"NAME_final\", is.long = TRUE) dat <- data.frame(region = c(\"central\",  \"eastern\", \"northern\", \"western\"), Year1 = stats::rnorm(4), Year2 = stats::rnorm(4), Year3 = stats::rnorm(4)) utils::head(dat) mapPlot(dat, variables = c(\"Year1\", \"Year2\", \"Year3\"),  labels = c(1980, 1990, 2000), by.data = \"region\", geo = DemoMap$geo, by.geo = \"NAME_final\", is.long = FALSE)  }"},{"path":"https://richardli.github.io/SUMMER/reference/mapPoints.html","id":null,"dir":"Reference","previous_headings":"","what":"Map GPS points to polygon regions — mapPoints","title":"Map GPS points to polygon regions — mapPoints","text":"Map GPS points polygon regions","code":""},{"path":"https://richardli.github.io/SUMMER/reference/mapPoints.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Map GPS points to polygon regions — mapPoints","text":"","code":"mapPoints(data, geo, long, lat, names)"},{"path":"https://richardli.github.io/SUMMER/reference/mapPoints.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Map GPS points to polygon regions — mapPoints","text":"data point data two columns GPS locations. geo SpatialPolygonsDataFrame map long column name longitudinal coordinate data lat column name latitude coordinate data names character vector region ids added neighbours list","code":""},{"path":"https://richardli.github.io/SUMMER/reference/mapPoints.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Map GPS points to polygon regions — mapPoints","text":"Spatial djacency matrix.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/mapPoints.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Map GPS points to polygon regions — mapPoints","text":"Zehang Richard Li","code":""},{"path":"https://richardli.github.io/SUMMER/reference/mapPoints.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Map GPS points to polygon regions — mapPoints","text":"","code":"data(DemoMap)  dat <- data.frame(ID = c(1,2,3), lon = c(32.2, 33.7, 33), lat = c(0.1, 0.9, 2.8)) dat2 <- mapPoints(dat, DemoMap$geo, long = \"lon\", lat = \"lat\", names = \"REGNAME\") dat2 #>   ID  lon lat  REGNAME #> 1  1 32.2 0.1  central #> 2  2 33.7 0.9  eastern #> 3  3 33.0 2.8 northern"},{"path":"https://richardli.github.io/SUMMER/reference/plot.SUMMERproj.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot projection output. — plot.SUMMERproj","title":"Plot projection output. — plot.SUMMERproj","text":"Plot projection output.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/plot.SUMMERproj.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot projection output. — plot.SUMMERproj","text":"","code":"# S3 method for SUMMERproj plot(   x,   year_label = c(\"85-89\", \"90-94\", \"95-99\", \"00-04\", \"05-09\", \"10-14\", \"15-19\"),   year_med = c(1987, 1992, 1997, 2002, 2007, 2012, 2017),   is.subnational = TRUE,   proj_year = 2015,   data.add = NULL,   option.add = list(point = NULL, lower = NULL, upper = NULL, by = NULL),   color.add = \"black\",   label.add = NULL,   dodge.width = 1,   plot.CI = NULL,   per1000 = FALSE,   color.CI = NULL,   alpha.CI = 0.5,   ... )"},{"path":"https://richardli.github.io/SUMMER/reference/plot.SUMMERproj.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot projection output. — plot.SUMMERproj","text":"x output getSmoothed year_label labels periods year_med labels middle years period, used yearly period estimates plotted. case, year_med specifies period estimates aligned. .subnational logical indicator whether data contains subnational estimates proj_year first year projections made, .e., data available. data.add data frame Comparisons data points add graph. can , example, raw direct estimates. data frame merged projections column 'region' 'years'. Except two columns, dataset Comparisons columns names overlapping getSmoothed output. option.add list options specifying variable names points plot, lower upper bounds, grouping variable. intended used add Comparisons estimates plot smoothed estimates. See examples details. color.add color Comparisons data points plot. label.add label Comparisons data points legend. dodge.width amount add data points year avoid overlap. Default 1. plot.CI logical indicator whether plot error bars. per1000 logical indicator plot mortality rates rates per 1,000 live births. Note added comparison data always probability scale. color.CI color error bars credible interval. alpha.CI alpha (transparency) error bars credible interval. ... optional arguments, see details","code":""},{"path":[]},{"path":"https://richardli.github.io/SUMMER/reference/plot.SUMMERproj.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Plot projection output. — plot.SUMMERproj","text":"Zehang Richard Li","code":""},{"path":"https://richardli.github.io/SUMMER/reference/plot.SUMMERproj.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot projection output. — plot.SUMMERproj","text":"","code":"if (FALSE) { years <- levels(DemoData[[1]]$time)  # obtain direct estimates data <- getDirectList(births = DemoData,  years = years,   regionVar = \"region\", timeVar = \"time\",  clusterVar = \"~clustid+id\",  ageVar = \"age\", weightsVar = \"weights\",  geo.recode = NULL) # obtain direct estimates data_multi <- getDirectList(births = DemoData, years = years,   regionVar = \"region\",  timeVar = \"time\", clusterVar = \"~clustid+id\",   ageVar = \"age\", weightsVar = \"weights\", geo.recode = NULL) data <- aggregateSurvey(data_multi)  #  national model years.all <- c(years, \"15-19\") fit1 <- smoothDirect(data = data, geo = NULL, Amat = NULL,    year_label = years.all, year_range = c(1985, 2019),    rw = 2, is.yearly=FALSE, m = 5) out1 <- getSmoothed(fit1) plot(out1, is.subnational=FALSE)  #  subnational model fit2 <- smoothDirect(data = data, geo = geo, Amat = mat,    year_label = years.all, year_range = c(1985, 2019),    rw = 2, is.yearly=TRUE, m = 5, type.st = 4) out2 <- getSmoothed(fit2) plot(out2, is.yearly=TRUE, is.subnational=TRUE)   }"},{"path":"https://richardli.github.io/SUMMER/reference/poppRegionFromPopMat.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate a population frame of a similar format to poppa argument of simPopCustom with a custom set of regions — poppRegionFromPopMat","title":"Generate a population frame of a similar format to poppa argument of simPopCustom with a custom set of regions — poppRegionFromPopMat","text":"Generate population frame similar format poppa argument simPopCustom custom set regions","code":""},{"path":"https://richardli.github.io/SUMMER/reference/poppRegionFromPopMat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate a population frame of a similar format to poppa argument of simPopCustom with a custom set of regions — poppRegionFromPopMat","text":"","code":"poppRegionFromPopMat(popMat, regions)"},{"path":"https://richardli.github.io/SUMMER/reference/poppRegionFromPopMat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate a population frame of a similar format to poppa argument of simPopCustom with a custom set of regions — poppRegionFromPopMat","text":"popMat Pixellated grid data frame variables `area` `pop`. Assumed stratified urban/rural regions character vector length nPixels giving custom set regions generate  population frame using population density","code":""},{"path":"https://richardli.github.io/SUMMER/reference/poppRegionFromPopMat.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate a population frame of a similar format to poppa argument of simPopCustom with a custom set of regions — poppRegionFromPopMat","text":"table population totals region","code":""},{"path":"https://richardli.github.io/SUMMER/reference/poppRegionFromPopMat.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generate a population frame of a similar format to poppa argument of simPopCustom with a custom set of regions — poppRegionFromPopMat","text":"Urbanicity thresholds set based region's percent population  urban. Intended helper function getPoppsub,  can also used custom sets regions (.e. just 2  areal levels: area subarea).","code":""},{"path":[]},{"path":"https://richardli.github.io/SUMMER/reference/poppRegionFromPopMat.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Generate a population frame of a similar format to poppa argument of simPopCustom with a custom set of regions — poppRegionFromPopMat","text":"John Paige","code":""},{"path":"https://richardli.github.io/SUMMER/reference/poppRegionFromPopMat.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate a population frame of a similar format to poppa argument of simPopCustom with a custom set of regions — poppRegionFromPopMat","text":"","code":"if (FALSE) { data(kenyaPopulationData)  #' # download Kenya GADM shapefiles from SUMMERdata github repository githubURL <- \"https://github.com/paigejo/SUMMERdata/blob/main/data/kenyaMaps.rda?raw=true\" tempDirectory = \"~/\" mapsFilename = paste0(tempDirectory, \"/kenyaMaps.rda\") if(!file.exists(mapsFilename)) {   download.file(githubURL,mapsFilename) }  # load it in out = load(mapsFilename) out adm1@data$NAME_1 = as.character(adm1@data$NAME_1) adm1@data$NAME_1[adm1@data$NAME_1 == \"Trans Nzoia\"] = \"Trans-Nzoia\" adm1@data$NAME_1[adm1@data$NAME_1 == \"Elgeyo-Marakwet\"] = \"Elgeyo Marakwet\" adm2@data$NAME_1 = as.character(adm2@data$NAME_1) adm2@data$NAME_1[adm2@data$NAME_1 == \"Trans Nzoia\"] = \"Trans-Nzoia\" adm2@data$NAME_1[adm2@data$NAME_1 == \"Elgeyo-Marakwet\"] = \"Elgeyo Marakwet\"  # some Admin-2 areas have the same name adm2@data$NAME_2 = as.character(adm2@data$NAME_2) adm2@data$NAME_2[(adm2@data$NAME_1 == \"Bungoma\") &    (adm2@data$NAME_2 == \"Lugari\")] = \"Lugari, Bungoma\" adm2@data$NAME_2[(adm2@data$NAME_1 == \"Kakamega\") &    (adm2@data$NAME_2 == \"Lugari\")] = \"Lugari, Kakamega\" adm2@data$NAME_2[(adm2@data$NAME_1 == \"Meru\") &    (adm2@data$NAME_2 == \"Igembe South\")] = \"Igembe South, Meru\" adm2@data$NAME_2[(adm2@data$NAME_1 == \"Tharaka-Nithi\") &    (adm2@data$NAME_2 == \"Igembe South\")] = \"Igembe South, Tharaka-Nithi\"  # The spatial area of unknown 8 is so small, it causes problems unless  # its removed or unioned with another subarea. Union it with neighboring  # Kakeguria: newadm2 = adm2 unknown8I = which(newadm2$NAME_2 == \"unknown 8\") newadm2$NAME_2[newadm2$NAME_2 %in% c(\"unknown 8\", \"Kapenguria\")] <- \"Kapenguria + unknown 8\" admin2.IDs <- newadm2$NAME_2  newadm2@data = cbind(newadm2@data, NAME_2OLD = newadm2@data$NAME_2) newadm2@data$NAME_2OLD = newadm2@data$NAME_2 newadm2@data$NAME_2 = admin2.IDs newadm2$NAME_2 = admin2.IDs temp <- terra::aggregate(as(newadm2, \"SpatVector\"), by=\"NAME_2\")  library(sf) temp <- sf::st_as_sf(temp) temp <- sf::as_Spatial(temp)  tempData = newadm2@data[-unknown8I,] tempData = tempData[order(tempData$NAME_2),] newadm2 <- SpatialPolygonsDataFrame(temp, tempData, match.ID = F) adm2 = newadm2  # download 2014 Kenya population density TIF file  githubURL <- paste0(\"https://github.com/paigejo/SUMMERdata/blob/main/data/\",                      \"Kenya2014Pop/worldpop_total_1y_2014_00_00.tif?raw=true\") popTIFFilename = paste0(tempDirectory, \"/worldpop_total_1y_2014_00_00.tif\") if(!file.exists(popTIFFilename)) {   download.file(githubURL,popTIFFilename) }  # load it in pop = terra::rast(popTIFFilename)  eastLim = c(-110.6405, 832.4544) northLim = c(-555.1739, 608.7130)  require(fields)  # Now generate a general population integration table at 5km resolution,  # based on subarea (Admin-2) x urban/rural population totals. This takes  # ~1 minute system.time(popMatKenya <- makePopIntegrationTab(   kmRes=5, pop=pop, domainMapDat=adm0,   eastLim=eastLim, northLim=northLim, mapProjection=projKenya,   poppa = poppaKenya, poppsub=poppsubKenya,    areaMapDat = adm1, subareaMapDat = adm2,   areaNameVar = \"NAME_1\", subareaNameVar=\"NAME_2\"))    out = poppRegionFromPopMat(popMatKenya, popMatKenya$area) out poppaKenya  out = poppRegionFromPopMat(popMatKenya, popMatKenya$subarea) out poppsubKenya  popMatKenyaUnstratified = popMatKenya popMatKenyaUnstratified$urban = NULL out = poppRegionFromPopMat(popMatKenyaUnstratified, popMatKenyaUnstratified$area) out poppaKenya }"},{"path":"https://richardli.github.io/SUMMER/reference/print.SUMMERmodel.html","id":null,"dir":"Reference","previous_headings":"","what":"Print method for the smoothing models. — print.SUMMERmodel","title":"Print method for the smoothing models. — print.SUMMERmodel","text":"function print method class SUMMERmodel.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/print.SUMMERmodel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print method for the smoothing models. — print.SUMMERmodel","text":"","code":"# S3 method for SUMMERmodel print(x, ...)"},{"path":"https://richardli.github.io/SUMMER/reference/print.SUMMERmodel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print method for the smoothing models. — print.SUMMERmodel","text":"x output smoothDirect smoothCluster ... used","code":""},{"path":[]},{"path":"https://richardli.github.io/SUMMER/reference/print.SUMMERmodel.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Print method for the smoothing models. — print.SUMMERmodel","text":"Zehang Li","code":""},{"path":"https://richardli.github.io/SUMMER/reference/print.SUMMERmodel.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Print method for the smoothing models. — print.SUMMERmodel","text":"","code":"if (FALSE) {   library(SUMMER)   library(dplyr)   data(DemoData)    # Smooth Direct Model   years <- levels(DemoData[[1]]$time)   # obtain direct estimates   data_multi <- getDirectList(births = DemoData, years = years,   regionVar = \"region\",  timeVar = \"time\", clusterVar = \"~clustid+id\",   ageVar = \"age\", weightsVar = \"weights\", geo.recode = NULL)   data <- aggregateSurvey(data_multi)      years.all <- c(years, \"15-19\")   fit <- smoothDirect(data = data, Amat = NULL,    year_label = years.all, year_range = c(1985, 2019),    time.model = 'rw2', is.yearly=FALSE, m = 5)   fit    # Cluster-level Model   counts.all <- NULL   for(i in 1:length(DemoData)){   counts <- getCounts(DemoData[[i]][, c(\"clustid\", \"time\", \"age\", \"died\",                                        \"region\", \"strata\")],            variables = 'died', by = c(\"age\", \"clustid\", \"region\",                                          \"time\", \"strata\"))   counts <- counts %>% mutate(cluster = clustid, years = time, Y=died)   counts$strata <- gsub(\".*\\\\.\",\"\",counts$strata)   counts$survey <- names(DemoData)[i]    counts.all <- rbind(counts.all, counts)   }      # fit cluster-level model on the periods   periods <- levels(DemoData[[1]]$time)   fit <- smoothCluster(data = counts.all,       Amat = DemoMap$Amat,       time.model = \"rw2\",       st.time.model = \"rw1\",      strata.time.effect =  TRUE,       survey.effect = TRUE,      family = \"betabinomial\",      year_label = c(periods, \"15-19\"))   fit }"},{"path":"https://richardli.github.io/SUMMER/reference/print.SUMMERmodel.svy.html","id":null,"dir":"Reference","previous_headings":"","what":"Print method for the smoothing models from smoothSurvey. — print.SUMMERmodel.svy","title":"Print method for the smoothing models from smoothSurvey. — print.SUMMERmodel.svy","text":"function print method class SUMMERmodel.svy.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/print.SUMMERmodel.svy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print method for the smoothing models from smoothSurvey. — print.SUMMERmodel.svy","text":"","code":"# S3 method for SUMMERmodel.svy print(x, ...)"},{"path":"https://richardli.github.io/SUMMER/reference/print.SUMMERmodel.svy.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print method for the smoothing models from smoothSurvey. — print.SUMMERmodel.svy","text":"x output smoothSurvey. ... used","code":""},{"path":[]},{"path":"https://richardli.github.io/SUMMER/reference/print.SUMMERmodel.svy.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Print method for the smoothing models from smoothSurvey. — print.SUMMERmodel.svy","text":"Zehang Li","code":""},{"path":"https://richardli.github.io/SUMMER/reference/print.SUMMERmodel.svy.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Print method for the smoothing models from smoothSurvey. — print.SUMMERmodel.svy","text":"","code":"if (FALSE) { data(DemoData2) data(DemoMap2) fit0 <- smoothSurvey(data=DemoData2,   Amat=DemoMap2$Amat, responseType=\"binary\",  responseVar=\"tobacco.use\", strataVar=\"strata\",  weightVar=\"weights\", regionVar=\"region\",  clusterVar = \"~clustid+id\", CI = 0.95) fit0 }"},{"path":"https://richardli.github.io/SUMMER/reference/print.SUMMERprojlist.html","id":null,"dir":"Reference","previous_headings":"","what":"Print method for the combined projection output. — print.SUMMERprojlist","title":"Print method for the combined projection output. — print.SUMMERprojlist","text":"function print method class SUMMERprojlist.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/print.SUMMERprojlist.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print method for the combined projection output. — print.SUMMERprojlist","text":"","code":"# S3 method for SUMMERprojlist print(x, ...)"},{"path":"https://richardli.github.io/SUMMER/reference/print.SUMMERprojlist.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print method for the combined projection output. — print.SUMMERprojlist","text":"x output getSmoothed ... used","code":""},{"path":"https://richardli.github.io/SUMMER/reference/print.SUMMERprojlist.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Print method for the combined projection output. — print.SUMMERprojlist","text":"Zehang Li","code":""},{"path":"https://richardli.github.io/SUMMER/reference/print.SUMMERprojlist.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Print method for the combined projection output. — print.SUMMERprojlist","text":"","code":"if (FALSE) {  library(SUMMER)  library(dplyr)  data(DemoData)  # Create dataset of counts  counts.all <- NULL  for(i in 1:length(DemoData)){  counts <- getCounts(DemoData[[i]][, c(\"clustid\", \"time\", \"age\", \"died\",                                       \"region\", \"strata\")],           variables = 'died', by = c(\"age\", \"clustid\", \"region\",                                         \"time\", \"strata\"))  counts <- counts %>% mutate(cluster = clustid, years = time, Y=died)  counts$strata <- gsub(\".*\\\\.\",\"\",counts$strata)  counts$survey <- names(DemoData)[i]   counts.all <- rbind(counts.all, counts)  }    # fit cluster-level model on the periods  periods <- levels(DemoData[[1]]$time)  fit <- smoothCluster(data = counts.all,      Amat = DemoMap$Amat,      time.model = \"rw2\",      st.time.model = \"rw1\",     strata.time.effect =  TRUE,      survey.effect = TRUE,     family = \"betabinomial\",     year_label = c(periods, \"15-19\"))  summary(fit)  est <- getSmoothed(fit, nsim = 1000) }"},{"path":"https://richardli.github.io/SUMMER/reference/projKenya.html","id":null,"dir":"Reference","previous_headings":"","what":"Map projection for Kenya — projKenya","title":"Map projection for Kenya — projKenya","text":"Projection specifically chosen Kenya. Project lat/lon northing/easting  kilometers.  Uses epsg=21097 km units. May work systems due  differences behavior different PROJ GDAL versions.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/projKenya.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Map projection for Kenya — projKenya","text":"","code":"projKenya(lon, lat = NULL, inverse = FALSE)"},{"path":"https://richardli.github.io/SUMMER/reference/projKenya.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Map projection for Kenya — projKenya","text":"lon either longitude , inverse == TRUE, easting km lat either latitude , inverse == TRUE, northing km inverse FALSE, projects lon/lat easting/northing.  Else easting/northing lon/lat","code":""},{"path":"https://richardli.github.io/SUMMER/reference/projKenya.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Map projection for Kenya — projKenya","text":"2 column matrix easting/northing coordinates km inverse == FALSE. Otherwise, 2 column matrix longitude/latitude coordinates.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/projKenya.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Map projection for Kenya — projKenya","text":"John Paige","code":""},{"path":"https://richardli.github.io/SUMMER/reference/projKenya.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Map projection for Kenya — projKenya","text":"","code":"eastLim = c(-110.6405, 832.4544) northLim = c(-555.1739, 608.7130) coordMatrixEN = cbind(eastLim, northLim) coordMatrixLL = projKenya(coordMatrixEN, inverse=TRUE)  coordMatrixLL #>           lon       lat #> [1,] 33.50075 -5.002281 #> [2,] 42.00093  5.496810 # if the coordMatrixLL isn't the following, projKenya may not support  # your installation of GDAL and/or PROJ: #      east north # [1,] 33.5  -5.0 # [2,] 42.0   5.5  projKenya(coordMatrixLL, inverse=FALSE) #>           east     north #> [1,] -110.6405 -555.1739 #> [2,]  832.4544  608.7130 # regardless of your PROJ/GDAL installations, the result of the  # above line of could should be: #            lon       lat # [1,] -110.6405 -555.1739 # [2,]  832.4544  608.7130"},{"path":"https://richardli.github.io/SUMMER/reference/ridgePlot.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate and plot posterior densities of the projected estimates — ridgePlot","title":"Calculate and plot posterior densities of the projected estimates — ridgePlot","text":"function ridgePlot replaces previous function name getSmoothedDensity (version 1.0.0).","code":""},{"path":"https://richardli.github.io/SUMMER/reference/ridgePlot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate and plot posterior densities of the projected estimates — ridgePlot","text":"","code":"ridgePlot(   x = NULL,   nsim = 1000,   draws = NULL,   year_plot = NULL,   strata_plot = NULL,   by.year = TRUE,   ncol = 4,   scale = 2,   per1000 = FALSE,   order = 0,   direction = 1,   linewidth = 0.5,   results = NULL,   save.density = FALSE,   ... )  getSmoothedDensity(   x = NULL,   nsim = 1000,   draws = NULL,   year_plot = NULL,   strata_plot = NULL,   by.year = TRUE,   ncol = 4,   scale = 2,   per1000 = FALSE,   order = 0,   direction = 1,   linewidth = 0.5,   results = NULL,   save.density = FALSE,   ... )"},{"path":"https://richardli.github.io/SUMMER/reference/ridgePlot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate and plot posterior densities of the projected estimates — ridgePlot","text":"x output smoothDirect smoothed direct estimates, smoothCluster cluster-level estimates. nsim number posterior draws take. used cluster-level models draws NULL. Otherwise posterior draws draws used instead without resampling. draws Output getSmoothed save.draws set TRUE. argument allows previously sampled draws (setting save.draws TRUE) used new aggregation tasks. argument used cluster-level models. year_plot vector indicate years plot strata_plot Name strata plot. specified, overall plotted. .year logical indicator whether output uses years facets. ncol number columns output figure. scale numerical value controlling height density plots. per1000 logical indicator multiply results 1000. order order regions .year set TRUE. Negative values indicate regions ordered high low posterior medians top bottom. Positive values indicate low high. 0 indicate alphabetic orders. direction Direction color scheme. can either 1 (smaller values darker) -1 (higher values darker). Default set 1. linewidth width ridgeline. results output ridgePlot returned object save.density = TRUE. argument can specified avoid calculating densities visualization changes. save.density Logical indicator whether densities returned ggplot object. set TRUE, output list consisting (1) data frame computed densities (2) ggplot object plot. ... additional configurations passed inla.posterior.sample.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/ridgePlot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate and plot posterior densities of the projected estimates — ridgePlot","text":"ridge plot density,  save.density = TRUE, also data frame calculated densities","code":""},{"path":[]},{"path":"https://richardli.github.io/SUMMER/reference/ridgePlot.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Calculate and plot posterior densities of the projected estimates — ridgePlot","text":"Zehang Richard Li","code":""},{"path":"https://richardli.github.io/SUMMER/reference/ridgePlot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate and plot posterior densities of the projected estimates — ridgePlot","text":"","code":"if (FALSE) { years <- levels(DemoData[[1]]$time)  data <- getDirectList(births = DemoData,  years = years,   regionVar = \"region\", timeVar = \"time\",  clusterVar = \"~clustid+id\",  ageVar = \"age\", weightsVar = \"weights\",  geo.recode = NULL) # obtain direct estimates data_multi <- getDirectList(births = DemoData, years = years,   regionVar = \"region\",  timeVar = \"time\", clusterVar = \"~clustid+id\",   ageVar = \"age\", weightsVar = \"weights\", geo.recode = NULL) data <- aggregateSurvey(data_multi)  #  national model years.all <- c(years, \"15-19\") fit1 <- smoothDirect(data = data, geo = NULL, Amat = NULL,    year_label = years.all, year_range = c(1985, 2019),    rw = 2, m = 5) ## Plot marginal posterior densities over time ridgePlot(fit1, year_plot = years.all,            ncol = 4, by.year = FALSE)  #  subnational model fit2 <- smoothDirect(data = data, geo = DemoMap$geo, Amat = DemoMap$Amat,    year_label = years.all, year_range = c(1985, 2019),    rw = 2, m = 5, type.st = 1)  # Plot marginal posterior densities over time (regions are ordered alphabetically) ridgePlot(fit2, year_plot = years.all, ncol = 4)  # Re-order the regions and save the density to avoid re-compute later density <- ridgePlot(fit2, year_plot = years.all,  ncol = 4, per1000 = TRUE, order = -1, save.density = TRUE) density$g  # Show each region (instead of each year) in a panel  ## Instead of recalculate the posteriors, we can use previously calculated densities as input  ridgePlot(results = density, year_plot = years.all,  ncol = 4, by.year=FALSE, per1000 = TRUE)  # Show more years ridgePlot(results = density, year_plot = c(1990:2019),  ncol = 4, by.year=FALSE, per1000 = TRUE)    }"},{"path":"https://richardli.github.io/SUMMER/reference/rst.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate spatial and temporal random effects — rst","title":"Simulate spatial and temporal random effects — rst","text":"function simulates spatial temporal random effects mean zero. method described Algorithm 3.1 Rue & Held 2015.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/rst.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate spatial and temporal random effects — rst","text":"","code":"rst(   n = 1,   type = c(\"s\", \"t\", \"st\")[1],   type.s = \"ICAR\",   type.t = c(\"RW1\", \"RW2\")[2],   Amat = NULL,   n.t = NULL,   scale.model = TRUE )"},{"path":"https://richardli.github.io/SUMMER/reference/rst.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate spatial and temporal random effects — rst","text":"n sample size type type random effects: temporal (t), spatial (s), spatial-temporal (st) type.s type spatial random effect, currently ICAR available type.t type temporal random effect, currently RW1 RW2 available Amat adjacency matrix spatial regions n.t number time points temporal random effect scale.model logical indicator whether scale random effects unit generalized variance. See Sørbye 2013 details","code":""},{"path":"https://richardli.github.io/SUMMER/reference/rst.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate spatial and temporal random effects — rst","text":"matrix (spatial temporal) three-dimensional array (spatial-temporal) random effects.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/rst.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Simulate spatial and temporal random effects — rst","text":"Rue, H., & Held, L. (2005). Gaussian Markov random fields: theory applications. CRC press. Sørbye, S. H. (2013). Tutorial: Scaling IGMRF-models R-INLA. Department Mathematics Statistics, University Tromsø.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/rst.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Simulate spatial and temporal random effects — rst","text":"Zehang Richard Li","code":""},{"path":"https://richardli.github.io/SUMMER/reference/rst.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulate spatial and temporal random effects — rst","text":"","code":"if (FALSE) { data(DemoMap) ## Spatial random effects  out <- rst(n=10000, type = \"s\", Amat = DemoMap$Amat) # To verify the mean under the conditional specification mean(out[,1] - apply(out[,c(2,3,4)], 1, mean))   mean(out[,2] - apply(out[,c(1,3)], 1, mean))  mean(out[,3] - apply(out[,c(1,2,4)], 1, mean))   mean(out[,4] - apply(out[,c(1,3)], 1, mean))   ## Temporal random effects (RW1) out <- rst(n=1, type = \"t\", type.t = \"RW1\", n.t = 200, scale.model = FALSE) par(mfrow = c(1,2)) plot(1:dim(out)[2], out, col = 1, type = \"l\", xlab = \"Time\", ylab = \"Random effects\") # verify the first order difference is normally distributed first_diff <- diff(as.numeric(out[1,])) qqnorm(first_diff )   abline(c(0,1))  ## Temporal random effects (RW2) out <- rst(n=1, type = \"t\", type.t = \"RW2\", n.t = 200, scale.model = FALSE) par(mfrow = c(1,2)) plot(1:dim(out)[2], out, col = 1, type = \"l\", xlab = \"Time\", ylab = \"Random effects\") # verify the second order difference is normally distributed first_diff <- diff(as.numeric(out[1,])) second_diff <- diff(first_diff) qqnorm(second_diff)   abline(c(0,1))  ## Spatial-temporal random effects out <- rst(n=1, type = \"st\", type.t = \"RW2\", Amat = DemoMap$Amat, n.t = 50) dimnames(out) par(mfrow = c(1,1)) plot(1:dim(out)[3], out[1,1,], col = 1,  type = \"l\", ylim = range(out), xlab = \"Time\", ylab = \"Random effects\") for(i in 2:4) lines(1:dim(out)[3], out[1,i,], col = i) legend(\"bottomright\", colnames(DemoMap$Amat), col = c(1:4), lty = rep(1,4)) }"},{"path":"https://richardli.github.io/SUMMER/reference/rw.new.html","id":null,"dir":"Reference","previous_headings":"","what":"New random walk 1 and 2 models for m-year to period random effects — rw.new","title":"New random walk 1 and 2 models for m-year to period random effects — rw.new","text":"New random walk 1 2 models m-year period random effects","code":""},{"path":"https://richardli.github.io/SUMMER/reference/rw.new.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"New random walk 1 and 2 models for m-year to period random effects — rw.new","text":"","code":"rw.new(   cmd = c(\"graph\", \"Q\", \"mu\", \"initial\", \"log.norm.const\", \"log.prior\", \"quit\"),   theta = NULL )"},{"path":"https://richardli.github.io/SUMMER/reference/rw.new.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"New random walk 1 and 2 models for m-year to period random effects — rw.new","text":"cmd list model components theta log precision","code":""},{"path":"https://richardli.github.io/SUMMER/reference/rw.new.pc.html","id":null,"dir":"Reference","previous_headings":"","what":"New random walk 1 and 2 models for m-year to period random effects — rw.new.pc","title":"New random walk 1 and 2 models for m-year to period random effects — rw.new.pc","text":"New random walk 1 2 models m-year period random effects","code":""},{"path":"https://richardli.github.io/SUMMER/reference/rw.new.pc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"New random walk 1 and 2 models for m-year to period random effects — rw.new.pc","text":"","code":"rw.new.pc(   cmd = c(\"graph\", \"Q\", \"mu\", \"initial\", \"log.norm.const\", \"log.prior\", \"quit\"),   theta = NULL )"},{"path":"https://richardli.github.io/SUMMER/reference/rw.new.pc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"New random walk 1 and 2 models for m-year to period random effects — rw.new.pc","text":"cmd list model components theta log precision","code":""},{"path":"https://richardli.github.io/SUMMER/reference/setThresholdsByRegion.html","id":null,"dir":"Reference","previous_headings":"","what":"Set thresholds of population density for urbanicity classifications within each region of the given type — setThresholdsByRegion","title":"Set thresholds of population density for urbanicity classifications within each region of the given type — setThresholdsByRegion","text":"Set thresholds population density urbanicity classifications  within region given type","code":""},{"path":"https://richardli.github.io/SUMMER/reference/setThresholdsByRegion.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set thresholds of population density for urbanicity classifications within each region of the given type — setThresholdsByRegion","text":"","code":"setThresholdsByRegion(popMat, poppr, regionType = \"area\")"},{"path":"https://richardli.github.io/SUMMER/reference/setThresholdsByRegion.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set thresholds of population density for urbanicity classifications within each region of the given type — setThresholdsByRegion","text":"popMat pixellated population density data frame variables  regionType `pop` poppr table population totals region given type  (e.g. poppa poppsub makePopIntegrationTab) regionType variable name poppr giving region names.  Defaults \"area\"","code":""},{"path":"https://richardli.github.io/SUMMER/reference/setThresholdsByRegion.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set thresholds of population density for urbanicity classifications within each region of the given type — setThresholdsByRegion","text":"list region names urbanicity thresholds population density","code":""},{"path":"https://richardli.github.io/SUMMER/reference/setThresholdsByRegion.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Set thresholds of population density for urbanicity classifications within each region of the given type — setThresholdsByRegion","text":"Thresholds set based region's percent population  urban. Intended helper function makePopIntegrationTab.","code":""},{"path":[]},{"path":"https://richardli.github.io/SUMMER/reference/setThresholdsByRegion.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Set thresholds of population density for urbanicity classifications within each region of the given type — setThresholdsByRegion","text":"John Paige","code":""},{"path":"https://richardli.github.io/SUMMER/reference/setThresholdsByRegion.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Set thresholds of population density for urbanicity classifications within each region of the given type — setThresholdsByRegion","text":"","code":"if (FALSE) { data(kenyaPopulationData)  #' # download Kenya GADM shapefiles from SUMMERdata github repository githubURL <- \"https://github.com/paigejo/SUMMERdata/blob/main/data/kenyaMaps.rda?raw=true\" tempDirectory = \"~/\" mapsFilename = paste0(tempDirectory, \"/kenyaMaps.rda\") if(!file.exists(mapsFilename)) {   download.file(githubURL,mapsFilename) }  # load it in out = load(mapsFilename) out adm1@data$NAME_1 = as.character(adm1@data$NAME_1) adm1@data$NAME_1[adm1@data$NAME_1 == \"Trans Nzoia\"] = \"Trans-Nzoia\" adm1@data$NAME_1[adm1@data$NAME_1 == \"Elgeyo-Marakwet\"] = \"Elgeyo Marakwet\" adm2@data$NAME_1 = as.character(adm2@data$NAME_1) adm2@data$NAME_1[adm2@data$NAME_1 == \"Trans Nzoia\"] = \"Trans-Nzoia\" adm2@data$NAME_1[adm2@data$NAME_1 == \"Elgeyo-Marakwet\"] = \"Elgeyo Marakwet\"  # some Admin-2 areas have the same name adm2@data$NAME_2 = as.character(adm2@data$NAME_2) adm2@data$NAME_2[(adm2@data$NAME_1 == \"Bungoma\") &    (adm2@data$NAME_2 == \"Lugari\")] = \"Lugari, Bungoma\" adm2@data$NAME_2[(adm2@data$NAME_1 == \"Kakamega\") &    (adm2@data$NAME_2 == \"Lugari\")] = \"Lugari, Kakamega\" adm2@data$NAME_2[(adm2@data$NAME_1 == \"Meru\") &    (adm2@data$NAME_2 == \"Igembe South\")] = \"Igembe South, Meru\" adm2@data$NAME_2[(adm2@data$NAME_1 == \"Tharaka-Nithi\") &    (adm2@data$NAME_2 == \"Igembe South\")] = \"Igembe South, Tharaka-Nithi\"  # The spatial area of unknown 8 is so small, it causes problems unless  # its removed or unioned with another subarea. Union it with neighboring  # Kakeguria: newadm2 = adm2 unknown8I = which(newadm2$NAME_2 == \"unknown 8\") newadm2$NAME_2[newadm2$NAME_2 %in% c(\"unknown 8\", \"Kapenguria\")] <- \"Kapenguria + unknown 8\" admin2.IDs <- newadm2$NAME_2  newadm2@data = cbind(newadm2@data, NAME_2OLD = newadm2@data$NAME_2) newadm2@data$NAME_2OLD = newadm2@data$NAME_2 newadm2@data$NAME_2 = admin2.IDs newadm2$NAME_2 = admin2.IDs temp <- terra::aggregate(as(newadm2, \"SpatVector\"), by=\"NAME_2\")  library(sf) temp <- sf::st_as_sf(temp) temp <- sf::as_Spatial(temp)  tempData = newadm2@data[-unknown8I,] tempData = tempData[order(tempData$NAME_2),] newadm2 <- SpatialPolygonsDataFrame(temp, tempData, match.ID = F) adm2 = newadm2  # download 2014 Kenya population density TIF file  githubURL <- paste0(\"https://github.com/paigejo/SUMMERdata/blob/main/data/\",                      \"Kenya2014Pop/worldpop_total_1y_2014_00_00.tif?raw=true\") popTIFFilename = paste0(tempDirectory, \"/worldpop_total_1y_2014_00_00.tif\") if(!file.exists(popTIFFilename)) {   download.file(githubURL,popTIFFilename) }  # load it in pop = terra::rast(popTIFFilename)  eastLim = c(-110.6405, 832.4544) northLim = c(-555.1739, 608.7130)  require(fields)  # Now generate a general population integration table at 5km resolution,  # based on subarea (Admin-2) x urban/rural population totals. This takes  # ~1 minute system.time(popMatKenya <- makePopIntegrationTab(   kmRes=5, pop=pop, domainMapDat=adm0,   eastLim=eastLim, northLim=northLim, mapProjection=projKenya,   poppa = poppaKenya, poppsub=poppsubKenya,    areaMapDat = adm1, subareaMapDat = adm2,   areaNameVar = \"NAME_1\", subareaNameVar=\"NAME_2\"))  out = setThresholdsByRegion(popMatKenya, poppaKenya) out  out = setThresholdsByRegion(popMatKenya, poppsubKenya, regionType=\"subarea\") out }"},{"path":"https://richardli.github.io/SUMMER/reference/simPop.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate populations and areal prevalences — simPop","title":"Simulate populations and areal prevalences — simPop","text":"Given spatial risk model, simulate populations population prevalences  enumeration area level (represented points), aggregate pixel  administrative areal level.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/simPop.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate populations and areal prevalences — simPop","text":"","code":"simPopSPDE(   nsim = 1,   easpa,   popMat,   targetPopMat,   poppsub,   spdeMesh,   margVar = 0.243,   sigmaEpsilon = sqrt(0.463),   gamma = 0.009,   effRange = 406.51,   beta0 = -3.922,   seed = NULL,   inla.seed = -1L,   nHHSampled = 25,   stratifyByUrban = TRUE,   subareaLevel = TRUE,   doFineScaleRisk = FALSE,   doSmoothRisk = FALSE,   doSmoothRiskLogisticApprox = FALSE,   min1PerSubarea = TRUE )  simPopCustom(   logitRiskDraws,   sigmaEpsilonDraws,   easpa,   popMat,   targetPopMat,   stratifyByUrban = TRUE,   validationPixelI = NULL,   validationClusterI = NULL,   clustersPerPixel = NULL,   doFineScaleRisk = FALSE,   doSmoothRisk = FALSE,   doSmoothRiskLogisticApprox = FALSE,   poppsub = NULL,   subareaLevel = FALSE,   min1PerSubarea = TRUE,   returnEAinfo = FALSE,   epsc = NULL )"},{"path":"https://richardli.github.io/SUMMER/reference/simPop.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate populations and areal prevalences — simPop","text":"nsim Number simulations easpa data.frame enumeration area, households, target population per area stratified urban/rural variables: area name area EAUrb number urban enumeration areas area EARur number rural enumeration areas area EATotal total number enumeration areas area HHUrb number urban households area HHRur number rural households area HHTotal total number households area popUrb total urban (target) population area popRur total rural (target) population area popTotal total (general) population area popMat Pixellated grid data frame variables `lon`, `lat`, `pop`, `area`, `subareas` (subareaLevel TRUE), `urban` (stratifyByUrban TRUE), `east`, `north` targetPopMat popMat, `pop` variable gives target rather general population poppsub data.frame population per subarea separated  urban/rural using population density grid normalization urbanicity  classification. Often based extra fine scale population density grid. variables: spdeMesh Triangular mesh SPDE margVar Marginal variance spatial process, excluding cluster effects.  0, spatial component included sigmaEpsilon Standard deviation logit scale iid Gaussian EA level random effects risk model gamma Effect urban logit scale logit model risk effRange Effective spatial range SPDE model beta0 Intercept logit model risk seed Random number generator seed inla.seed Seed input inla.qsample. 0L sets seed intelligently,  > 0 sets specific seed, < 0 keeps existing RNG nHHSampled Number households sampled per enumeration area. Default 25 match DHS surveys stratifyByUrban Whether stratify simulations urban/rural classification subareaLevel Whether aggregate population subarea doFineScaleRisk Whether calculate fine scale risk aggregation level addition prevalence doSmoothRisk Whether calculate smooth risk aggregation level addition prevalence doSmoothRiskLogisticApprox Whether use logistic approximation calculating smooth risk. See  logitNormMean details. min1PerSubarea TRUE, ensures least 1 EA per subarea. subareas particularly unlikely  enumeration areas since low proportion population area, setting TRUE may  computationally intensive. logitRiskDraws nIntegrationPoints x nsim dimension matrix draws pixel leve risk field logit scale, leaving  potential nugget/cluster/EA level effects. sigmaEpsilonDraws nsim length vector draws cluster effect logit scale SD (joint draws logitRiskDraws) validationPixelI CURRENTLY TESTING PURPOSES set indices pixels want simulate populations (used pixel level validation) validationClusterI CURRENTLY TESTING PURPOSES set indices cluster want simulate populations (used cluster level validation) clustersPerPixel CURRENTLY TESTING PURPOSES Used pixel level validation. Fixes number EAs per pixel. returnEAinfo TRUE, returns information every individual EA (BAU) simulated population epsc nEAs x nsim matrix simulated EA (BAU) level iid effects representing fine scale variation        risk. NULL, simulated iid Gaussian logit scale        SD given sigmaEpsilonDraws list(pixelPop=outPixelLevel, subareaPop=outSubareaLevel, areaPop=outAreaLevel, logitRiskDraws=logitRiskDraws)","code":""},{"path":"https://richardli.github.io/SUMMER/reference/simPop.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate populations and areal prevalences — simPop","text":"simulated population aggregated enumeration area,  pixel, subarea (generally Admin2), area (generally Admin1) levels. Output includes: pixelPop list pixel level population aggregates subareaPop list `subarea` level population aggregates areaPop list `area` level population aggregates contains population numerator denominator well prevalence risk  information aggregated appropriate level.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/simPop.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Simulate populations and areal prevalences — simPop","text":"population simulation aggregation, consider three models: smooth   risk, fine scale risk, fine scale prevalence. described detail  paper preparation. smooth risk model, pixel level risks integrated  respect target population density producing areal estimates prespecified  set integration points. target population may , example, neonatals rather  general population. fine scale models, enumeration areas (EAs) simulated  point locations iid random effects EA level risk allowed. EAs populations dispersed conditional (possibly  approximately) known number EAs, households, target population particular  areal level (call `areas`) using multilevel multinomial sampling, first  sampling EAs, distributing households among EAs, target population  among households. areal level `areas` call `subareas`. instance,  `areas` might Admin-1 smallest level number EAs,  households, people known, `subareas` might Admin-2. multilevel  multinomial sampling may stratified urban/rural within areas number  EAs, households, people also approximately known level. Within EA assume fixed probability event occurring, fine scale `risk`.  fine scale `prevalence` empirical proportion events within EA. assume EA  level logit scale iid N(0, sigmaEpsilon^2) random effects risk model. averaged  equal weights EAs areal unit, forms fine scale risk.  instead population numerators denominators aggregated, used  calculate empirical proportion events occurring areal unit, resulting  quantity fine scale prevalence areal unit. Note functions can used either simulating populations simulation  studies, generating predictions accounting uncertainty EA locations  fine scale variation occurring EA level due EA level iid random effects.  Required, however, separately fit EA level spatial risk model  information spatial population density population frame.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/simPop.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Simulate populations and areal prevalences — simPop","text":"simPopSPDE(): Simulate populations population prevalences given census frame population density  information. Uses SPDE model generating spatial risk can include iid cluster  level effect. simPopCustom(): Simulate populations population prevalences given census frame population density  information. Uses custom spatial logit risk function can include iid cluster  level effect.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/simPop.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Simulate populations and areal prevalences — simPop","text":"preparation","code":""},{"path":[]},{"path":"https://richardli.github.io/SUMMER/reference/simPop.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Simulate populations and areal prevalences — simPop","text":"John Paige","code":""},{"path":"https://richardli.github.io/SUMMER/reference/simPop.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulate populations and areal prevalences — simPop","text":"","code":"if (FALSE) { ## In this script we will create 5km resolution pixellated grid over Kenya,  ## and generate tables of estimated (both target and general) population  ## totals at the area (e.g. Admin-1) and subarea (e.g. Admin-2) levels. Then  ## we will use that to simulate populations of   # download Kenya GADM shapefiles from SUMMERdata github repository githubURL <- paste0(\"https://github.com/paigejo/SUMMERdata/blob/main/data/\",                      \"kenyaMaps.rda?raw=true\") tempDirectory = \"~/\" mapsFilename = paste0(tempDirectory, \"/kenyaMaps.rda\") if(!file.exists(mapsFilename)) {   download.file(githubURL,mapsFilename) }  # load it in out = load(mapsFilename) out adm1@data$NAME_1 = as.character(adm1@data$NAME_1) adm1@data$NAME_1[adm1@data$NAME_1 == \"Trans Nzoia\"] = \"Trans-Nzoia\" adm1@data$NAME_1[adm1@data$NAME_1 == \"Elgeyo-Marakwet\"] = \"Elgeyo Marakwet\" adm2@data$NAME_1 = as.character(adm2@data$NAME_1) adm2@data$NAME_1[adm2@data$NAME_1 == \"Trans Nzoia\"] = \"Trans-Nzoia\" adm2@data$NAME_1[adm2@data$NAME_1 == \"Elgeyo-Marakwet\"] = \"Elgeyo Marakwet\"  # some Admin-2 areas have the same name adm2@data$NAME_2 = as.character(adm2@data$NAME_2) adm2@data$NAME_2[(adm2@data$NAME_1 == \"Bungoma\") &                     (adm2@data$NAME_2 == \"Lugari\")] = \"Lugari, Bungoma\" adm2@data$NAME_2[(adm2@data$NAME_1 == \"Kakamega\") &                     (adm2@data$NAME_2 == \"Lugari\")] = \"Lugari, Kakamega\" adm2@data$NAME_2[(adm2@data$NAME_1 == \"Meru\") &                     (adm2@data$NAME_2 == \"Igembe South\")] = \"Igembe South, Meru\" adm2@data$NAME_2[(adm2@data$NAME_1 == \"Tharaka-Nithi\") &                     (adm2@data$NAME_2 == \"Igembe South\")] = \"Igembe South, Tharaka-Nithi\"  # The spatial area of unknown 8 is so small, it causes problems unless its removed or  # unioned with another subarea. Union it with neighboring Kakeguria: newadm2 = adm2 unknown8I = which(newadm2$NAME_2 == \"unknown 8\") newadm2$NAME_2[newadm2$NAME_2 %in% c(\"unknown 8\", \"Kapenguria\")] <-    \"Kapenguria + unknown 8\" admin2.IDs <- newadm2$NAME_2  newadm2@data = cbind(newadm2@data, NAME_2OLD = newadm2@data$NAME_2) newadm2@data$NAME_2OLD = newadm2@data$NAME_2 newadm2@data$NAME_2 = admin2.IDs newadm2$NAME_2 = admin2.IDs temp <- terra::aggregate(as(newadm2, \"SpatVector\"), by=\"NAME_2\")  library(sf) temp <- sf::st_as_sf(temp) temp <- sf::as_Spatial(temp)  tempData = newadm2@data[-unknown8I,] tempData = tempData[order(tempData$NAME_2),] newadm2 <- SpatialPolygonsDataFrame(temp, tempData, match.ID = F) adm2 = newadm2  # download 2014 Kenya population density TIF file  githubURL <- paste0(\"https://github.com/paigejo/SUMMERdata/blob/main/data/\",                      \"Kenya2014Pop/worldpop_total_1y_2014_00_00.tif?raw=true\") popTIFFilename = paste0(tempDirectory, \"/worldpop_total_1y_2014_00_00.tif\") if(!file.exists(popTIFFilename)) {   download.file(githubURL,popTIFFilename) }  # load it in pop = terra::rast(popTIFFilename)  eastLim = c(-110.6405, 832.4544) northLim = c(-555.1739, 608.7130)  ## Construct poppsubKenya, a table of urban/rural general population totals  ## in each subarea. Technically, this is not necessary since we can load in  ## poppsubKenya via data(kenyaPopulationData). First, we will need to calculate  ## the areas in km^2 of the areas and subareas  # use Lambert equal area projection of areas (Admin-1) and subareas (Admin-2) midLon = mean(adm1@bbox[1,]) midLat = mean(adm1@bbox[2,]) p4s = paste0(\"+proj=laea +x_0=0 +y_0=0 +lon_0=\", midLon,               \" +lat_0=\", midLat, \" +units=km\")  adm1_sf = st_as_sf(adm1) adm1proj_sf = st_transform(adm1_sf, p4s) adm1proj = as(adm1proj_sf, \"Spatial\")  adm2_sf = st_as_sf(adm2) adm2proj_sf = st_transform(adm2_sf, p4s) adm2proj = as(adm2proj_sf, \"Spatial\")  # now calculate spatial area in km^2 admin1Areas = as.numeric(st_area(adm1proj_sf)) admin2Areas = as.numeric(st_area(adm2proj_sf))  areapaKenya = data.frame(area=adm1proj@data$NAME_1, spatialArea=admin1Areas) areapsubKenya = data.frame(area=adm2proj@data$NAME_1, subarea=adm2proj@data$NAME_2,                             spatialArea=admin2Areas)  # Calculate general population totals at the subarea (Admin-2) x urban/rural  # level and using 1km resolution population grid. Assign urbanicity by  # thresholding population density based on estimated proportion population  # urban/rural, making sure total area (Admin-1) urban/rural populations in  # each area matches poppaKenya.  # NOTE: the following function will typically take ~15-20 minutes. Can speed up  #       by setting kmRes to be higher, but we recommend fine resolution for  #       this step, since it only needs to be done once. system.time(poppsubKenya <- getPoppsub(   kmRes=1, pop=pop, domainMapDat=adm0,   eastLim=eastLim, northLim=northLim, mapProjection=projKenya,   poppa = poppaKenya, areapa=areapaKenya, areapsub=areapsubKenya,    areaMapDat=adm1, subareaMapDat=adm2,    areaNameVar = \"NAME_1\", subareaNameVar=\"NAME_2\"))  # Now generate a general population integration table at 5km resolution,  # based on subarea (Admin-2) x urban/rural population totals. This takes  # ~1 minute system.time(popMatKenya <- makePopIntegrationTab(   kmRes=5, pop=pop, domainMapDat=adm0,   eastLim=eastLim, northLim=northLim, mapProjection=projKenya,   poppa = poppaKenya, poppsub=poppsubKenya,    areaMapDat = adm1, subareaMapDat = adm2,   areaNameVar = \"NAME_1\", subareaNameVar=\"NAME_2\"))  ## Adjust popMat to be target (neonatal) rather than general population  ## density. First create the target population frame ## (these numbers are based on IPUMS microcensus data) mothersPerHouseholdUrb = 0.3497151 childrenPerMotherUrb = 1.295917 mothersPerHouseholdRur = 0.4787696 childrenPerMotherRur = 1.455222 targetPopPerStratumUrban = easpaKenya$HHUrb * mothersPerHouseholdUrb *    childrenPerMotherUrb targetPopPerStratumRural = easpaKenya$HHRur * mothersPerHouseholdRur *    childrenPerMotherRur easpaKenyaNeonatal = easpaKenya easpaKenyaNeonatal$popUrb = targetPopPerStratumUrban easpaKenyaNeonatal$popRur = targetPopPerStratumRural easpaKenyaNeonatal$popTotal = easpaKenyaNeonatal$popUrb +    easpaKenyaNeonatal$popRur easpaKenyaNeonatal$pctUrb = 100 * easpaKenyaNeonatal$popUrb /    easpaKenyaNeonatal$popTotal easpaKenyaNeonatal$pctTotal =    100 * easpaKenyaNeonatal$popTotal / sum(easpaKenyaNeonatal$popTotal)  # Generate the target population density by scaling the current  # population density grid at the Admin1 x urban/rural level popMatKenyaNeonatal = adjustPopMat(popMatKenya, easpaKenyaNeonatal)  # Generate neonatal population table from the neonatal population integration  # matrix. This is technically not necessary for population simulation purposes,  # but is here for illustrative purposes poppsubKenyaNeonatal = poppRegionFromPopMat(popMatKenyaNeonatal,                                              popMatKenyaNeonatal$subarea) poppsubKenyaNeonatal =    cbind(subarea=poppsubKenyaNeonatal$region,          area=adm2@data$NAME_1[match(poppsubKenyaNeonatal$region, adm2@data$NAME_2)],          poppsubKenyaNeonatal[,-1]) print(head(poppsubKenyaNeonatal))  ## Now we're ready to simulate neonatal populations along with neonatal  ## mortality risks and prevalences  # use the following model to simulate the neonatal population based roughly  # on Paige et al. (2020) neonatal mortality modeling for Kenya. beta0=-2.9 # intercept gamma=-1 # urban effect rho=(1/3)^2 # spatial variance effRange = 400 # effective spatial range in km sigmaEpsilon=sqrt(1/2.5) # cluster (nugget) effect standard deviation  # Run a simulation! This produces multiple dense nEA x nsim and nPixel x nsim  # matrices. In the future sparse matrices and chunk by chunk computations  # may be incorporated. simPop = simPopSPDE(nsim=1, easpa=easpaKenyaNeonatal,                      popMat=popMatKenya, targetPopMat=popMatKenyaNeonatal,                      poppsub=poppsubKenya, spdeMesh=kenyaMesh,                      margVar=rho, sigmaEpsilon=sigmaEpsilon,                      gamma=gamma, effRange=effRange, beta0=beta0,                      seed=12, inla.seed=12, nHHSampled=25,                      stratifyByUrban=TRUE, subareaLevel=TRUE,                      doFineScaleRisk=TRUE, doSmoothRisk=TRUE,                      min1PerSubarea=TRUE)  # get average absolute percent error relative to fine scale prevalence at Admin-2 level tempDat = simPop$subareaPop$aggregationResults[c(\"region\", \"pFineScalePrevalence\",                                                    \"pFineScaleRisk\", \"pSmoothRisk\")] 100*mean(abs(tempDat$pFineScalePrevalence - tempDat$pFineScaleRisk) /             tempDat$pFineScalePrevalence) 100*mean(abs(tempDat$pFineScalePrevalence - tempDat$pSmoothRisk) /             tempDat$pFineScalePrevalence) 100*mean(abs(tempDat$pFineScaleRisk - tempDat$pSmoothRisk) /             tempDat$pFineScalePrevalence)  # verify number of EAs per area and subarea cbind(aggregate(simPop$eaPop$eaSamples[,1], by=list(area=popMatKenya$area), FUN=sum),        trueNumEAs=easpaKenya$EATotal[order(easpaKenya$area)]) aggregate(simPop$eaPop$eaSamples[,1], by=list(area=popMatKenya$subarea), FUN=sum)  ## plot simulated population # directory for plotting  # (mapPlot takes longer when it doesn't save to a file) tempDirectory = \"~/\"  # pixel level plots. Some pixels have no simulated EAs, in which case they will be  # plotted as white. Expected noisy looking plots of fine scale risk and prevalence  # due to EAs being discrete, as compared to a very smooth plot of smooth risk. zlim = c(0, quantile(probs=.995, c(simPop$pixelPop$pFineScalePrevalence,                                     simPop$pixelPop$pFineScaleRisk,                                     simPop$pixelPop$pSmoothRisk), na.rm=TRUE)) pdf(file=paste0(tempDirectory, \"simPopSPDEPixel.pdf\"), width=8, height=8) par(mfrow=c(2,2)) plot(adm2, asp=1) points(simPop$eaPop$eaDatList[[1]]$lon, simPop$eaPop$eaDatList[[1]]$lat, pch=\".\", col=\"blue\") plot(adm2, asp=1) quilt.plot(popMatKenya$lon, popMatKenya$lat, simPop$pixelPop$pFineScalePrevalence,             zlim=zlim, add=TRUE, FUN=function(x) {mean(x, na.rm=TRUE)}) plot(adm2, asp=1) quilt.plot(popMatKenya$lon, popMatKenya$lat, simPop$pixelPop$pFineScaleRisk,             zlim=zlim, add=TRUE, FUN=function(x) {mean(x, na.rm=TRUE)}) quilt.plot(popMatKenya$lon, popMatKenya$lat, simPop$pixelPop$pSmoothRisk,             zlim=zlim, FUN=function(x) {mean(x, na.rm=TRUE)}, asp=1) plot(adm2, add=TRUE) dev.off()  range(simPop$eaPop$eaDatList[[1]]$N)  # areal (Admin-1) level: these results should look essentially identical  tempDat = simPop$areaPop$aggregationResults[c(\"region\", \"pFineScalePrevalence\",                                                 \"pFineScaleRisk\", \"pSmoothRisk\")] pdf(file=paste0(tempDirectory, \"simPopSPDEAdmin-1.pdf\"), width=7, height=7) mapPlot(tempDat,          variables=c(\"pFineScalePrevalence\", \"pFineScaleRisk\", \"pSmoothRisk\"),          geo=adm1, by.geo=\"NAME_1\", by.data=\"region\", is.long=FALSE) dev.off()  # subareal (Admin-2) level: these results should look subtley different  # depending on the type of prevalence/risk considered tempDat = simPop$subareaPop$aggregationResults[c(\"region\", \"pFineScalePrevalence\",                                                    \"pFineScaleRisk\", \"pSmoothRisk\")] pdf(file=paste0(tempDirectory, \"simPopSPDEAdmin-2.pdf\"), width=7, height=7) mapPlot(tempDat,          variables=c(\"pFineScalePrevalence\", \"pFineScaleRisk\", \"pSmoothRisk\"),          geo=adm2, by.geo=\"NAME_2\", by.data=\"region\", is.long=FALSE) dev.off() }"},{"path":"https://richardli.github.io/SUMMER/reference/simPopInternal.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal functions for population simulation — simPopInternal","title":"Internal functions for population simulation — simPopInternal","text":"Functions calculating valuable quantities drawing important  distributions population simulation.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/simPopInternal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal functions for population simulation — simPopInternal","text":"","code":"getExpectedNperEA(easpa, popMat, level = c(\"grid\", \"EA\"), pixelIndexMat = NULL)  getSortIndices(   i,   urban = TRUE,   popMat,   stratifyByUrban = TRUE,   validationPixelI = NULL )  rStratifiedMultnomial(n, popMat, easpa, stratifyByUrban = TRUE)  rStratifiedMultnomialBySubarea(   n,   popMat,   easpa,   stratifyByUrban = TRUE,   poppsub = NULL,   min1PerSubarea = TRUE,   minSample = 1 )  rMyMultinomial(   n,   i,   stratifyByUrban = TRUE,   urban = TRUE,   popMat = NULL,   easpa = NULL,   min1PerSubarea = FALSE,   method = c(\"mult1\", \"mult\", \"indepMH\"),   minSample = 1 )  rMyMultinomialSubarea(   n,   i,   easpsub,   stratifyByUrban = TRUE,   urban = TRUE,   popMat = NULL )  rmultinom1(   n = 1,   size,   prob,   maxSize = 8000 * 8000,   method = c(\"mult1\", \"mult\", \"indepMH\"),   verbose = FALSE,   minSample = 100,   maxExpectedSizeBeforeSwitch = 1000 * 1e+07,   init = NULL,   burnIn = floor(n/4),   filterEvery = 10,   zeroProbZeroSamples = TRUE,   allowSizeLessThanK = FALSE )  sampleNMultilevelMultinomial(   nDraws = ncol(pixelIndexMat),   pixelIndexMat = NULL,   urbanMat = NULL,   areaMat = NULL,   easpaList,   popMat,   stratifyByUrban = TRUE,   verbose = TRUE,   returnEAinfo = FALSE,   minHHPerEA = 25,   fixHHPerEA = NULL,   fixPopPerHH = NULL )  sampleNMultilevelMultinomialFixed(   clustersPerPixel,   nDraws = ncol(pixelIndices),   pixelIndices = NULL,   urbanVals = NULL,   areaVals = NULL,   easpa,   popMat,   stratifyByUrban = TRUE,   verbose = TRUE )"},{"path":"https://richardli.github.io/SUMMER/reference/simPopInternal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Internal functions for population simulation — simPopInternal","text":"easpa Census frame. See simPopCustom details popMat data.frame pixellated grid population densities. See simPopCustom details level Whether calculate results integration grid EA level pixelIndexMat Matrix pixel indices associated EA draw.  required getExpectedNperEA unless level == \"EA\" Index urban TRUE, calculate urban part area. FALSE, rural part stratifyByUrban whether stratify calculations urban/rural classification validationPixelI CURRENTLY TESTING PURPOSES set indices pixels want simulate populations (used pixel level validation) n Number samples poppsub Population per subarea. See simPopCustom details min1PerSubarea Whether ensure least 1 EA per subarea. See simPopCustom details minSample minimum number samples per `chunk` samples truncated multinomial sampling. Defaults 1 method min1PerSubarea TRUE, sampling method truncated multinomial use rmulitnom1. rmultinom1 automatically          switches depending number expected samples. methods : mult1 rejection sampling multinomial plus 1 category mult rejection sampling multinomial category zero count indepMH independent Metropolis-Hastings using multinomial plus 1 distribution proposal easpsub either total EAs per subarea, subarea crossed urban  rural stratifyByUrban TRUE size Multinomial size parameter. See rmultinom prob Multinomial probability vector parameter. See rmultinom maxSize maximum number elements matrix drawn proposal distribution per sample chunk. verbose Whether print progress function proceeds maxExpectedSizeBeforeSwitch Max expected number samples / k, number categories, switching method init Initial sample method `indepMH` burnIn Number initial samples samples collected method `indepMH` filterEvery Store every filterEvery samples method `indepMH` zeroProbZeroSamples TRUE, set samples parts prob vector zero zero. Otherwise set one. allowSizeLessThanK TRUE, size < number categories (k), returns matrix  column vector size ones k - size zeros. FALSE, throws error size < k nDraws Number draws urbanMat Matrix urbanicities associated EA draw areaMat Matrix areas associated EA draw easpaList list length n element format easpa  giving number households EAs  per stratum. assumed number EAs per stratum  list element. easpaList data frame,  number households per stratum assumed constant returnEAinfo Whether data frame EA level desired minHHPerEA minimum number households per EA (defaults 25, since  number households sampled per DHS cluster) fixHHPerEA NULL, fixed number households per EA fixPopPerHH NULL, fixed target population per household clustersPerPixel CURRENTLY TESTING PURPOSES vector length nIntegrationPoints specifying number clusters per pixel fixed pixelIndices nEA x n matrix pixel indices associated EA per simulation/draw urbanVals nEA x n matrix urbanicities associated EA per simulation/draw areaVals nEA x n matrix area names associated EA per simulation/draw","code":""},{"path":"https://richardli.github.io/SUMMER/reference/simPopInternal.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Internal functions for population simulation — simPopInternal","text":"getExpectedNperEA(): Calculates expected denominator per enumeration area. getSortIndices(): recombining separate multinomials draws grid points rStratifiedMultnomial(): Gives nIntegrationPoints x n matrix draws stratified multinomial values  corresponding value |C^g| pixel, g (number EAs/pixel) rStratifiedMultnomialBySubarea(): Gives nIntegrationPoints x n matrix draws stratified multinomial values rMyMultinomial(): rMyMultinomialSubarea(): rmultinom1(): Random (truncated) multinomial draws conditional number type least one sampleNMultilevelMultinomial(): Take multilevel multinomial draws first joint distribution  number households per EA given total per stratum, joint  distribution total target population per household given  total per stratum sampleNMultilevelMultinomialFixed(): sampleNMultilevelMultinomial, except number EAs per pixel fixed","code":""},{"path":"https://richardli.github.io/SUMMER/reference/simSPDE.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate from the SPDE spatial model — simSPDE","title":"Simulate from the SPDE spatial model — simSPDE","text":"Generates nCoords x nsim matrix simulated  values SPDE spatial process","code":""},{"path":"https://richardli.github.io/SUMMER/reference/simSPDE.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate from the SPDE spatial model — simSPDE","text":"","code":"simSPDE(   coords,   nsim = 1,   mesh,   effRange = (max(coords[, 1]) - min(coords[, 1]))/3,   margVar = 1,   inla.seed = 0L )"},{"path":"https://richardli.github.io/SUMMER/reference/simSPDE.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate from the SPDE spatial model — simSPDE","text":"coords 2 column matrix spatial coordinates simulate spatial process nsim number draws SPDE model mesh SPDE mesh effRange effective spatial range margVar marginal variance spatial process inla.seed seed input inla.qsample. 0L sets seed intelligently,  > 0 sets specific seed, < 0 keeps existing RNG","code":""},{"path":"https://richardli.github.io/SUMMER/reference/simSPDE.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Simulate from the SPDE spatial model — simSPDE","text":"Lindgren, F., Rue, H., Lindström, J., 2011. explicit link Gaussian fields Gaussian Markov random fields: stochastic differential equation approach (discussion). Journal Royal Statistical Society, Series B 73, 423–498.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/simSPDE.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Simulate from the SPDE spatial model — simSPDE","text":"John Paige","code":""},{"path":"https://richardli.github.io/SUMMER/reference/simSPDE.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulate from the SPDE spatial model — simSPDE","text":"","code":"if (FALSE) { set.seed(123) require(INLA) coords = matrix(runif(10*2), ncol=2) mesh = inla.mesh.2d(loc.domain=cbind(c(0, 0, 1, 1), c(0, 1, 0, 1)),    n=3000, max.n=5000, max.edge=c(.01, .05), offset=-.1) simVals = simSPDE(coords, nsim=1, mesh, effRange=.2, inla.seed=1L) }"},{"path":"https://richardli.github.io/SUMMER/reference/simhyper.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate hyperpriors from an GMRF — simhyper","title":"Simulate hyperpriors from an GMRF — simhyper","text":"Simulate hyperpriors GMRF","code":""},{"path":"https://richardli.github.io/SUMMER/reference/simhyper.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate hyperpriors from an GMRF — simhyper","text":"","code":"simhyper(   R = 2,   nsamp = 1e+05,   nsamp.check = 5000,   Amat = NULL,   nperiod = 6,   only.iid = TRUE )"},{"path":"https://richardli.github.io/SUMMER/reference/simhyper.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate hyperpriors from an GMRF — simhyper","text":"R Desired prior odds ratio. Default 2, .e., 95% prior interval residual odds ratios lies interval (R, 1/R). nsamp Sample simulate scaling factor nsamp.check Sample simulate checking range Amat Adjacency matrix areas data. nperiod numerical value many time periods data .iid Indicator whether IID hyperpriors simulated","code":""},{"path":"https://richardli.github.io/SUMMER/reference/simhyper.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Simulate hyperpriors from an GMRF — simhyper","text":"Wakefield, J. Multi-level modelling, ecologic fallacy, hybrid study designs. International Journal Epidemiology, 2009, vol. 38 (pg. 330-336).","code":""},{"path":"https://richardli.github.io/SUMMER/reference/simhyper.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Simulate hyperpriors from an GMRF — simhyper","text":"Zehang Richard Li, Laina Mercer","code":""},{"path":"https://richardli.github.io/SUMMER/reference/simhyper.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulate hyperpriors from an GMRF — simhyper","text":"","code":"if (FALSE) { data(DemoMap) mat <- DemoMap$Amat priors <- simhyper(R = 2, nsamp = 1e+05, nsamp.check = 5000, Amat = mat) }"},{"path":"https://richardli.github.io/SUMMER/reference/smoothArea.html","id":null,"dir":"Reference","previous_headings":"","what":"Small area estimation via basic area level model — smoothArea","title":"Small area estimation via basic area level model — smoothArea","text":"Generates small area estimates  smoothing direct estimates using area level model","code":""},{"path":"https://richardli.github.io/SUMMER/reference/smoothArea.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Small area estimation via basic area level model — smoothArea","text":"","code":"smoothArea(   formula,   domain,   design = NULL,   adj.mat = NULL,   X.domain = NULL,   direct.est = NULL,   domain.size = NULL,   transform = c(\"identity\", \"logit\", \"log\"),   pc.u = 1,   pc.alpha = 0.01,   pc.u.phi = 0.5,   pc.alpha.phi = 2/3,   level = 0.95,   n.sample = 250,   var.tol = 1e-10,   return.samples = F )"},{"path":"https://richardli.github.io/SUMMER/reference/smoothArea.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Small area estimation via basic area level model — smoothArea","text":"formula object class 'formula' describing model fitted.  direct.est specified, right hand side formula necessary. domain One-sided formula specifying factors containing domain labels design object class \"svydesign\" containing data model adj.mat Adjacency matrix rownames matching domain labels. set NULL, IID spatial effect used. X.domain Data frame areal covariates. One column names needs match name domain variable, order linked data input. Currently supporting time-invariant covariates. direct.est Data frame direct estimates, first column containing domain variable, second column containing direct estimate, third column containing variance direct estimate. domain.size Data frame domain sizes. One column names needs match name domain variable, order linked data input must column names 'size' containing domain sizes. transform Optional transformation applied direct estimates fitting area level model. default option transformation, logit log implemented. pc.u Hyperparameter U PC prior precisions. See INLA documentation details parameterization. pc.alpha Hyperparameter alpha PC prior precisions. pc.u.phi Hyperparameter U PC prior mixture probability phi BYM2 model. pc.alpha.phi Hyperparameter alpha PC prior mixture probability phi BYM2 model. level specified level posterior credible intervals n.sample Number draws posterior used compute summaries var.tol Tolerance parameter; variance area's direct estimator value, direct estimator dropped model return.samples TRUE, return matrix posterior samples area level quantities","code":""},{"path":"https://richardli.github.io/SUMMER/reference/smoothArea.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Small area estimation via basic area level model — smoothArea","text":"svysae object","code":""},{"path":"https://richardli.github.io/SUMMER/reference/smoothArea.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Small area estimation via basic area level model — smoothArea","text":"","code":"if (FALSE) { data(DemoData2) data(DemoMap2) library(survey) des0 <- svydesign(ids = ~clustid+id, strata = ~strata,                   weights = ~weights, data = DemoData2, nest = TRUE) Xmat <- aggregate(age~region, data = DemoData2, FUN = mean)  # EXAMPLE 1: Continuous response model cts.res <- smoothArea(tobacco.use ~ 1,                       domain = ~region,                       design = des0,                       adj.mat = DemoMap2$Amat,                        pc.u = 1,                       pc.alpha = 0.01,                       pc.u.phi = 0.5,                       pc.alpha.phi = 2/3)  # EXAMPLE 2: Including area level covariates cts.cov.res <- smoothArea(tobacco.use ~ age,                            domain = ~region,                           design = des0,                           adj.mat = DemoMap2$Amat,                            X.domain = Xmat,                           pc.u = 1,                           pc.alpha = 0.01,                           pc.u.phi = 0.5,                           pc.alpha.phi = 2/3)  # EXAMPLE 3: Binary response model bin.res <- smoothArea(tobacco.use ~ 1,                        domain = ~region,                       design = des0,                       adj.mat = DemoMap2$Amat,                        transform = \"logit\",                       pc.u = 1,                       pc.alpha = 0.01,                       pc.u.phi = 0.5,                       pc.alpha.phi = 2/3)  # EXAMPLE 4: Including area level covariates in binary response model bin.cov.res <- smoothArea(tobacco.use ~ age,                            domain = ~region,                           design = des0,                           adj.mat = DemoMap2$Amat,                            transform = \"logit\",                           X.domain = Xmat,                           pc.u = 1,                           pc.alpha = 0.01,                           pc.u.phi = 0.5,                           pc.alpha.phi = 2/3) }"},{"path":"https://richardli.github.io/SUMMER/reference/smoothCluster.html","id":null,"dir":"Reference","previous_headings":"","what":"Cluster-level space-time smoothing models for mortality rates — smoothCluster","title":"Cluster-level space-time smoothing models for mortality rates — smoothCluster","text":"function smoothCluster replace previous function name fitINLA2 (version 1.0.0).","code":""},{"path":"https://richardli.github.io/SUMMER/reference/smoothCluster.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cluster-level space-time smoothing models for mortality rates — smoothCluster","text":"","code":"smoothCluster(   data,   X = NULL,   family = c(\"betabinomial\", \"binomial\")[1],   age.groups = c(\"0\", \"1-11\", \"12-23\", \"24-35\", \"36-47\", \"48-59\"),   age.n = c(1, 11, 12, 12, 12, 12),   age.time.group = c(1, 2, 3, 3, 3, 3),   age.strata.fixed.group = c(1, 2, 3, 4, 5, 6),   time.model = c(\"rw1\", \"rw2\", \"ar1\")[2],   st.time.model = NULL,   Amat,   bias.adj = NULL,   bias.adj.by = NULL,   formula = NULL,   year_label,   type.st = 4,   survey.effect = FALSE,   linear.trend = TRUE,   common.trend = FALSE,   strata.time.effect = FALSE,   hyper = \"pc\",   pc.u = 1,   pc.alpha = 0.01,   pc.u.phi = 0.5,   pc.alpha.phi = 2/3,   pc.u.cor = 0.7,   pc.alpha.cor = 0.9,   pc.st.u = NA,   pc.st.alpha = NA,   pc.st.slope.u = NA,   pc.st.slope.alpha = NA,   overdisp.mean = 0,   overdisp.prec = 0.4,   options = list(config = TRUE),   control.inla = list(strategy = \"adaptive\", int.strategy = \"auto\"),   control.fixed = list(),   verbose = FALSE,   geo = NULL,   rw = NULL,   ar = NULL,   st.rw = NULL,   age.rw.group = NULL,   ... )  fitINLA2(   data,   X = NULL,   family = c(\"betabinomial\", \"binomial\")[1],   age.groups = c(\"0\", \"1-11\", \"12-23\", \"24-35\", \"36-47\", \"48-59\"),   age.n = c(1, 11, 12, 12, 12, 12),   age.time.group = c(1, 2, 3, 3, 3, 3),   age.strata.fixed.group = c(1, 2, 3, 4, 5, 6),   time.model = c(\"rw1\", \"rw2\", \"ar1\")[2],   st.time.model = NULL,   Amat,   bias.adj = NULL,   bias.adj.by = NULL,   formula = NULL,   year_label,   type.st = 4,   survey.effect = FALSE,   linear.trend = TRUE,   common.trend = FALSE,   strata.time.effect = FALSE,   hyper = \"pc\",   pc.u = 1,   pc.alpha = 0.01,   pc.u.phi = 0.5,   pc.alpha.phi = 2/3,   pc.u.cor = 0.7,   pc.alpha.cor = 0.9,   pc.st.u = NA,   pc.st.alpha = NA,   pc.st.slope.u = NA,   pc.st.slope.alpha = NA,   overdisp.mean = 0,   overdisp.prec = 0.4,   options = list(config = TRUE),   control.inla = list(strategy = \"adaptive\", int.strategy = \"auto\"),   control.fixed = list(),   verbose = FALSE,   geo = NULL,   rw = NULL,   ar = NULL,   st.rw = NULL,   age.rw.group = NULL,   ... )"},{"path":"https://richardli.github.io/SUMMER/reference/smoothCluster.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cluster-level space-time smoothing models for mortality rates — smoothCluster","text":"data count data person-months following columns cluster: cluster ID years: time period region: region cluster strata: stratum cluster age: age group corresponding row total: total number person-month age group, stratum, cluster, period Y: total number deaths age group, stratum, cluster, period X Covariate matrix. must contain either column name \"region\", column name \"years\", . covariates must missing values regions (varying space) time periods (varying time). rest columns treated covariates mean model. family family model. can either binomial (logistic normal prior), betabiniomial. age.groups character vector age groups increasing order. age.n number months age groups order. age.time.group vector indicating grouping ages groups temporal model. example, age group assigned different temporal component, set age.rw.group c(1:length(age.groups)); age groups share random walk component, set age.rw.group rep(1, length(age.groups)). default 6 age groups c(1,2,3,3,3,3), assigns separate temporal trend first two groups common random walk rest age groups. vector contain values starting 1. argument replaces previous age.rw.group argument. age.strata.fixed.group vector indicating grouping ages groups different strata intercept. default c(1:length(age.groups)), correspond age group within stratum receives separate intercept. several age groups specified value vector, stratum specific deviation baseline assumed age groups. example, age.strata.fixed.group = c(1, 2, 3, 3, 3, 3), intercept part linear predictor consists 6 overall age-specific intercepts 3 set strata effects (base stratum chosen internally), age groups 1, 2, rest respectively. Notice argument control linear temporal trends (also parameterized fixed effect, determined age.rw.group argument). vector contain values starting 1. specific examples: (1) age group assigned different intercept, set age.strata.fixed.group c(1:length(age.groups)) (2) age groups share intercept, set age.strata.fixed.group rep(1, length(age.groups)). default 6 age groups former. (3) temporal trend associated intercept, set age.rw.group. time.model Model main temporal trend, can rw1, rw2, ar1, NULL (spatial-smoothing). Default rw2. ar1 main effect, linear slope also added time scaled -0.5 0.5, .e., slope coefficient represents total change first year last year projection period logit scale. st.time.model Temporal component model interaction term, can rw1, rw2, ar1. Default time.model unless specified otherwise. default include region-specific random slopes. can added interaction term specifying pc.st.slope.u pc.st.slope.alpha. Amat Adjacency matrix regions bias.adj ratio unadjusted mortality rates age-group-specific hazards true rates hazards. needs data frame can merged thee outcome, .e., column names time periods (national adjustment), time periods region (subnational adjustment). column specifying adjustment ratio named \"ratio\". bias.adj.vector column names specifying merge bias adjustment count data. example, bias adjustment factor provided bias.adj region time, bias.adj.`c(\"region\", \"time\")`. formula INLA formula.  See vignette example using customized formula. year_label string vector year names type.st type space-time interaction survey.effect logical indicator whether include survey fixed effect. set TRUE, needs column named 'survey' input data frame. prediction, effect term set 0. linear.trend logical indicator whether linear trend added temporal main effect. temporal main effect RW2, forced FALSE. Default TRUE. common.trend logical indicator whether age groups strata share linear trend temporal main effect. strata.time.effect logical indicator whether include strata specific temporal trends. hyper Deprecated. hyperpriors use. supports PC prior (\"pc\"). pc.u hyperparameter U PC prior precisions. pc.alpha hyperparameter alpha PC prior precisions. pc.u.phi hyperparameter U PC prior mixture probability phi BYM2 model. pc.alpha.phi hyperparameter alpha PC prior mixture probability phi BYM2 model. pc.u.cor hyperparameter U PC prior autocorrelation parameter AR prior, .e. Prob(cor > pc.u.cor) = pc.alpha.cor. pc.alpha.cor hyperparameter alpha PC prior autocorrelation parameter AR prior. pc.st.u hyperparameter U PC prior precisions interaction term. pc.st.alpha hyperparameter alpha PC prior precisions interaction term. pc.st.slope.u hyperparameter U PC prior precisions area-level random slope. pc.st.slope.u pc.st.slope.alpha NA, area-level random slope iid prior added model. parameterization random slope Prob(|beta| > pc.st.slope.u) = pc.st.slope.alpha, time covariate rescaled -0.5 0.5, random slope can interpreted total deviation main trend first year last year projected, logit scale. pc.st.slope.alpha hyperparameter alpha PC prior precisions area-level random slope. See parameterization. overdisp.mean hyperparameter betabinomial likelihood. Mean -dispersion parameter logit scale. overdisp.prec hyperparameter betabinomial likelihood. Precision -dispersion parameter logit scale. options list options passed control.compute() inla() function. control.inla list options passed control.inla() inla() function. Default \"adaptive\" integration strategy. control.fixed list options passed control.fixed() inla() function. verbose logical indicator print detailed inla() intermediate steps. geo Deprecated. Spatial polygon file, legacy parameter previous versions package. rw Deprecated. Take values 0, 1 2, indicating order random walk. rw = 0, autoregressive process used instead random walk main trend. See description argument ar details. ar Deprecated. Order autoregressive component. ar specified positive integer, random walk components replaced AR(p) terms interaction part. main temporal trend remains random walk order rw unless rw = 0. st.rw Deprecated. Take values 1 2, indicating order random walk interaction term. specified, take order argument rw main effect. Notice argument used ar set 0. age.rw.group Deprecated. Legacy parameter replaced age.time.group. ... arguments passed inla() function call.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/smoothCluster.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cluster-level space-time smoothing models for mortality rates — smoothCluster","text":"INLA model fit using provided formula, country summary data, geographic data","code":""},{"path":[]},{"path":"https://richardli.github.io/SUMMER/reference/smoothCluster.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Cluster-level space-time smoothing models for mortality rates — smoothCluster","text":"Zehang Richard Li","code":""},{"path":"https://richardli.github.io/SUMMER/reference/smoothCluster.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cluster-level space-time smoothing models for mortality rates — smoothCluster","text":"","code":"if (FALSE) { library(dplyr) data(DemoData) # Create dataset of counts counts.all <- NULL for(i in 1:length(DemoData)){   counts <- getCounts(DemoData[[i]][, c(\"clustid\", \"time\", \"age\", \"died\",                                         \"region\", \"strata\")],             variables = 'died', by = c(\"age\", \"clustid\", \"region\",                                           \"time\", \"strata\"))   counts <- counts %>% mutate(cluster = clustid, years = time, Y=died)   counts$strata <- gsub(\".*\\\\.\",\"\",counts$strata)   counts$survey <- names(DemoData)[i]    counts.all <- rbind(counts.all, counts) }  # fit cluster-level model on the periods periods <- levels(DemoData[[1]]$time) fit <- smoothCluster(data = counts.all,       Amat = DemoMap$Amat,       time.model = \"rw2\",       st.time.model = \"rw1\",      strata.time.effect =  TRUE,       survey.effect = TRUE,      family = \"betabinomial\",      year_label = c(periods, \"15-19\")) summary(fit) est <- getSmoothed(fit, nsim = 1000) plot(est$stratified, plot.CI=TRUE) + ggplot2::facet_wrap(~strata)   # fit cluster-level space-time model with covariate # notice without projected covariates, we use periods up to 10-14 only # construct a random covariate matrix for illustration periods <- levels(DemoData[[1]]$time) X <- expand.grid(years = periods,         region = unique(counts.all$region)) X$X1 <- rnorm(dim(X)[1]) X$X2 <- rnorm(dim(X)[1]) fit.covariate <- smoothCluster(data = counts.all,     X = X,      Amat = DemoMap$Amat,       time.model = \"rw2\",       st.time.model = \"rw1\",      strata.time.effect =  TRUE,       survey.effect = TRUE,      family = \"betabinomial\",      year_label = c(periods)) est <- getSmoothed(fit.covariate, nsim = 1000)  # fit cluster-level model for one time point only # i.e., space-only model fit.sp <- smoothCluster(data = subset(counts.all, time == \"10-14\"),       Amat = DemoMap$Amat,       time.model = NULL,       survey.effect = TRUE,      family = \"betabinomial\") summary(fit.sp) est <- getSmoothed(fit.sp, nsim = 1000) plot(est$stratified, plot.CI = TRUE) + ggplot2::facet_wrap(~strata)   # fit cluster-level model for one time point and covariate # construct a random covariate matrix for illustration X <- data.frame(region = unique(counts.all$region),       X1 = c(1, 2, 2, 1),        X2 = c(1, 1, 1, 2)) fit.sp.covariate <- smoothCluster(data = subset(counts.all, time == \"10-14\"),       X = X,       Amat = DemoMap$Amat,       time.model = NULL,       survey.effect = TRUE,      family = \"betabinomial\") summary(fit.sp.covariate) est <- getSmoothed(fit.sp.covariate, nsim = 1000) }"},{"path":"https://richardli.github.io/SUMMER/reference/smoothDirect.html","id":null,"dir":"Reference","previous_headings":"","what":"Smoothed direct estimates for mortality rates — smoothDirect","title":"Smoothed direct estimates for mortality rates — smoothDirect","text":"function smoothDirect replaces previous function name fitINLA (version 1.0.0).","code":""},{"path":"https://richardli.github.io/SUMMER/reference/smoothDirect.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Smoothed direct estimates for mortality rates — smoothDirect","text":"","code":"smoothDirect(   data,   Amat,   formula = NULL,   time.model = c(\"rw1\", \"rw2\", \"ar1\")[2],   st.time.model = NULL,   year_label,   year_range = c(1980, 2014),   is.yearly = TRUE,   m = 5,   type.st = 1,   survey.effect = FALSE,   hyper = c(\"pc\", \"gamma\")[1],   pc.u = 1,   pc.alpha = 0.01,   pc.u.phi = 0.5,   pc.alpha.phi = 2/3,   pc.u.cor = 0.7,   pc.alpha.cor = 0.9,   pc.st.u = NA,   pc.st.alpha = NA,   control.compute = list(dic = TRUE, mlik = TRUE, cpo = TRUE, openmp.strategy =     \"default\", config = TRUE),   control.inla = list(strategy = \"adaptive\", int.strategy = \"auto\"),   control.fixed = list(),   verbose = FALSE,   geo = NULL,   rw = NULL,   ar = NULL,   options = NULL )  fitINLA(   data,   Amat,   formula = NULL,   time.model = c(\"rw1\", \"rw2\", \"ar1\")[2],   st.time.model = NULL,   year_label,   year_range = c(1980, 2014),   is.yearly = TRUE,   m = 5,   type.st = 1,   survey.effect = FALSE,   hyper = c(\"pc\", \"gamma\")[1],   pc.u = 1,   pc.alpha = 0.01,   pc.u.phi = 0.5,   pc.alpha.phi = 2/3,   pc.u.cor = 0.7,   pc.alpha.cor = 0.9,   pc.st.u = NA,   pc.st.alpha = NA,   control.compute = list(dic = TRUE, mlik = TRUE, cpo = TRUE, openmp.strategy =     \"default\", config = TRUE),   control.inla = list(strategy = \"adaptive\", int.strategy = \"auto\"),   control.fixed = list(),   verbose = FALSE,   geo = NULL,   rw = NULL,   ar = NULL,   options = NULL )"},{"path":"https://richardli.github.io/SUMMER/reference/smoothDirect.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Smoothed direct estimates for mortality rates — smoothDirect","text":"data Combined dataset Amat Adjacency matrix regions formula INLA formula. See vignette example using customized formula. time.model Model main temporal trend, can rw1, rw2, ar1. ar1 implemented yearly model period data input. Default rw2. ar1 main effect, linear slope also added time scaled -0.5 0.5, .e., slope coefficient represents total change first year last year projection period logit scale. st.time.model Temporal component model interaction term, can rw1, rw2, ar1. ar1 implemented yearly model period data input. Default time.model unless specified otherwise. ar1 interaction model, region-specific random slopes currently implemented. year_label string vector year names year_range Entire range years (inclusive) defined year_label. .yearly Logical indicator fitting yearly period model. m Number years period. type.st type space-time interaction survey.effect logical indicator whether include survey iid random effect. set TRUE, needs column named 'survey' input data frame. prediction, random effect term set 0. Notice survey effect implemented according Merter et al. (2015) model, differently compared smoothCluster() function. hyper hyperpriors use. Default using PC prior (\"pc\"). pc.u hyperparameter U PC prior precisions. pc.alpha hyperparameter alpha PC prior precisions. pc.u.phi hyperparameter U PC prior mixture probability phi BYM2 model. pc.alpha.phi hyperparameter alpha PC prior mixture probability phi BYM2 model. pc.u.cor hyperparameter U PC prior autocorrelation parameter AR prior, .e. Prob(cor > pc.u.cor) = pc.alpha.cor. pc.alpha.cor hyperparameter alpha PC prior autocorrelation parameter AR prior. pc.st.u hyperparameter U PC prior precisions interaction term. pc.st.alpha hyperparameter alpha PC prior precisions interaction term. control.compute list options passed control.compute() inla() function. default argument saves internal objects created INLA posterior sampling later. fitted object large size need perform joint posterior sampling model (used benchmarking), argument can set control.compute = list(config = FALSE) reduce size fitted object. control.inla list options passed control.inla() inla() function. Default \"adaptive\" integration strategy. control.fixed list options passed control.fixed() inla() function. verbose logical indicator print detailed inla() intermediate steps. geo Deprecated. rw Deprecated. ar Deprecated. options Deprecated.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/smoothDirect.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Smoothed direct estimates for mortality rates — smoothDirect","text":"List fitted object","code":""},{"path":"https://richardli.github.io/SUMMER/reference/smoothDirect.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Smoothed direct estimates for mortality rates — smoothDirect","text":"Li, Z., Hsiao, Y., Godwin, J., Martin, B. D., Wakefield, J., Clark, S. J., & support United Nations Inter-agency Group Child Mortality Estimation technical advisory group. (2019). Changes spatial distribution -five mortality rate: Small-area analysis 122 DHS surveys 262 subregions 35 countries Africa. PloS one, 14(1), e0210645. Mercer, L. D., Wakefield, J., Pantazis, ., Lutambi, . M., Masanja, H., & Clark, S. (2015). Space-time smoothing complex survey data: small area estimation child mortality. annals applied statistics, 9(4), 1889.","code":""},{"path":[]},{"path":"https://richardli.github.io/SUMMER/reference/smoothDirect.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Smoothed direct estimates for mortality rates — smoothDirect","text":"Zehang Richard Li","code":""},{"path":"https://richardli.github.io/SUMMER/reference/smoothDirect.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Smoothed direct estimates for mortality rates — smoothDirect","text":"","code":"if (FALSE) {   years <- levels(DemoData[[1]]$time)   # obtain direct estimates   data_multi <- getDirectList(births = DemoData, years = years,   regionVar = \"region\",  timeVar = \"time\", clusterVar = \"~clustid+id\",   ageVar = \"age\", weightsVar = \"weights\", geo.recode = NULL)   data <- aggregateSurvey(data_multi)      #  national model   years.all <- c(years, \"15-19\")   fit1 <- smoothDirect(data = data, Amat = NULL,    year_label = years.all, year_range = c(1985, 2019),    time.model = 'rw2', m = 5, control.compute = list(config =TRUE))   out1 <- getSmoothed(fit1)   plot(out1)      #  subnational model   fit2 <- smoothDirect(data = data, Amat = DemoMap$Amat,    year_label = years.all, year_range = c(1985, 2019),    time.model = 'rw2', m = 5, type.st = 4)   out2 <- getSmoothed(fit2)   plot(out2)      #  subnational space-only model for one period   fit3 <- smoothDirect(data = subset(data, years == \"10-14\"),             time.model = NULL, Amat = DemoMap$Amat)   out3 <- getSmoothed(fit3)   plot(out3, plot.CI = TRUE) }"},{"path":"https://richardli.github.io/SUMMER/reference/smoothSurvey.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit space-time smoothing models for a generic outcome from complex surveys. — smoothSurvey","title":"Fit space-time smoothing models for a generic outcome from complex surveys. — smoothSurvey","text":"function calculates direct estimates region fit simple spatial smoothing model direct estimates adjusting survey design. Normal binary variables currently supported. binary variables, logit transformation performed direct estimates probabilities, Gaussian additive model fitted logit scale using INLA.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/smoothSurvey.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit space-time smoothing models for a generic outcome from complex surveys. — smoothSurvey","text":"","code":"smoothSurvey(   data,   geo = NULL,   Amat = NULL,   region.list = NULL,   X = NULL,   X.unit = NULL,   responseType = c(\"binary\", \"gaussian\")[1],   responseVar,   strataVar = \"strata\",   weightVar = \"weights\",   regionVar = \"region\",   clusterVar = \"~v001+v002\",   pc.u = 1,   pc.alpha = 0.01,   pc.u.phi = 0.5,   pc.alpha.phi = 2/3,   CI = 0.95,   formula = NULL,   timeVar = NULL,   time.model = c(\"rw1\", \"rw2\")[1],   include_time_unstruct = FALSE,   type.st = 1,   direct.est = NULL,   direct.est.var = NULL,   is.unit.level = FALSE,   is.agg = FALSE,   strataVar.within = NULL,   totalVar = NULL,   weight.strata = NULL,   nsim = 1000,   save.draws = FALSE,   smooth = TRUE,   ... )  fitGeneric(   data,   geo = NULL,   Amat = NULL,   region.list = NULL,   X = NULL,   X.unit = NULL,   responseType = c(\"binary\", \"gaussian\")[1],   responseVar,   strataVar = \"strata\",   weightVar = \"weights\",   regionVar = \"region\",   clusterVar = \"~v001+v002\",   pc.u = 1,   pc.alpha = 0.01,   pc.u.phi = 0.5,   pc.alpha.phi = 2/3,   CI = 0.95,   formula = NULL,   timeVar = NULL,   time.model = c(\"rw1\", \"rw2\")[1],   include_time_unstruct = FALSE,   type.st = 1,   direct.est = NULL,   direct.est.var = NULL,   is.unit.level = FALSE,   is.agg = FALSE,   strataVar.within = NULL,   totalVar = NULL,   weight.strata = NULL,   nsim = 1000,   save.draws = FALSE,   smooth = TRUE,   ... )"},{"path":"https://richardli.github.io/SUMMER/reference/smoothSurvey.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit space-time smoothing models for a generic outcome from complex surveys. — smoothSurvey","text":"data input data frame. input data  column response variable (responseVar), region ID (regionVar), stratification within region (strataVar), cluster ID (clusterVar). area-level model, data frame consist survey observations corresponding survey weights (weightVar). unit-level model .agg = FALSE, data frame consist aggregated counts clusters (binary responses), cluster-level response (continuous response). binary response (responseType = 'binary'), beta-binomial model fitted cluster-level counts. continuous response (responseType = 'gaussian'), Gaussian smoothing model fitted cluster-level response. unit-level model .agg = TRUE, data frame area-level model. binary response (responseType = 'binary'), beta-binomial model fitted cluster-level counts aggregated internally. continuous response (responseType = 'gaussian'), nested error model fitted unit-level response. geo Deprecated argument early versions. Amat Adjacency matrix regions. set NULL, IID spatial effect used. region.list vector region names. used IID model used adjacency matrix specified. allows output include regions sample data. spatial adjacency matrix specified, column names adjacency matrix used determine region.list. set NULL, regions data used. X Areal covariates data frame. One column name needs match regionVar specified function call, order linked data input. Currently supporting time-invariant region-level covariates. X.unit Column names unit-level covariates. X.unit specified, nested error model fitted unit-level IID noise, area-level predictions produced plugging covariate specified X argument. X specified, empirical mean covariate used. implemented continuous response Gaussian likelihood model unit-level model. responseType Type response variable, currently supports 'binary' (default logit link function) 'gaussian'. responseVar response variable strataVar strata variable used area-level model. weightVar weights variable regionVar Variable name region. clusterVar Variable name cluster. area-level model, formula cluster survey design object, e.g., '~clusterID + householdID'. unit-level model, variable name cluster unit. pc.u hyperparameter U PC prior precisions. pc.alpha hyperparameter alpha PC prior precisions. pc.u.phi hyperparameter U PC prior mixture probability phi BYM2 model. pc.alpha.phi hyperparameter alpha PC prior mixture probability phi BYM2 model. CI desired posterior credible interval calculate formula string user-specified random effects model used INLA call timeVar variable indicating time period. set NULL temporal model space-time interaction model ignored. time.model model temporal trends interactions. can either \"rw1\" \"rw2\". include_time_unstruct Indicator whether include temporal unstructured effects (.e., shocks) smoothed estimates cluster-level model. argument applies unit-level models. Default FALSE excludes unstructured temporal components. set TRUE  unstructured temporal random effects included. type.st can take values 0 (interaction), 1 4, corresponding type IV space-time interaction. direct.est data frame direct estimates, column names response region specified responseVar, regionVar, timeVar.  direct.est specified, overwrites data input. direct.est.var column name corresponding variance direct estimates. .unit.level logical indicator whether unit-level model fitted instead area-level model. .agg logical indicator whether input aggregated counts cluster. used unit-level model binary response variable. strataVar.within variable specifying within region stratification variable. used unit-level model. totalVar variable specifying total observations counts. used unit-level model counts specified. weight.strata data frame one column corresponding regionVar, columns specifying proportion strata region. argument specifies weights strata-specific estimates. used unit-level model. nsim number posterior draws take. used unit-level model weight.strata provided. save.draws logical indicator whether save full posterior draws. smooth logical indicator whether perform smoothing. set FALSE, data frame direct estimate returned. used .unit.level FALSE. ... additional arguments passed svydesign function.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/smoothSurvey.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit space-time smoothing models for a generic outcome from complex surveys. — smoothSurvey","text":"HT Direct estimates smooth Smoothed direct estimates fit fitted INLA object CI input argument Amat input argument responseType input argument formula INLA formula","code":""},{"path":"https://richardli.github.io/SUMMER/reference/smoothSurvey.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fit space-time smoothing models for a generic outcome from complex surveys. — smoothSurvey","text":"function smoothSurvey replaces previous function name fitGeneric (version 1.0.0).","code":""},{"path":[]},{"path":"https://richardli.github.io/SUMMER/reference/smoothSurvey.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Fit space-time smoothing models for a generic outcome from complex surveys. — smoothSurvey","text":"Zehang Richard Li","code":""},{"path":"https://richardli.github.io/SUMMER/reference/smoothSurvey.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit space-time smoothing models for a generic outcome from complex surveys. — smoothSurvey","text":"","code":"if (FALSE) { ## ## 1. Area-level model with binary response ##  data(DemoData2) data(DemoMap2) fit0 <- smoothSurvey(data=DemoData2,   Amat=DemoMap2$Amat, responseType=\"binary\",  responseVar=\"tobacco.use\", strataVar=\"strata\",  weightVar=\"weights\", regionVar=\"region\",  clusterVar = \"~clustid+id\", CI = 0.95) summary(fit0)  # if only direct estimates without smoothing is of interest fit0.dir <- smoothSurvey(data=DemoData2,   Amat=DemoMap2$Amat, responseType=\"binary\",  responseVar=\"tobacco.use\", strataVar=\"strata\",  weightVar=\"weights\", regionVar=\"region\",  clusterVar = \"~clustid+id\", CI = 0.95, smooth = FALSE)  # posterior draws can be returned with save.draws = TRUE fit0.draws <- smoothSurvey(data=DemoData2,   Amat=DemoMap2$Amat, responseType=\"binary\",  responseVar=\"tobacco.use\", strataVar=\"strata\",  weightVar=\"weights\", regionVar=\"region\",  clusterVar = \"~clustid+id\", CI = 0.95, save.draws = TRUE) # notice the posterior draws are on the latent scale head(fit0.draws$draws.est[, 1:10])   # Example with region-level covariates  Xmat <- aggregate(age~region, data = DemoData2,              FUN = function(x) mean(x))  fit1 <- smoothSurvey(data=DemoData2,     Amat=DemoMap2$Amat, responseType=\"binary\",    X = Xmat,   responseVar=\"tobacco.use\", strataVar=\"strata\",    weightVar=\"weights\", regionVar=\"region\",    clusterVar = \"~clustid+id\", CI = 0.95)  # Example with using only direct estimates as input instead of the full data direct <- fit0$HT[, c(\"region\", \"HT.est\", \"HT.var\")] fit2 <- smoothSurvey(data=NULL, direct.est = direct,                      Amat=DemoMap2$Amat, regionVar=\"region\",                     responseVar=\"HT.est\", direct.est.var = \"HT.var\",                      responseType = \"gaussian\") # Check it is the same as fit0 plot(fit2$smooth$mean, fit0$smooth$mean)  # Example with using only direct estimates as input,  #   and after transformation into a Gaussian smoothing model # Notice: the output are on the same scale as the input  #   and in this case, the logit estimates.     direct.logit <- fit0$HT[, c(\"region\", \"HT.logit.est\", \"HT.logit.var\")] fit3 <- smoothSurvey(data=NULL, direct.est = direct.logit,                 Amat=DemoMap2$Amat, regionVar=\"region\",                responseVar=\"HT.logit.est\", direct.est.var = \"HT.logit.var\",                responseType = \"gaussian\") # Check it is the same as fit0 plot(fit3$smooth$mean, fit0$smooth$logit.mean)  # Example with non-spatial smoothing using IID random effects fit4 <- smoothSurvey(data=DemoData2, responseType=\"binary\",         responseVar=\"tobacco.use\", strataVar=\"strata\",         weightVar=\"weights\", regionVar=\"region\",         clusterVar = \"~clustid+id\", CI = 0.95)  # Example with missing regions in the raw input DemoData2.sub <- subset(DemoData2, region != \"central\") fit.without.central <- smoothSurvey(data=DemoData2.sub,                            Amat=NULL, responseType=\"binary\",                           responseVar=\"tobacco.use\", strataVar=\"strata\",                           weightVar=\"weights\", regionVar=\"region\",                           clusterVar = \"~clustid+id\", CI = 0.95) fit.without.central$HT fit.without.central$smooth  fit.without.central <- smoothSurvey(data=DemoData2.sub,                            Amat=NULL, region.list = unique(DemoData2$region),                          responseType=\"binary\",                           responseVar=\"tobacco.use\", strataVar=\"strata\",                           weightVar=\"weights\", regionVar=\"region\",                           clusterVar = \"~clustid+id\", CI = 0.95) fit.with.central$HT fit.with.central$smooth  # Using the formula argument, further customizations can be added to the  #  model fitted. For example, we can fit the Fay-Harriot model with  #  IID effect instead of the BYM2 random effect as follows. #  The \"region.struct\" and \"hyperpc1\" are picked to match internal object  #  names. Other object names can be inspected from the source of smoothSurvey. fit5 <- smoothSurvey(data=DemoData2,          Amat=DemoMap2$Amat, responseType=\"binary\",         formula = \"f(region.struct, model = 'iid', hyper = hyperpc1)\",        pc.u = 1, pc.alpha = 0.01,        responseVar=\"tobacco.use\", strataVar=\"strata\",         weightVar=\"weights\", regionVar=\"region\",         clusterVar = \"~clustid+id\", CI = 0.95) # Check it is the same as fit4, notice the region order may be different regions <- fit5$smooth$region plot(fit4$smooth[match(regions, fit4$smooth$region),]$logit.mean, fit5$smooth$logit.mean)  ## ## 2. Unit-level model with binary response   ##  # For unit-level models, we need to create stratification variable within regions data <- DemoData2 data$urbanicity <- \"rural\" data$urbanicity[grep(\"urban\", data$strata)] <- \"urban\"  # Beta-binomial likelihood is used in this model fit6 <- smoothSurvey(data=data,    Amat=DemoMap2$Amat, responseType=\"binary\",    X = Xmat, is.unit.level = TRUE,   responseVar=\"tobacco.use\", strataVar.within = \"urbanicity\",    regionVar=\"region\", clusterVar = \"clustid\", CI = 0.95)  # We may use aggregated PSU-level counts as input as well #    in the case of modeling a binary outcome  data.agg <- aggregate(tobacco.use~region + urbanicity + clustid,                        data = data, FUN = sum) data.agg.total <- aggregate(tobacco.use~region + urbanicity + clustid,                        data = data, FUN = length) colnames(data.agg.total)[4] <- \"total\" data.agg <- merge(data.agg, data.agg.total) head(data.agg)  fit7 <- smoothSurvey(data=data.agg,    Amat=DemoMap2$Amat, responseType=\"binary\",    X = Xmat, is.unit.level = TRUE, is.agg = TRUE,   responseVar = \"tobacco.use\", strataVar.within = \"urbanicity\",    totalVar = \"total\", regionVar=\"region\", clusterVar = \"clustid\", CI = 0.95)  # Check it is the same as fit6 plot(fit6$smooth$mean, fit7$smooth$mean)    ## ## 3. Area-level model with continuous response ##  # The smoothing model is the same as area-level model with binary response #  the continuous direct estimates are smoothed instead of  #  their logit-transformed versions for binary response. fit8 <- smoothSurvey(data=DemoData2, Amat=DemoMap2$Amat,         responseType=\"gaussian\", responseVar=\"age\", strataVar=\"strata\",         weightVar=\"weights\", regionVar=\"region\",         pc.u.phi = 0.5, pc.alpha.phi = 0.5,        clusterVar = \"~clustid+id\", CI = 0.95)  ## ## 4. Unit-level model with continuous response   ##    (or nested error models)  # The unit-level model assumes for each of the i-th unit, #    Y_{i} ~ intercept + region_effect + IID_i #    where IID_i is the error term specific to i-th unit  # When more than one level of cluster sampling is carried out,  #   they are ignored here. Only the input unit is considered. #   So here we do not need to specify clusterVar any more.  fit9 <- smoothSurvey(data= data,    Amat=DemoMap2$Amat, responseType=\"gaussian\",    is.unit.level = TRUE, responseVar=\"age\", strataVar.within = NULL,   regionVar=\"region\", clusterVar = NULL, CI = 0.95)  # To compare, we may also model PSU-level responses. As an illustration,  data.median <- aggregate(age~region + urbanicity + clustid,                        data = data, FUN = median)  fit10 <- smoothSurvey(data= data.median,    Amat=DemoMap2$Amat, responseType=\"gaussian\",    is.unit.level = TRUE, responseVar=\"age\", strataVar.within = NULL,   regionVar=\"region\", clusterVar = \"clustid\", CI = 0.95)   # To further incorporate within-area stratification  fit11 <- smoothSurvey(data = data,    Amat = DemoMap2$Amat, responseType = \"gaussian\",    is.unit.level = TRUE, responseVar=\"age\", strataVar.within = \"urbanicity\",   regionVar = \"region\", clusterVar = NULL, CI = 0.95)    # Notice the usual output is now stratified within each region # The aggregated estimates require strata proportions for each region # For illustration, we set strata population proportions below prop <- data.frame(region = unique(data$region),                              urban = 0.3,                              rural = 0.7) fit12 <- smoothSurvey(data=data,    Amat=DemoMap2$Amat, responseType=\"gaussian\",    is.unit.level = TRUE, responseVar=\"age\", strataVar.within = \"urbanicity\",   regionVar=\"region\", clusterVar = NULL, CI = 0.95,   weight.strata = prop)    # aggregated outcome head(fit12$smooth.overall)  # Compare aggregated outcome with direct aggregating posterior means.  # There could be small differences if only 1000 posterior draws are taken. est.urb <- subset(fit11$smooth, strata == \"urban\") est.rural <- subset(fit11$smooth, strata == \"rural\") est.mean.post <- est.urb$mean * 0.3 + est.rural$mean * 0.7 plot(fit12$smooth.overall$mean, est.mean.post)   ## ## 6. Unit-level model with continuous response and unit-level covariate  ##   # For area-level prediction, area-level covariate mean needs to be   #   specified in X argument. And unit-level covariate names are specified #   in X.unit argument.  set.seed(1) sim <- data.frame(region = rep(c(1, 2, 3, 4), 1000),                    X1 = rnorm(4000), X2 = rnorm(4000)) Xmean <- aggregate(.~region, data = sim, FUN = sum) sim$Y <- rnorm(4000, mean = sim$X1 + 0.3 * sim$X2 + sim$region) samp <- sim[sample(1:4000, 20), ] fit.sim <- smoothSurvey(data=samp ,                    X.unit = c(\"X1\", \"X2\"),                   X = Xmean, Amat=NULL, responseType=\"gaussian\",                    is.unit.level = TRUE, responseVar=\"Y\", regionVar = \"region\",                     pc.u = 1, pc.alpha = 0.01, CI = 0.95)   }"},{"path":"https://richardli.github.io/SUMMER/reference/smoothUnit.html","id":null,"dir":"Reference","previous_headings":"","what":"Smooth via basic unit level model — smoothUnit","title":"Smooth via basic unit level model — smoothUnit","text":"Generates small area estimates smoothing direct estimates using basic  unit level model","code":""},{"path":"https://richardli.github.io/SUMMER/reference/smoothUnit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Smooth via basic unit level model — smoothUnit","text":"","code":"smoothUnit(   formula,   domain,   design,   family = c(\"gaussian\", \"binomial\")[1],   X.pop = NULL,   adj.mat = NULL,   domain.size = NULL,   pc.u = 1,   pc.alpha = 0.01,   pc.u.phi = 0.5,   pc.alpha.phi = 2/3,   level = 0.95,   n.sample = 250,   return.samples = F,   X.pop.weights = NULL )"},{"path":"https://richardli.github.io/SUMMER/reference/smoothUnit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Smooth via basic unit level model — smoothUnit","text":"formula object class 'formula' describing model fitted. domain One-sided formula specifying factors containing domain labels design object class \"svydesign\" containing data model family response variable, currently supports 'binomial' (default logit link function) 'gaussian'. X.pop Data frame population unit-level covariates. One column name needs match domain specified, order linked data input. Currently supporting time-invariant covariates. adj.mat Adjacency matrix rownames matching domain labels. set NULL, IID spatial effect used. domain.size Data frame domain sizes. One column names needs match name domain variable, order linked data input must column names 'size' containing domain sizes. default option transformation, logit log implemented. pc.u Hyperparameter U PC prior precisions. See INLA documentation details parameterization. pc.alpha Hyperparameter alpha PC prior precisions. pc.u.phi Hyperparameter U PC prior mixture probability phi BYM2 model. pc.alpha.phi Hyperparameter alpha PC prior mixture probability phi BYM2 model. level specified level posterior credible intervals n.sample Number draws posterior used compute summaries return.samples TRUE, return matrix posterior samples area level quantities X.pop.weights Optional vector weights use aggregating unit level predictions","code":""},{"path":"https://richardli.github.io/SUMMER/reference/smoothUnit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Smooth via basic unit level model — smoothUnit","text":"svysae object","code":""},{"path":"https://richardli.github.io/SUMMER/reference/smoothUnit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Smooth via basic unit level model — smoothUnit","text":"","code":"if (FALSE) { data(DemoData2) data(DemoMap2) library(survey) des0 <- svydesign(ids = ~clustid+id, strata = ~strata,                  weights = ~weights, data = DemoData2, nest = TRUE)                   # EXAMPLE 1: Continuous response model cts.res <- smoothUnit(formula = tobacco.use ~ 1,                       domain = ~region,                       design = des0, X.pop = DemoData2)                        # EXAMPLE 2: Binary response model bin.res <- smoothUnit(formula = tobacco.use ~ 1,                       family = \"binomial\",                       domain = ~region,                       design = des0, X.pop = DemoData2) }"},{"path":"https://richardli.github.io/SUMMER/reference/st.new.html","id":null,"dir":"Reference","previous_headings":"","what":"New Type I to IV space time interaction models for m-year to period random effects — st.new","title":"New Type I to IV space time interaction models for m-year to period random effects — st.new","text":"New Type IV space time interaction models m-year period random effects","code":""},{"path":"https://richardli.github.io/SUMMER/reference/st.new.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"New Type I to IV space time interaction models for m-year to period random effects — st.new","text":"","code":"st.new(   cmd = c(\"graph\", \"Q\", \"mu\", \"initial\", \"log.norm.const\", \"log.prior\", \"quit\"),   theta = NULL )"},{"path":"https://richardli.github.io/SUMMER/reference/st.new.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"New Type I to IV space time interaction models for m-year to period random effects — st.new","text":"cmd list model components theta log precision","code":""},{"path":"https://richardli.github.io/SUMMER/reference/st.new.pc.html","id":null,"dir":"Reference","previous_headings":"","what":"New Type I to IV space time interaction models for m-year to period random effects — st.new.pc","title":"New Type I to IV space time interaction models for m-year to period random effects — st.new.pc","text":"New Type IV space time interaction models m-year period random effects","code":""},{"path":"https://richardli.github.io/SUMMER/reference/st.new.pc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"New Type I to IV space time interaction models for m-year to period random effects — st.new.pc","text":"","code":"st.new.pc(   cmd = c(\"graph\", \"Q\", \"mu\", \"initial\", \"log.norm.const\", \"log.prior\", \"quit\"),   theta = NULL )"},{"path":"https://richardli.github.io/SUMMER/reference/st.new.pc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"New Type I to IV space time interaction models for m-year to period random effects — st.new.pc","text":"cmd list model components theta log precision","code":""},{"path":"https://richardli.github.io/SUMMER/reference/summary.SUMMERmodel.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary method for the smoothing models. — summary.SUMMERmodel","title":"Summary method for the smoothing models. — summary.SUMMERmodel","text":"function summary method class SUMMERmodel.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/summary.SUMMERmodel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary method for the smoothing models. — summary.SUMMERmodel","text":"","code":"# S3 method for SUMMERmodel summary(object, ...)"},{"path":"https://richardli.github.io/SUMMER/reference/summary.SUMMERmodel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary method for the smoothing models. — summary.SUMMERmodel","text":"object output smoothDirect smoothCluster ... used","code":""},{"path":[]},{"path":"https://richardli.github.io/SUMMER/reference/summary.SUMMERmodel.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Summary method for the smoothing models. — summary.SUMMERmodel","text":"Zehang Li","code":""},{"path":"https://richardli.github.io/SUMMER/reference/summary.SUMMERmodel.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summary method for the smoothing models. — summary.SUMMERmodel","text":"","code":"if (FALSE) {   library(SUMMER)   library(dplyr)   data(DemoData)    # Smooth Direct Model   years <- levels(DemoData[[1]]$time)   # obtain direct estimates   data_multi <- getDirectList(births = DemoData, years = years,   regionVar = \"region\",  timeVar = \"time\", clusterVar = \"~clustid+id\",   ageVar = \"age\", weightsVar = \"weights\", geo.recode = NULL)   data <- aggregateSurvey(data_multi)      years.all <- c(years, \"15-19\")   fit <- smoothDirect(data = data, Amat = NULL,    year_label = years.all, year_range = c(1985, 2019),    time.model = 'rw2', is.yearly=FALSE, m = 5)   summary(fit)    # Cluster-level Model   counts.all <- NULL   for(i in 1:length(DemoData)){   counts <- getCounts(DemoData[[i]][, c(\"clustid\", \"time\", \"age\", \"died\",                                        \"region\", \"strata\")],            variables = 'died', by = c(\"age\", \"clustid\", \"region\",                                          \"time\", \"strata\"))   counts <- counts %>% mutate(cluster = clustid, years = time, Y=died)   counts$strata <- gsub(\".*\\\\.\",\"\",counts$strata)   counts$survey <- names(DemoData)[i]    counts.all <- rbind(counts.all, counts)   }      # fit cluster-level model on the periods   periods <- levels(DemoData[[1]]$time)   fit <- smoothCluster(data = counts.all,       Amat = DemoMap$Amat,       time.model = \"rw2\",       st.time.model = \"rw1\",      strata.time.effect =  TRUE,       survey.effect = TRUE,      family = \"betabinomial\",      year_label = c(periods, \"15-19\"))   summary(fit)  }"},{"path":"https://richardli.github.io/SUMMER/reference/summary.SUMMERmodel.svy.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary method for the smoothing model and output from smoothSurvey. — summary.SUMMERmodel.svy","title":"Summary method for the smoothing model and output from smoothSurvey. — summary.SUMMERmodel.svy","text":"function summary method class SUMMERmodel.svy.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/summary.SUMMERmodel.svy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary method for the smoothing model and output from smoothSurvey. — summary.SUMMERmodel.svy","text":"","code":"# S3 method for SUMMERmodel.svy summary(object, ...)"},{"path":"https://richardli.github.io/SUMMER/reference/summary.SUMMERmodel.svy.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary method for the smoothing model and output from smoothSurvey. — summary.SUMMERmodel.svy","text":"object output smoothSurvey ... used","code":""},{"path":[]},{"path":"https://richardli.github.io/SUMMER/reference/summary.SUMMERmodel.svy.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Summary method for the smoothing model and output from smoothSurvey. — summary.SUMMERmodel.svy","text":"Zehang Li","code":""},{"path":"https://richardli.github.io/SUMMER/reference/summary.SUMMERmodel.svy.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summary method for the smoothing model and output from smoothSurvey. — summary.SUMMERmodel.svy","text":"","code":"if (FALSE) { data(DemoData2) data(DemoMap2) fit0 <- smoothSurvey(data=DemoData2,   Amat=DemoMap2$Amat, responseType=\"binary\",  responseVar=\"tobacco.use\", strataVar=\"strata\",  weightVar=\"weights\", regionVar=\"region\",  clusterVar = \"~clustid+id\", CI = 0.95) summary(fit0) }"},{"path":"https://richardli.github.io/SUMMER/reference/summary.SUMMERprojlist.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary method for the combined projection output. This function is the print method for class SUMMERprojlist. — summary.SUMMERprojlist","title":"Summary method for the combined projection output. This function is the print method for class SUMMERprojlist. — summary.SUMMERprojlist","text":"Summary method combined projection output. function print method class SUMMERprojlist.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/summary.SUMMERprojlist.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary method for the combined projection output. This function is the print method for class SUMMERprojlist. — summary.SUMMERprojlist","text":"","code":"# S3 method for SUMMERprojlist summary(object, ...)"},{"path":"https://richardli.github.io/SUMMER/reference/summary.SUMMERprojlist.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary method for the combined projection output. This function is the print method for class SUMMERprojlist. — summary.SUMMERprojlist","text":"object output getSmoothed ... used","code":""},{"path":"https://richardli.github.io/SUMMER/reference/summary.SUMMERprojlist.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Summary method for the combined projection output. This function is the print method for class SUMMERprojlist. — summary.SUMMERprojlist","text":"Zehang Li","code":""},{"path":"https://richardli.github.io/SUMMER/reference/summary.SUMMERprojlist.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summary method for the combined projection output. This function is the print method for class SUMMERprojlist. — summary.SUMMERprojlist","text":"","code":"if (FALSE) {  library(SUMMER)  library(dplyr)  data(DemoData)  # Create dataset of counts  counts.all <- NULL  for(i in 1:length(DemoData)){  counts <- getCounts(DemoData[[i]][, c(\"clustid\", \"time\", \"age\", \"died\",                                       \"region\", \"strata\")],           variables = 'died', by = c(\"age\", \"clustid\", \"region\",                                         \"time\", \"strata\"))  counts <- counts %>% mutate(cluster = clustid, years = time, Y=died)  counts$strata <- gsub(\".*\\\\.\",\"\",counts$strata)  counts$survey <- names(DemoData)[i]   counts.all <- rbind(counts.all, counts)  }    # fit cluster-level model on the periods  periods <- levels(DemoData[[1]]$time)  fit <- smoothCluster(data = counts.all,      Amat = DemoMap$Amat,      time.model = \"rw2\",      st.time.model = \"rw1\",     strata.time.effect =  TRUE,      survey.effect = TRUE,     family = \"betabinomial\",     year_label = c(periods, \"15-19\"))  summary(fit)  est <- getSmoothed(fit, nsim = 1000) }"},{"path":"https://richardli.github.io/SUMMER/reference/tcpPlot.html","id":null,"dir":"Reference","previous_headings":"","what":"Discrete-color maps based on the True Classification Probabilities — tcpPlot","title":"Discrete-color maps based on the True Classification Probabilities — tcpPlot","text":"Discrete-color maps based True Classification Probabilities","code":""},{"path":"https://richardli.github.io/SUMMER/reference/tcpPlot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Discrete-color maps based on the True Classification Probabilities — tcpPlot","text":"","code":"tcpPlot(   draws,   geo,   by.geo = NULL,   year_plot = NULL,   ncol = 4,   per1000 = FALSE,   thresholds = NULL,   intervals = 3,   size.title = 0.7,   legend.label = NULL,   border = \"gray20\",   size = 0.5 )"},{"path":"https://richardli.github.io/SUMMER/reference/tcpPlot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Discrete-color maps based on the True Classification Probabilities — tcpPlot","text":"draws posterior draw object getSmoothed geo SpatialPolygonsDataFrame object map .geo variable name specifying region names geo year_plot vector year string vector plotted. ncol number columns output figure. per1000 logical indicator multiply results 1000. thresholds vector thresholds (mortality scale) defining discrete color scale maps. intervals number quantile intervals defining discrete color scale maps. Required thresholds specified. size.title numerical value giving amount plot title magnified relative default. legend.label Label color legend. border color border size size border","code":""},{"path":"https://richardli.github.io/SUMMER/reference/tcpPlot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Discrete-color maps based on the True Classification Probabilities — tcpPlot","text":"list True Classification Probability (TCP) tables, list individual spplot maps, gridded array maps.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/tcpPlot.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Discrete-color maps based on the True Classification Probabilities — tcpPlot","text":"Tracy Qi Dong, Jon Wakefield. (2020) Modeling presentation vaccination coverage estimates using data household surveys. arXiv preprint arXiv:2004.03127.","code":""},{"path":"https://richardli.github.io/SUMMER/reference/tcpPlot.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Discrete-color maps based on the True Classification Probabilities — tcpPlot","text":"Tracy Qi Dong, Zehang Richard Li","code":""},{"path":"https://richardli.github.io/SUMMER/reference/tcpPlot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Discrete-color maps based on the True Classification Probabilities — tcpPlot","text":"","code":"if (FALSE) { library(dplyr) data(DemoData) # Create dataset of counts, unstratified counts.all <- NULL for(i in 1:length(DemoData)){   counts <- getCounts(DemoData[[i]][, c(\"clustid\", \"time\", \"age\", \"died\",                                         \"region\")],             variables = 'died', by = c(\"age\", \"clustid\", \"region\",                                           \"time\"))   counts <- counts %>% mutate(cluster = clustid, years = time, Y=died)   counts$strata <- NA   counts$survey <- names(DemoData)[i]    counts.all <- rbind(counts.all, counts) }  # fit cluster-level model on the periods periods <- levels(DemoData[[1]]$time) fit <- smoothCluster(data = counts.all,        Amat = DemoMap$Amat,        time.model = \"rw2\",        st.time.model = \"rw1\",       strata.time.effect =  TRUE,        survey.effect = TRUE,       family = \"betabinomial\",       year_label = c(periods, \"15-19\")) est <- getSmoothed(fit, nsim = 1000, save.draws=TRUE)  tcp <- tcpPlot(est, DemoMap$geo, by.geo = \"REGNAME\", interval = 3, year_plot = periods)  tcp$g }"},{"path":"https://richardli.github.io/SUMMER/news/index.html","id":"version-140","dir":"Changelog","previous_headings":"","what":"Version 1.4.0","title":"Version 1.4.0","text":"CRAN release: 2024-03-01 New major functions population prevalence simulation based population frame population density information, along methods aggregating pixel level prevalences populations areal level.","code":""},{"path":"https://richardli.github.io/SUMMER/news/index.html","id":"version-130","dir":"Changelog","previous_headings":"","what":"Version 1.3.0","title":"Version 1.3.0","text":"CRAN release: 2022-07-08 New SAE functions vignette.","code":""},{"path":"https://richardli.github.io/SUMMER/news/index.html","id":"version-121","dir":"Changelog","previous_headings":"","what":"Version 1.2.1","title":"Version 1.2.1","text":"CRAN release: 2022-02-14 smoothSurvey now can return posterior draws. flexible strata effect specification smoothCluster. Discrete cut option mapPlot Internal changes work latest INLA version 21.11.22.","code":""},{"path":"https://richardli.github.io/SUMMER/news/index.html","id":"version-120-2021-07-01","dir":"Changelog","previous_headings":"","what":"Version 1.2.0 (2021-07-01)","title":"Version 1.2.0 (2021-07-01)","text":"CRAN release: 2021-07-06 Major expansion smoothSurvey implement popular SAE methods. Syntax change function. Allows smoothDirect smoothCluster fit space-models. smoothSurvey, smoothDirect, smoothCluster now returns S3 classed objects. Bug fixes.","code":""},{"path":"https://richardli.github.io/SUMMER/news/index.html","id":"version-110-2021-01-31","dir":"Changelog","previous_headings":"","what":"Version 1.1.0 (2021-01-31)","title":"Version 1.1.0 (2021-01-31)","text":"CRAN release: 2021-02-02 Allows stratum-specific time trends shared cluster-level models. Allows age truncated full years adjusted age.truncate variable getBirths function. corrects person-month calculation DHS surveys age months reported full years children 24 months old. Major bug fix: person-months records produced getBirths function contained error previous versions, leading incorrect death counts exposure months. addition, age bands specified different default, age variable output wrong. bugs now fixed latest version. Fix incorrectly calculated time main effect getDiag function. Fix bug data contain rows incorrectly labeled time periods. Fix year.cut argument length 2 getBirths function.","code":""},{"path":"https://richardli.github.io/SUMMER/news/index.html","id":"version-100-2020-07-01","dir":"Changelog","previous_headings":"","what":"Version 1.0.0 (2020-07-01)","title":"Version 1.0.0 (2020-07-01)","text":"CRAN release: 2020-07-09 fitGeneric now smoothSurvey fitINLA now smoothDirect fitINLA2 now smoothCluster extensions smoothed direct cluster level models. Major changes temporal models specified time.model st.time.model. interpretable parameterization slope random slopes. visualization options. Note: Previous function name argument syntax remain work , may receive high priority maintenance future. Better model summary message. Removed unnecessary function arguments, e.g., geo various functions. Removed requirement repeated specifying Amat, year_label year_range. Now required model fitting stage. New vignettes.","code":""},{"path":"https://richardli.github.io/SUMMER/news/index.html","id":"version-031-2019-10-23","dir":"Changelog","previous_headings":"","what":"Version 0.3.1 (2019-10-23)","title":"Version 0.3.1 (2019-10-23)","text":"Fixed minor typo lower upper bounds switched applying aggregateSurvey(). Add option remove person-month records last time period contain k years data getBirth(). Improved mapPlot().","code":""},{"path":"https://richardli.github.io/SUMMER/news/index.html","id":"version-030-2019-10-01","dir":"Changelog","previous_headings":"","what":"Version 0.3.0 (2019-10-01)","title":"Version 0.3.0 (2019-10-01)","text":"CRAN release: 2019-10-23 Version 0.3.0 contains major updates previous versions. countrySummary now getDirect cuontrySummary_mult now getDirectList fitspace now fitGeneric projINLA now getSmooth fitINLA2: implements new smoothing methods based binomial models cluster level. getDiag: produce diagnostic plots fitted model. hatchPlot: plot variables map hatching indicating width credible interval. getAdjusted: produce adjusted estimates fitted model getAmat: automatic extract spatial adjacency matrix polygon file. getCounts: aggregate person-month data counts totals groups. mapPoints: map GPS points polygon regions. Default prior changed BYM2 + PC priors. Various name changes function arguments reduce ambiguity. Various output column name change improve consistency across functions. Three set new vignettes provided guide users various modeling workflow.","code":""}]
